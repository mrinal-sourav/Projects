
C:\Users\mrinal\Documents\code_stuff\Carom Billiards Source>python nn_a_star_train.py
C:\Users\mrinal\AppData\Local\Programs\Python\Python36\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Train on 8396403 samples, validate on 2099101 samples
Epoch 1/35
2018-11-10 12:14:26.881085: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2018-11-10 12:14:27.887519: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1212] Found device 0 with properties:
name: GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:01:00.0
totalMemory: 4.00GiB freeMemory: 3.30GiB
2018-11-10 12:14:27.896694: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 12:14:28.564997: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3032 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
8396403/8396403 [==============================] - 29s 3us/step - loss: 294.9149 - val_loss: 288.9569
Epoch 2/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 273.5725 - val_loss: 269.0333
Epoch 3/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 263.1647 - val_loss: 269.2672
Epoch 4/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 255.4129 - val_loss: 274.8102
Epoch 5/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 250.2306 - val_loss: 249.4518
Epoch 6/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 246.5003 - val_loss: 269.1524
Epoch 7/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 243.6328 - val_loss: 267.1758
Epoch 8/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 241.5125 - val_loss: 291.2211
Epoch 9/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 239.6265 - val_loss: 239.2971
Epoch 10/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 237.7815 - val_loss: 236.2417
Epoch 11/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 236.2903 - val_loss: 269.9621
Epoch 12/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 234.9739 - val_loss: 235.9444
Epoch 13/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 233.7492 - val_loss: 236.1993
Epoch 14/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 232.4638 - val_loss: 239.3234
Epoch 15/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 231.1265 - val_loss: 229.2278
Epoch 16/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 229.9069 - val_loss: 234.2482
Epoch 17/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 228.6030 - val_loss: 228.1959
Epoch 18/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 227.2746 - val_loss: 238.7868
Epoch 19/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 226.1795 - val_loss: 231.0386
Epoch 20/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 225.0308 - val_loss: 243.0438
Epoch 21/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 224.2027 - val_loss: 248.7214
Epoch 22/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 223.0568 - val_loss: 228.4449
Epoch 23/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 222.1433 - val_loss: 245.0270
Epoch 24/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 221.4932 - val_loss: 227.7227
Epoch 25/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 220.6992 - val_loss: 223.3956
Epoch 26/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 219.9906 - val_loss: 227.3613
Epoch 27/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 219.2540 - val_loss: 227.2156
Epoch 28/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 218.7871 - val_loss: 269.8892
Epoch 29/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 218.2098 - val_loss: 256.2168
Epoch 30/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 217.7841 - val_loss: 227.4047
Epoch 31/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 216.8985 - val_loss: 217.1809
Epoch 32/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 216.3031 - val_loss: 231.9399
Epoch 33/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 215.7114 - val_loss: 238.1438
Epoch 34/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 215.3326 - val_loss: 244.7772
Epoch 35/35
8396403/8396403 [==============================] - 26s 3us/step - loss: 214.9900 - val_loss: 235.7905

 ###### inititial_accuracy = 259.74142576998975



 QUEUE SIZE BEFORE GET = 1


 NODE SELECTED <<<------ Epochs = 35 -------- BatchSize = 4000 --------- Accuracy = 259.74142576998975 -------->>>


 CHILD 1 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 3000

         EPOCHS = 35
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/35
2018-11-10 12:29:44.369967: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 12:29:44.375630: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 33s 4us/step - loss: 295.4704 - val_loss: 273.0383
Epoch 2/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 271.6458 - val_loss: 269.2371
Epoch 3/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 261.1172 - val_loss: 259.6120
Epoch 4/35
9445953/9445953 [==============================] - 33s 4us/step - loss: 253.4096 - val_loss: 246.4229
Epoch 5/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 248.3016 - val_loss: 245.1950
Epoch 6/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 244.7124 - val_loss: 242.2310
Epoch 7/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 241.7356 - val_loss: 236.0365
Epoch 8/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 238.8910 - val_loss: 234.9783
Epoch 9/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 235.9679 - val_loss: 233.0078
Epoch 10/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 233.1440 - val_loss: 228.1090
Epoch 11/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 230.9394 - val_loss: 232.4729
Epoch 12/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 228.9359 - val_loss: 225.2030
Epoch 13/35
9445953/9445953 [==============================] - 32s 3us/step - loss: 227.4338 - val_loss: 222.6199
Epoch 14/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 225.8150 - val_loss: 229.4274
Epoch 15/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 224.7686 - val_loss: 221.6892
Epoch 16/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 223.5673 - val_loss: 230.1751
Epoch 17/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 222.4702 - val_loss: 219.8494
Epoch 18/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 221.4632 - val_loss: 219.0705
Epoch 19/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 220.5600 - val_loss: 216.5591
Epoch 20/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 219.6651 - val_loss: 214.1322
Epoch 21/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 218.8928 - val_loss: 215.3177
Epoch 22/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 217.9155 - val_loss: 215.3310
Epoch 23/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 217.3405 - val_loss: 212.6291
Epoch 24/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 216.6051 - val_loss: 212.8647
Epoch 25/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 215.9857 - val_loss: 217.2697
Epoch 26/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 215.4639 - val_loss: 223.4660
Epoch 27/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 214.7599 - val_loss: 215.7592
Epoch 28/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 214.1591 - val_loss: 218.7339
Epoch 29/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 213.7472 - val_loss: 211.4770
Epoch 30/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 213.0220 - val_loss: 212.9299
Epoch 31/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 212.5844 - val_loss: 223.3947
Epoch 32/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 212.0925 - val_loss: 216.0848
Epoch 33/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 211.6199 - val_loss: 209.9085
Epoch 34/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 211.1403 - val_loss: 214.8851
Epoch 35/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 210.6574 - val_loss: 222.7748

         CHILD ACCURACY = 220.44908140002684


         PARENT ACCURACY = 259.74142576998975


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 1 <<<<<<<<<<<<<<<<<<<<<<<<<<<


                         ********** BEST MODEL SAVED | EPOCHS = 35 | BATCH_SIZE = 3000 | ACCURACY = 220.44908140002684 ********




 CHILD 2 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 3000

         EPOCHS = 40
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/40
2018-11-10 12:48:55.488198: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 12:48:55.492934: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 294.4765 - val_loss: 274.9031
Epoch 2/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 274.8783 - val_loss: 268.5415
Epoch 3/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 263.8940 - val_loss: 254.8412
Epoch 4/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 254.8889 - val_loss: 247.1957
Epoch 5/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 249.6007 - val_loss: 243.2354
Epoch 6/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 245.8336 - val_loss: 247.2536
Epoch 7/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 242.8691 - val_loss: 238.5209
Epoch 8/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 240.4217 - val_loss: 241.2442
Epoch 9/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 237.4910 - val_loss: 239.0966
Epoch 10/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 234.0447 - val_loss: 228.2489
Epoch 11/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 230.5383 - val_loss: 223.8910
Epoch 12/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 228.0234 - val_loss: 221.1513
Epoch 13/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 226.1492 - val_loss: 226.3682
Epoch 14/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 224.2039 - val_loss: 219.8707
Epoch 15/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 222.7280 - val_loss: 219.0999
Epoch 16/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 221.5744 - val_loss: 214.7168
Epoch 17/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 220.2956 - val_loss: 221.0199
Epoch 18/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 219.1463 - val_loss: 215.8018
Epoch 19/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 218.2153 - val_loss: 212.9152
Epoch 20/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 217.2292 - val_loss: 213.2391
Epoch 21/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 216.4544 - val_loss: 213.1375
Epoch 22/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 215.7180 - val_loss: 215.9399
Epoch 23/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 214.9395 - val_loss: 211.2100
Epoch 24/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 214.1719 - val_loss: 214.0093
Epoch 25/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 213.5495 - val_loss: 207.3454
Epoch 26/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 212.7994 - val_loss: 212.7969
Epoch 27/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 212.1150 - val_loss: 212.8386
Epoch 28/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 211.6003 - val_loss: 209.9572
Epoch 29/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 211.0495 - val_loss: 207.4056
Epoch 30/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 210.5822 - val_loss: 204.1522
Epoch 31/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 210.0522 - val_loss: 203.7322
Epoch 32/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 209.6931 - val_loss: 204.7180
Epoch 33/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 209.2566 - val_loss: 220.7110
Epoch 34/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 208.7092 - val_loss: 212.8161
Epoch 35/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 208.7030 - val_loss: 209.7050
Epoch 36/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 207.9419 - val_loss: 205.2235
Epoch 37/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 207.7182 - val_loss: 204.5124
Epoch 38/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 207.3013 - val_loss: 203.3615
Epoch 39/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 206.9133 - val_loss: 210.6223
Epoch 40/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 206.3820 - val_loss: 201.2406

         CHILD ACCURACY = 202.7897110871526


         PARENT ACCURACY = 259.74142576998975


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 2 <<<<<<<<<<<<<<<<<<<<<<<<<<<


                         ********** BEST MODEL SAVED | EPOCHS = 40 | BATCH_SIZE = 3000 | ACCURACY = 202.7897110871526 ********




 CHILD 3 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 4000

         EPOCHS = 30
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/30
2018-11-10 13:10:58.525387: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 13:10:58.530330: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 29s 3us/step - loss: 291.5593 - val_loss: 276.2218
Epoch 2/30
9445953/9445953 [==============================] - 28s 3us/step - loss: 274.8623 - val_loss: 279.6643
Epoch 3/30
9445953/9445953 [==============================] - 29s 3us/step - loss: 271.4181 - val_loss: 265.7098
Epoch 4/30
9445953/9445953 [==============================] - 29s 3us/step - loss: 261.8576 - val_loss: 253.0588
Epoch 5/30
9445953/9445953 [==============================] - 28s 3us/step - loss: 253.1029 - val_loss: 249.0737
Epoch 6/30
9445953/9445953 [==============================] - 28s 3us/step - loss: 248.0584 - val_loss: 242.7325
Epoch 7/30
9445953/9445953 [==============================] - 28s 3us/step - loss: 244.6503 - val_loss: 242.4612
Epoch 8/30
9445953/9445953 [==============================] - 28s 3us/step - loss: 241.6244 - val_loss: 252.7082
Epoch 9/30
9445953/9445953 [==============================] - 29s 3us/step - loss: 238.9707 - val_loss: 237.0468
Epoch 10/30
9445953/9445953 [==============================] - 28s 3us/step - loss: 236.1563 - val_loss: 236.5294
Epoch 11/30
9445953/9445953 [==============================] - 29s 3us/step - loss: 233.3516 - val_loss: 229.4855
Epoch 12/30
9445953/9445953 [==============================] - 28s 3us/step - loss: 230.7573 - val_loss: 226.0133
Epoch 13/30
9445953/9445953 [==============================] - 29s 3us/step - loss: 228.5177 - val_loss: 222.9765
Epoch 14/30
9445953/9445953 [==============================] - 28s 3us/step - loss: 226.4218 - val_loss: 227.7456
Epoch 15/30
9445953/9445953 [==============================] - 29s 3us/step - loss: 225.0489 - val_loss: 220.9380
Epoch 16/30
9445953/9445953 [==============================] - 29s 3us/step - loss: 223.4285 - val_loss: 217.6790
Epoch 17/30
9445953/9445953 [==============================] - 28s 3us/step - loss: 222.1502 - val_loss: 223.7599
Epoch 18/30
9445953/9445953 [==============================] - 28s 3us/step - loss: 220.9016 - val_loss: 224.2797
Epoch 19/30
9445953/9445953 [==============================] - 28s 3us/step - loss: 219.8036 - val_loss: 215.0737
Epoch 20/30
9445953/9445953 [==============================] - 28s 3us/step - loss: 218.9022 - val_loss: 214.3482
Epoch 21/30
9445953/9445953 [==============================] - 29s 3us/step - loss: 217.9957 - val_loss: 215.3069
Epoch 22/30
9445953/9445953 [==============================] - 29s 3us/step - loss: 217.0554 - val_loss: 233.6852
Epoch 23/30
9445953/9445953 [==============================] - 28s 3us/step - loss: 216.1466 - val_loss: 223.4970
Epoch 24/30
9445953/9445953 [==============================] - 28s 3us/step - loss: 215.3095 - val_loss: 222.7164
Epoch 25/30
9445953/9445953 [==============================] - 29s 3us/step - loss: 214.5390 - val_loss: 213.5403
Epoch 26/30
9445953/9445953 [==============================] - 28s 3us/step - loss: 213.8691 - val_loss: 213.2850
Epoch 27/30
9445953/9445953 [==============================] - 28s 3us/step - loss: 213.3146 - val_loss: 224.1566
Epoch 28/30
9445953/9445953 [==============================] - 28s 3us/step - loss: 212.6285 - val_loss: 218.1433
Epoch 29/30
9445953/9445953 [==============================] - 28s 3us/step - loss: 211.9235 - val_loss: 212.2537
Epoch 30/30
9445953/9445953 [==============================] - 29s 3us/step - loss: 211.4235 - val_loss: 212.0642

         CHILD ACCURACY = 220.9863997878874


         PARENT ACCURACY = 259.74142576998975


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 3 <<<<<<<<<<<<<<<<<<<<<<<<<<<


 CHILD 4 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 4000

         EPOCHS = 40
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/40
2018-11-10 13:25:13.870380: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 13:25:13.875390: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 29s 3us/step - loss: 297.2359 - val_loss: 274.9479
Epoch 2/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 274.7882 - val_loss: 270.9357
Epoch 3/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 268.9471 - val_loss: 260.9635
Epoch 4/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 260.0776 - val_loss: 263.1612
Epoch 5/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 253.9047 - val_loss: 250.6693
Epoch 6/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 249.5191 - val_loss: 244.4487
Epoch 7/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 246.1811 - val_loss: 240.2867
Epoch 8/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 243.3546 - val_loss: 243.0748
Epoch 9/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 240.9362 - val_loss: 238.3148
Epoch 10/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 238.6180 - val_loss: 233.8189
Epoch 11/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 236.2047 - val_loss: 241.7547
Epoch 12/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 233.7981 - val_loss: 229.4557
Epoch 13/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 231.5336 - val_loss: 229.4583
Epoch 14/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 229.4331 - val_loss: 232.2927
Epoch 15/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 227.5228 - val_loss: 226.2911
Epoch 16/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 226.0175 - val_loss: 225.7627
Epoch 17/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 224.6047 - val_loss: 218.3122
Epoch 18/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 223.4778 - val_loss: 223.0372
Epoch 19/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 222.2931 - val_loss: 219.0278
Epoch 20/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 221.1756 - val_loss: 222.4446
Epoch 21/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 220.1711 - val_loss: 215.0671
Epoch 22/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 219.4708 - val_loss: 215.7744
Epoch 23/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 218.4905 - val_loss: 215.6915
Epoch 24/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 217.7705 - val_loss: 212.2299
Epoch 25/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 217.1474 - val_loss: 223.0886
Epoch 26/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 216.3520 - val_loss: 217.4113
Epoch 27/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 215.7548 - val_loss: 222.4912
Epoch 28/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 215.0816 - val_loss: 216.9923
Epoch 29/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 214.5427 - val_loss: 218.6528
Epoch 30/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 214.0192 - val_loss: 209.0159
Epoch 31/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 213.3775 - val_loss: 211.4928
Epoch 32/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 212.9235 - val_loss: 218.0215
Epoch 33/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 212.5523 - val_loss: 209.3721
Epoch 34/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 211.9246 - val_loss: 218.3683
Epoch 35/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 211.5408 - val_loss: 205.1947
Epoch 36/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 211.2741 - val_loss: 217.6016
Epoch 37/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 210.5802 - val_loss: 208.6147
Epoch 38/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 210.2576 - val_loss: 208.5867
Epoch 39/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 209.8483 - val_loss: 216.3796
Epoch 40/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 209.5662 - val_loss: 215.0397

         CHILD ACCURACY = 214.24724719783927


         PARENT ACCURACY = 259.74142576998975


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 4 <<<<<<<<<<<<<<<<<<<<<<<<<<<


 CHILD 5 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 30
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/30
2018-11-10 13:44:12.636723: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 13:44:12.642481: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 26s 3us/step - loss: 301.3934 - val_loss: 275.2739
Epoch 2/30
9445953/9445953 [==============================] - 26s 3us/step - loss: 273.1999 - val_loss: 268.5999
Epoch 3/30
9445953/9445953 [==============================] - 26s 3us/step - loss: 264.0126 - val_loss: 261.6418
Epoch 4/30
9445953/9445953 [==============================] - 26s 3us/step - loss: 256.5232 - val_loss: 257.1708
Epoch 5/30
9445953/9445953 [==============================] - 26s 3us/step - loss: 251.1117 - val_loss: 265.8854
Epoch 6/30
9445953/9445953 [==============================] - 26s 3us/step - loss: 247.1959 - val_loss: 245.0539
Epoch 7/30
9445953/9445953 [==============================] - 26s 3us/step - loss: 243.8087 - val_loss: 244.7226
Epoch 8/30
9445953/9445953 [==============================] - 26s 3us/step - loss: 241.0793 - val_loss: 260.6417
Epoch 9/30
9445953/9445953 [==============================] - 26s 3us/step - loss: 238.7741 - val_loss: 241.7527
Epoch 10/30
9445953/9445953 [==============================] - 26s 3us/step - loss: 236.5550 - val_loss: 232.2412
Epoch 11/30
9445953/9445953 [==============================] - 26s 3us/step - loss: 234.5289 - val_loss: 230.8709
Epoch 12/30
9445953/9445953 [==============================] - 26s 3us/step - loss: 232.1547 - val_loss: 241.3531
Epoch 13/30
9445953/9445953 [==============================] - 31s 3us/step - loss: 229.8722 - val_loss: 231.0166
Epoch 14/30
9445953/9445953 [==============================] - 30s 3us/step - loss: 227.7560 - val_loss: 229.4603
Epoch 15/30
9445953/9445953 [==============================] - 30s 3us/step - loss: 225.8421 - val_loss: 224.6373
Epoch 16/30
9445953/9445953 [==============================] - 29s 3us/step - loss: 224.3626 - val_loss: 223.9208
Epoch 17/30
9445953/9445953 [==============================] - 29s 3us/step - loss: 222.9660 - val_loss: 246.8860
Epoch 18/30
9445953/9445953 [==============================] - 28s 3us/step - loss: 221.7982 - val_loss: 224.9997
Epoch 19/30
9445953/9445953 [==============================] - 33s 4us/step - loss: 220.6258 - val_loss: 218.2060
Epoch 20/30
9445953/9445953 [==============================] - 34s 4us/step - loss: 219.4673 - val_loss: 231.5658
Epoch 21/30
9445953/9445953 [==============================] - 31s 3us/step - loss: 218.7138 - val_loss: 218.9662
Epoch 22/30
9445953/9445953 [==============================] - 28s 3us/step - loss: 217.8283 - val_loss: 250.9471
Epoch 23/30
9445953/9445953 [==============================] - 29s 3us/step - loss: 216.9653 - val_loss: 231.3068
Epoch 24/30
9445953/9445953 [==============================] - 32s 3us/step - loss: 216.2219 - val_loss: 226.2943
Epoch 25/30
9445953/9445953 [==============================] - 33s 3us/step - loss: 215.4117 - val_loss: 242.3763
Epoch 26/30
9445953/9445953 [==============================] - 32s 3us/step - loss: 214.6726 - val_loss: 220.2818
Epoch 27/30
9445953/9445953 [==============================] - 30s 3us/step - loss: 214.1700 - val_loss: 215.2545
Epoch 28/30
9445953/9445953 [==============================] - 30s 3us/step - loss: 213.2400 - val_loss: 230.8899
Epoch 29/30
9445953/9445953 [==============================] - 31s 3us/step - loss: 212.7053 - val_loss: 215.2024
Epoch 30/30
9445953/9445953 [==============================] - 35s 4us/step - loss: 212.1282 - val_loss: 213.2934

         CHILD ACCURACY = 224.25919626063197


         PARENT ACCURACY = 259.74142576998975


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 5 <<<<<<<<<<<<<<<<<<<<<<<<<<<


 CHILD 6 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 35
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/35
2018-11-10 13:58:41.045663: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 13:58:41.050139: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 38s 4us/step - loss: 302.3712 - val_loss: 276.4285
Epoch 2/35
9445953/9445953 [==============================] - 34s 4us/step - loss: 275.4192 - val_loss: 273.1819
Epoch 3/35
9445953/9445953 [==============================] - 32s 3us/step - loss: 267.1740 - val_loss: 265.2839
Epoch 4/35
9445953/9445953 [==============================] - 35s 4us/step - loss: 258.7088 - val_loss: 252.4505
Epoch 5/35
9445953/9445953 [==============================] - 31s 3us/step - loss: 252.6825 - val_loss: 259.6288
Epoch 6/35
9445953/9445953 [==============================] - 34s 4us/step - loss: 248.1196 - val_loss: 246.3394
Epoch 7/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 244.5301 - val_loss: 248.5335
Epoch 8/35
9445953/9445953 [==============================] - 27s 3us/step - loss: 241.5660 - val_loss: 238.8010
Epoch 9/35
9445953/9445953 [==============================] - 30s 3us/step - loss: 238.8575 - val_loss: 238.4509
Epoch 10/35
9445953/9445953 [==============================] - 29s 3us/step - loss: 236.0153 - val_loss: 250.6033
Epoch 11/35
9445953/9445953 [==============================] - 27s 3us/step - loss: 233.3019 - val_loss: 244.6318
Epoch 12/35
9445953/9445953 [==============================] - 26s 3us/step - loss: 230.7393 - val_loss: 234.4664
Epoch 13/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 228.4421 - val_loss: 228.3413
Epoch 14/35
9445953/9445953 [==============================] - 26s 3us/step - loss: 226.4020 - val_loss: 223.3805
Epoch 15/35
9445953/9445953 [==============================] - 26s 3us/step - loss: 224.8465 - val_loss: 223.4582
Epoch 16/35
9445953/9445953 [==============================] - 26s 3us/step - loss: 223.2318 - val_loss: 222.2056
Epoch 17/35
9445953/9445953 [==============================] - 26s 3us/step - loss: 221.9434 - val_loss: 225.5633
Epoch 18/35
9445953/9445953 [==============================] - 26s 3us/step - loss: 221.0078 - val_loss: 227.6098
Epoch 19/35
9445953/9445953 [==============================] - 26s 3us/step - loss: 219.6737 - val_loss: 235.5408
Epoch 20/35
9445953/9445953 [==============================] - 26s 3us/step - loss: 218.7802 - val_loss: 215.1380
Epoch 21/35
9445953/9445953 [==============================] - 26s 3us/step - loss: 217.9423 - val_loss: 221.9234
Epoch 22/35
9445953/9445953 [==============================] - 26s 3us/step - loss: 217.2496 - val_loss: 243.6936
Epoch 23/35
9445953/9445953 [==============================] - 26s 3us/step - loss: 216.4127 - val_loss: 217.9101
Epoch 24/35
9445953/9445953 [==============================] - 25s 3us/step - loss: 215.8360 - val_loss: 211.8858
Epoch 25/35
9445953/9445953 [==============================] - 26s 3us/step - loss: 215.1832 - val_loss: 227.8066
Epoch 26/35
9445953/9445953 [==============================] - 26s 3us/step - loss: 214.4236 - val_loss: 254.6490
Epoch 27/35
9445953/9445953 [==============================] - 26s 3us/step - loss: 213.8428 - val_loss: 211.0750
Epoch 28/35
9445953/9445953 [==============================] - 26s 3us/step - loss: 213.1872 - val_loss: 213.0784
Epoch 29/35
9445953/9445953 [==============================] - 26s 3us/step - loss: 212.5855 - val_loss: 214.9421
Epoch 30/35
9445953/9445953 [==============================] - 26s 3us/step - loss: 212.2511 - val_loss: 219.2326
Epoch 31/35
9445953/9445953 [==============================] - 25s 3us/step - loss: 211.5380 - val_loss: 229.2640
Epoch 32/35
9445953/9445953 [==============================] - 26s 3us/step - loss: 211.0779 - val_loss: 213.6222
Epoch 33/35
9445953/9445953 [==============================] - 26s 3us/step - loss: 210.5153 - val_loss: 220.6651
Epoch 34/35
9445953/9445953 [==============================] - 26s 3us/step - loss: 210.2148 - val_loss: 216.1408
Epoch 35/35
9445953/9445953 [==============================] - 26s 3us/step - loss: 209.7814 - val_loss: 225.0278

         CHILD ACCURACY = 227.3305637256194


         PARENT ACCURACY = 259.74142576998975


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 6 <<<<<<<<<<<<<<<<<<<<<<<<<<<


 CHILD 7 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 40
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/40
2018-11-10 14:14:44.553181: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 14:14:44.558368: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 26s 3us/step - loss: 297.9677 - val_loss: 282.1896
Epoch 2/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 275.2643 - val_loss: 275.8804
Epoch 3/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 265.4041 - val_loss: 271.0823
Epoch 4/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 257.3569 - val_loss: 254.8495
Epoch 5/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 251.5963 - val_loss: 252.3165
Epoch 6/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 247.4952 - val_loss: 244.8614
Epoch 7/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 243.9543 - val_loss: 238.8141
Epoch 8/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 241.5195 - val_loss: 240.2929
Epoch 9/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 238.9037 - val_loss: 242.9808
Epoch 10/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 236.3272 - val_loss: 237.7691
Epoch 11/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 233.4190 - val_loss: 235.4239
Epoch 12/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 230.2561 - val_loss: 230.8976
Epoch 13/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 227.7614 - val_loss: 224.3348
Epoch 14/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 225.6524 - val_loss: 233.5721
Epoch 15/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 223.9347 - val_loss: 225.1574
Epoch 16/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 222.4732 - val_loss: 258.6232
Epoch 17/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 221.3035 - val_loss: 237.6046
Epoch 18/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 220.0578 - val_loss: 229.8107
Epoch 19/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 219.0643 - val_loss: 224.1530
Epoch 20/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 218.0885 - val_loss: 221.1353
Epoch 21/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 217.2374 - val_loss: 214.2260
Epoch 22/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 216.0826 - val_loss: 219.4524
Epoch 23/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 215.5145 - val_loss: 227.4144
Epoch 24/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 214.8644 - val_loss: 232.9730
Epoch 25/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 214.1490 - val_loss: 220.2113
Epoch 26/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 213.4467 - val_loss: 214.0722
Epoch 27/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 212.9246 - val_loss: 214.4988
Epoch 28/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 212.2905 - val_loss: 223.7614
Epoch 29/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 211.6845 - val_loss: 220.7953
Epoch 30/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 211.2063 - val_loss: 212.2781
Epoch 31/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 210.9707 - val_loss: 224.4177
Epoch 32/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 210.2813 - val_loss: 212.0285
Epoch 33/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 209.7803 - val_loss: 213.7801
Epoch 34/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 209.3871 - val_loss: 211.8951
Epoch 35/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 208.9022 - val_loss: 206.2154
Epoch 36/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 208.4465 - val_loss: 208.9067
Epoch 37/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 207.9885 - val_loss: 211.7402
Epoch 38/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 207.6810 - val_loss: 220.6938
Epoch 39/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 207.3478 - val_loss: 206.3886
Epoch 40/40
9445953/9445953 [==============================] - 27s 3us/step - loss: 206.9731 - val_loss: 219.6035

         CHILD ACCURACY = 221.71544072299713


         PARENT ACCURACY = 259.74142576998975


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 7 <<<<<<<<<<<<<<<<<<<<<<<<<<<


 CHILD 8 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 3000

         EPOCHS = 30
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/30
2018-11-10 14:31:56.151954: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 14:31:56.156487: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 288.5004 - val_loss: 275.4951
Epoch 2/30
9445953/9445953 [==============================] - 33s 4us/step - loss: 268.9582 - val_loss: 259.9978
Epoch 3/30
9445953/9445953 [==============================] - 33s 3us/step - loss: 257.9229 - val_loss: 252.3170
Epoch 4/30
9445953/9445953 [==============================] - 33s 4us/step - loss: 251.1621 - val_loss: 248.1195
Epoch 5/30
9445953/9445953 [==============================] - 33s 4us/step - loss: 246.7330 - val_loss: 242.2301
Epoch 6/30
9445953/9445953 [==============================] - 33s 3us/step - loss: 243.5581 - val_loss: 237.2639
Epoch 7/30
9445953/9445953 [==============================] - 33s 3us/step - loss: 241.0553 - val_loss: 239.3252
Epoch 8/30
9445953/9445953 [==============================] - 33s 4us/step - loss: 238.8144 - val_loss: 234.0811
Epoch 9/30
9445953/9445953 [==============================] - 33s 3us/step - loss: 236.4220 - val_loss: 231.8822
Epoch 10/30
9445953/9445953 [==============================] - 33s 3us/step - loss: 233.5792 - val_loss: 228.0993
Epoch 11/30
9445953/9445953 [==============================] - 33s 4us/step - loss: 230.6736 - val_loss: 225.3848
Epoch 12/30
9445953/9445953 [==============================] - 33s 4us/step - loss: 227.9594 - val_loss: 224.1373
Epoch 13/30
9445953/9445953 [==============================] - 33s 3us/step - loss: 225.9296 - val_loss: 219.8656
Epoch 14/30
9445953/9445953 [==============================] - 33s 4us/step - loss: 223.8798 - val_loss: 217.6730
Epoch 15/30
9445953/9445953 [==============================] - 33s 4us/step - loss: 222.2070 - val_loss: 221.4679
Epoch 16/30
9445953/9445953 [==============================] - 33s 3us/step - loss: 220.8582 - val_loss: 226.8277
Epoch 17/30
9445953/9445953 [==============================] - 33s 3us/step - loss: 219.3950 - val_loss: 213.9480
Epoch 18/30
9445953/9445953 [==============================] - 33s 3us/step - loss: 218.2965 - val_loss: 214.6559
Epoch 19/30
9445953/9445953 [==============================] - 33s 4us/step - loss: 217.2298 - val_loss: 214.7461
Epoch 20/30
9445953/9445953 [==============================] - 33s 3us/step - loss: 216.1202 - val_loss: 213.0932
Epoch 21/30
9445953/9445953 [==============================] - 33s 4us/step - loss: 215.4951 - val_loss: 212.9498
Epoch 22/30
9445953/9445953 [==============================] - 33s 3us/step - loss: 214.5958 - val_loss: 209.9704
Epoch 23/30
9445953/9445953 [==============================] - 33s 4us/step - loss: 213.6930 - val_loss: 212.3253
Epoch 24/30
9445953/9445953 [==============================] - 33s 3us/step - loss: 212.8701 - val_loss: 229.3142
Epoch 25/30
9445953/9445953 [==============================] - 33s 3us/step - loss: 212.2220 - val_loss: 217.7518
Epoch 26/30
9445953/9445953 [==============================] - 33s 4us/step - loss: 211.4622 - val_loss: 213.2111
Epoch 27/30
9445953/9445953 [==============================] - 33s 4us/step - loss: 211.0665 - val_loss: 218.0862
Epoch 28/30
9445953/9445953 [==============================] - 33s 3us/step - loss: 210.1961 - val_loss: 209.6970
Epoch 29/30
9445953/9445953 [==============================] - 33s 4us/step - loss: 209.5407 - val_loss: 209.8802
Epoch 30/30
9445953/9445953 [==============================] - 33s 3us/step - loss: 209.1165 - val_loss: 219.4191

         CHILD ACCURACY = 218.56126093771417


         PARENT ACCURACY = 259.74142576998975


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 8 <<<<<<<<<<<<<<<<<<<<<<<<<<<



 QUEUE SIZE BEFORE GET = 8


 NODE SELECTED <<<------ Epochs = 40 -------- BatchSize = 3000 --------- Accuracy = 202.7897110871526 -------->>>


 CHILD 1 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 3000

         EPOCHS = 45
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-11-10 14:48:29.568940: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 14:48:29.574110: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 300.5946 - val_loss: 279.2620
Epoch 2/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 274.5410 - val_loss: 268.2501
Epoch 3/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 264.6838 - val_loss: 255.7301
Epoch 4/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 256.2505 - val_loss: 248.9113
Epoch 5/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 251.1230 - val_loss: 253.0446
Epoch 6/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 247.5316 - val_loss: 244.0168
Epoch 7/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 244.5419 - val_loss: 239.1992
Epoch 8/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 241.8869 - val_loss: 237.6850
Epoch 9/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 239.3255 - val_loss: 234.6743
Epoch 10/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 236.5823 - val_loss: 231.0825
Epoch 11/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 233.5798 - val_loss: 230.4960
Epoch 12/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 231.1387 - val_loss: 234.0974
Epoch 13/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 229.2120 - val_loss: 226.6614
Epoch 14/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 227.5024 - val_loss: 221.7611
Epoch 15/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 226.0345 - val_loss: 222.2022
Epoch 16/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 224.6253 - val_loss: 222.0179
Epoch 17/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 223.5264 - val_loss: 216.5878
Epoch 18/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 222.4577 - val_loss: 216.6668
Epoch 19/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 221.2845 - val_loss: 219.5075
Epoch 20/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 220.4349 - val_loss: 214.5498
Epoch 21/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 219.6184 - val_loss: 221.9175
Epoch 22/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 218.7768 - val_loss: 213.8616
Epoch 23/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 218.1368 - val_loss: 213.6078
Epoch 24/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 217.5043 - val_loss: 218.6568
Epoch 25/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 216.7501 - val_loss: 218.7321
Epoch 26/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 216.1783 - val_loss: 215.9500
Epoch 27/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 215.4735 - val_loss: 211.9804
Epoch 28/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 214.9724 - val_loss: 221.7329
Epoch 29/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 214.4708 - val_loss: 208.3545
Epoch 30/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 213.9684 - val_loss: 207.5727
Epoch 31/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 213.3136 - val_loss: 212.6739
Epoch 32/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 212.8763 - val_loss: 212.7995
Epoch 33/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 212.4960 - val_loss: 212.4460
Epoch 34/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 212.1039 - val_loss: 205.6067
Epoch 35/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 211.6715 - val_loss: 216.8505
Epoch 36/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 211.3363 - val_loss: 211.2533
Epoch 37/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 210.8091 - val_loss: 206.3766
Epoch 38/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 210.4407 - val_loss: 207.0511
Epoch 39/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 210.1994 - val_loss: 216.4039
Epoch 40/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 209.6018 - val_loss: 207.3424
Epoch 41/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 209.4631 - val_loss: 207.0670
Epoch 42/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 209.1580 - val_loss: 210.6028
Epoch 43/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 208.9163 - val_loss: 209.2029
Epoch 44/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 208.6642 - val_loss: 206.3542
Epoch 45/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 208.2719 - val_loss: 212.7521

         CHILD ACCURACY = 210.70342528839916


         PARENT ACCURACY = 202.7897110871526


 CHILD 2 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 4000

         EPOCHS = 35
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/35
2018-11-10 15:13:16.311509: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 15:13:16.316586: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 29s 3us/step - loss: 295.4046 - val_loss: 274.4640
Epoch 2/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 274.0625 - val_loss: 269.4236
Epoch 3/35
9445953/9445953 [==============================] - 29s 3us/step - loss: 264.1644 - val_loss: 274.3110
Epoch 4/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 256.0534 - val_loss: 266.7413
Epoch 5/35
9445953/9445953 [==============================] - 29s 3us/step - loss: 250.7036 - val_loss: 245.4772
Epoch 6/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 246.7557 - val_loss: 243.4418
Epoch 7/35
9445953/9445953 [==============================] - 29s 3us/step - loss: 243.8385 - val_loss: 240.2019
Epoch 8/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 241.4637 - val_loss: 236.5183
Epoch 9/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 239.0459 - val_loss: 243.2590
Epoch 10/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 236.7052 - val_loss: 235.4798
Epoch 11/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 233.7797 - val_loss: 227.7085
Epoch 12/35
9445953/9445953 [==============================] - 29s 3us/step - loss: 230.8444 - val_loss: 236.2562
Epoch 13/35
9445953/9445953 [==============================] - 29s 3us/step - loss: 228.7093 - val_loss: 222.8403
Epoch 14/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 226.6677 - val_loss: 220.9668
Epoch 15/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 224.8614 - val_loss: 238.6139
Epoch 16/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 223.5434 - val_loss: 216.5991
Epoch 17/35
9445953/9445953 [==============================] - 29s 3us/step - loss: 222.1894 - val_loss: 216.0144
Epoch 18/35
9445953/9445953 [==============================] - 29s 3us/step - loss: 220.9941 - val_loss: 216.4108
Epoch 19/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 219.9617 - val_loss: 215.6548
Epoch 20/35
9445953/9445953 [==============================] - 29s 3us/step - loss: 218.9601 - val_loss: 233.1605
Epoch 21/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 218.3076 - val_loss: 218.5668
Epoch 22/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 217.1714 - val_loss: 227.9468
Epoch 23/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 216.3553 - val_loss: 221.3398
Epoch 24/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 215.7163 - val_loss: 210.4557
Epoch 25/35
9445953/9445953 [==============================] - 29s 3us/step - loss: 216.2632 - val_loss: 213.1845
Epoch 26/35
9445953/9445953 [==============================] - 29s 3us/step - loss: 215.5830 - val_loss: 216.1113
Epoch 27/35
9445953/9445953 [==============================] - 29s 3us/step - loss: 214.1715 - val_loss: 211.7118
Epoch 28/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 213.3579 - val_loss: 213.8431
Epoch 29/35
9445953/9445953 [==============================] - 29s 3us/step - loss: 212.5786 - val_loss: 205.0940
Epoch 30/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 212.1033 - val_loss: 223.0749
Epoch 31/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 211.5866 - val_loss: 226.8143
Epoch 32/35
9445953/9445953 [==============================] - 29s 3us/step - loss: 211.0262 - val_loss: 209.1613
Epoch 33/35
9445953/9445953 [==============================] - 29s 3us/step - loss: 210.3930 - val_loss: 208.0799
Epoch 34/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 209.8754 - val_loss: 205.9206
Epoch 35/35
9445953/9445953 [==============================] - 29s 3us/step - loss: 209.6141 - val_loss: 210.0519

         CHILD ACCURACY = 206.3797274445755


         PARENT ACCURACY = 202.7897110871526


 CHILD 3 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 2000

         EPOCHS = 45
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-11-10 15:29:54.371216: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 15:29:54.377858: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 43s 5us/step - loss: 286.3721 - val_loss: 268.9023
Epoch 2/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 263.8374 - val_loss: 254.6846
Epoch 3/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 255.0829 - val_loss: 250.8665
Epoch 4/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 249.9058 - val_loss: 245.7943
Epoch 5/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 246.1269 - val_loss: 243.2413
Epoch 6/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 242.8814 - val_loss: 237.7492
Epoch 7/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 239.8528 - val_loss: 236.1658
Epoch 8/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 236.8440 - val_loss: 235.1487
Epoch 9/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 234.0391 - val_loss: 235.9578
Epoch 10/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 231.4047 - val_loss: 229.7058
Epoch 11/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 229.2652 - val_loss: 224.0243
Epoch 12/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 227.4736 - val_loss: 228.9964
Epoch 13/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 225.8197 - val_loss: 222.0428
Epoch 14/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 224.6058 - val_loss: 223.0259
Epoch 15/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 223.3398 - val_loss: 222.7046
Epoch 16/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 222.2350 - val_loss: 221.1610
Epoch 17/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 221.1075 - val_loss: 219.4824
Epoch 18/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 220.3152 - val_loss: 216.1108
Epoch 19/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 219.2103 - val_loss: 213.8198
Epoch 20/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 218.4467 - val_loss: 211.7258
Epoch 21/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 217.4933 - val_loss: 212.9159
Epoch 22/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 216.9137 - val_loss: 220.1249
Epoch 23/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 216.3478 - val_loss: 215.7979
Epoch 24/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 215.4634 - val_loss: 210.1406
Epoch 25/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 214.8939 - val_loss: 213.4115
Epoch 26/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 214.4241 - val_loss: 210.9078
Epoch 27/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 213.9486 - val_loss: 210.4357
Epoch 28/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 213.2812 - val_loss: 212.7899
Epoch 29/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 212.7791 - val_loss: 211.7899
Epoch 30/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 212.2594 - val_loss: 210.5659
Epoch 31/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 211.6802 - val_loss: 205.5949
Epoch 32/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 211.2836 - val_loss: 213.0986
Epoch 33/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 211.0566 - val_loss: 205.3936
Epoch 34/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 210.5144 - val_loss: 205.6922
Epoch 35/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 210.2137 - val_loss: 206.8529
Epoch 36/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 209.6643 - val_loss: 217.4825
Epoch 37/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 209.3893 - val_loss: 205.4071
Epoch 38/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 209.0025 - val_loss: 207.1600
Epoch 39/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 208.7253 - val_loss: 205.3946
Epoch 40/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 208.2147 - val_loss: 208.6135
Epoch 41/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 207.9617 - val_loss: 205.2417
Epoch 42/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 207.8019 - val_loss: 204.8423
Epoch 43/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 207.1531 - val_loss: 206.7195
Epoch 44/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 207.0948 - val_loss: 202.8944
Epoch 45/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 206.6995 - val_loss: 231.6017

         CHILD ACCURACY = 215.84163231177857


         PARENT ACCURACY = 202.7897110871526


 CHILD 4 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 2000

         EPOCHS = 35
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/35
2018-11-10 16:01:51.022517: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 16:01:51.027411: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 43s 5us/step - loss: 285.3923 - val_loss: 271.5294
Epoch 2/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 264.4114 - val_loss: 259.7150
Epoch 3/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 254.6256 - val_loss: 251.2305
Epoch 4/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 249.2271 - val_loss: 245.3579
Epoch 5/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 245.6028 - val_loss: 242.9015
Epoch 6/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 242.7929 - val_loss: 240.4520
Epoch 7/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 240.4411 - val_loss: 236.3803
Epoch 8/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 238.0696 - val_loss: 232.7167
Epoch 9/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 235.6438 - val_loss: 234.2700
Epoch 10/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 232.5491 - val_loss: 229.4260
Epoch 11/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 229.4733 - val_loss: 232.8941
Epoch 12/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 226.7906 - val_loss: 227.2997
Epoch 13/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 224.7432 - val_loss: 224.7687
Epoch 14/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 222.9113 - val_loss: 218.3196
Epoch 15/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 221.3599 - val_loss: 216.9898
Epoch 16/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 219.8193 - val_loss: 215.6414
Epoch 17/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 218.5816 - val_loss: 228.5771
Epoch 18/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 217.5533 - val_loss: 225.8243
Epoch 19/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 216.4105 - val_loss: 210.5777
Epoch 20/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 215.4273 - val_loss: 209.0787
Epoch 21/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 214.5794 - val_loss: 207.8021
Epoch 22/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 213.8431 - val_loss: 207.0377
Epoch 23/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 212.7668 - val_loss: 207.5014
Epoch 24/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 212.1594 - val_loss: 207.4575
Epoch 25/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 211.3178 - val_loss: 211.0462
Epoch 26/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 210.7532 - val_loss: 204.0725
Epoch 27/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 210.0792 - val_loss: 207.8621
Epoch 28/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 209.7260 - val_loss: 205.8235
Epoch 29/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 209.0127 - val_loss: 208.0594
Epoch 30/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 208.5154 - val_loss: 203.5785
Epoch 31/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 208.0861 - val_loss: 205.6829
Epoch 32/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 207.5390 - val_loss: 200.3915
Epoch 33/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 206.9022 - val_loss: 208.4182
Epoch 34/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 206.7328 - val_loss: 210.3573
Epoch 35/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 206.2816 - val_loss: 203.6496

         CHILD ACCURACY = 204.54440488061397


         PARENT ACCURACY = 202.7897110871526


 CHILD 5 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 2000

         EPOCHS = 40
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/40
2018-11-10 16:26:44.670347: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 16:26:44.675620: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 43s 5us/step - loss: 286.4092 - val_loss: 274.2897
Epoch 2/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 273.5390 - val_loss: 269.1488
Epoch 3/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 267.6454 - val_loss: 257.1551
Epoch 4/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 256.9595 - val_loss: 253.6941
Epoch 5/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 251.0543 - val_loss: 245.6105
Epoch 6/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 246.8980 - val_loss: 244.3461
Epoch 7/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 243.1270 - val_loss: 236.9201
Epoch 8/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 239.8316 - val_loss: 234.4294
Epoch 9/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 236.4990 - val_loss: 233.7384
Epoch 10/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 233.6852 - val_loss: 233.1886
Epoch 11/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 231.5230 - val_loss: 226.8372
Epoch 12/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 229.4131 - val_loss: 224.0181
Epoch 13/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 227.8858 - val_loss: 226.4193
Epoch 14/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 226.3818 - val_loss: 219.1998
Epoch 15/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 225.0265 - val_loss: 221.0621
Epoch 16/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 223.7232 - val_loss: 218.5420
Epoch 17/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 222.8727 - val_loss: 216.7670
Epoch 18/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 221.7292 - val_loss: 216.2885
Epoch 19/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 220.7603 - val_loss: 214.4635
Epoch 20/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 220.0231 - val_loss: 216.0509
Epoch 21/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 219.0921 - val_loss: 216.8810
Epoch 22/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 218.4776 - val_loss: 211.9762
Epoch 23/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 217.7549 - val_loss: 213.0301
Epoch 24/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 217.2666 - val_loss: 219.2645
Epoch 25/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 216.4598 - val_loss: 215.4101
Epoch 26/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 216.0270 - val_loss: 220.0189
Epoch 27/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 215.3883 - val_loss: 216.8842
Epoch 28/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 215.0483 - val_loss: 221.4887
Epoch 29/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 214.4854 - val_loss: 212.7287
Epoch 30/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 213.7605 - val_loss: 209.6039
Epoch 31/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 213.4819 - val_loss: 209.8993
Epoch 32/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 212.8954 - val_loss: 208.9184
Epoch 33/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 212.7404 - val_loss: 210.3887
Epoch 34/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 212.3166 - val_loss: 208.9752
Epoch 35/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 211.7776 - val_loss: 221.6931
Epoch 36/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 211.5905 - val_loss: 206.9212
Epoch 37/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 211.2480 - val_loss: 208.2064
Epoch 38/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 211.0661 - val_loss: 208.1769
Epoch 39/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 210.5073 - val_loss: 212.0764
Epoch 40/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 210.3455 - val_loss: 215.9469

         CHILD ACCURACY = 211.41156357204622


         PARENT ACCURACY = 202.7897110871526


 CHILD 6 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 4000

         EPOCHS = 45
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-11-10 16:54:54.966559: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 16:54:54.972530: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 29s 3us/step - loss: 293.1237 - val_loss: 277.0542
Epoch 2/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 273.4533 - val_loss: 267.5015
Epoch 3/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 264.6608 - val_loss: 255.4438
Epoch 4/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 256.0519 - val_loss: 254.9732
Epoch 5/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 250.6320 - val_loss: 251.0050
Epoch 6/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 246.6089 - val_loss: 248.2315
Epoch 7/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 243.5039 - val_loss: 241.5998
Epoch 8/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 240.9797 - val_loss: 238.2604
Epoch 9/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 238.7611 - val_loss: 238.8326
Epoch 10/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 236.8135 - val_loss: 236.4282
Epoch 11/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 234.9773 - val_loss: 231.8257
Epoch 12/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 233.0001 - val_loss: 230.7603
Epoch 13/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 230.4146 - val_loss: 228.0950
Epoch 14/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 227.8059 - val_loss: 240.4154
Epoch 15/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 225.5450 - val_loss: 225.2319
Epoch 16/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 223.6501 - val_loss: 218.6074
Epoch 17/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 222.1303 - val_loss: 238.6998
Epoch 18/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 220.6608 - val_loss: 222.6294
Epoch 19/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 219.3826 - val_loss: 237.0828
Epoch 20/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 218.2990 - val_loss: 213.8474
Epoch 21/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 217.2610 - val_loss: 221.0979
Epoch 22/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 216.2665 - val_loss: 227.9366
Epoch 23/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 215.4884 - val_loss: 209.2735
Epoch 24/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 214.4759 - val_loss: 215.5264
Epoch 25/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 213.7950 - val_loss: 210.8132
Epoch 26/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 213.1054 - val_loss: 216.9270
Epoch 27/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 212.4956 - val_loss: 208.6158
Epoch 28/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 211.7553 - val_loss: 218.6866
Epoch 29/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 211.0975 - val_loss: 210.9990
Epoch 30/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 210.5004 - val_loss: 205.5656
Epoch 31/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 209.9692 - val_loss: 212.4028
Epoch 32/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 209.3795 - val_loss: 208.8697
Epoch 33/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 208.8126 - val_loss: 203.8352
Epoch 34/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 208.3964 - val_loss: 205.3834
Epoch 35/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 207.8367 - val_loss: 219.1677
Epoch 36/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 207.3228 - val_loss: 207.3555
Epoch 37/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 206.9253 - val_loss: 212.9992
Epoch 38/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 206.6500 - val_loss: 201.7776
Epoch 39/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 206.2310 - val_loss: 207.8021
Epoch 40/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 205.6755 - val_loss: 208.5945
Epoch 41/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 205.3847 - val_loss: 203.5570
Epoch 42/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 204.9389 - val_loss: 204.5358
Epoch 43/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 204.6001 - val_loss: 202.0083
Epoch 44/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 204.1173 - val_loss: 211.6331
Epoch 45/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 203.8380 - val_loss: 203.7368

         CHILD ACCURACY = 206.58347410565037


         PARENT ACCURACY = 202.7897110871526



 QUEUE SIZE BEFORE GET = 7


 NODE SELECTED <<<------ Epochs = 40 -------- BatchSize = 4000 --------- Accuracy = 214.24724719783927 -------->>>


 CHILD 1 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 4000

         EPOCHS = 45
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-11-10 17:16:11.629835: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 17:16:11.635763: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 29s 3us/step - loss: 303.6715 - val_loss: 276.2022
Epoch 2/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 276.3535 - val_loss: 275.3394
Epoch 3/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 269.4155 - val_loss: 261.3848
Epoch 4/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 258.8448 - val_loss: 252.9318
Epoch 5/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 252.3255 - val_loss: 254.2132
Epoch 6/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 248.1955 - val_loss: 247.4653
Epoch 7/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 244.7469 - val_loss: 240.4418
Epoch 8/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 242.0853 - val_loss: 236.9714
Epoch 9/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 239.4342 - val_loss: 237.2734
Epoch 10/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 237.2122 - val_loss: 244.2340
Epoch 11/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 234.4996 - val_loss: 228.8053
Epoch 12/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 231.6186 - val_loss: 231.8391
Epoch 13/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 228.9124 - val_loss: 237.4476
Epoch 14/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 226.7458 - val_loss: 223.9108
Epoch 15/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 224.8397 - val_loss: 223.8544
Epoch 16/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 223.3249 - val_loss: 216.3162
Epoch 17/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 221.7925 - val_loss: 219.1410
Epoch 18/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 220.6952 - val_loss: 216.8873
Epoch 19/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 219.5758 - val_loss: 221.5924
Epoch 20/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 218.5356 - val_loss: 218.7236
Epoch 21/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 217.6795 - val_loss: 219.1257
Epoch 22/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 216.7852 - val_loss: 217.8973
Epoch 23/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 215.9883 - val_loss: 213.7412
Epoch 24/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 215.1981 - val_loss: 211.2783
Epoch 25/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 214.5167 - val_loss: 212.3034
Epoch 26/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 214.0646 - val_loss: 211.6374
Epoch 27/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 213.1310 - val_loss: 207.4573
Epoch 28/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 212.7688 - val_loss: 213.6890
Epoch 29/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 212.1257 - val_loss: 213.2962
Epoch 30/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 211.6046 - val_loss: 217.6174
Epoch 31/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 211.1290 - val_loss: 210.7893
Epoch 32/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 210.5918 - val_loss: 214.0986
Epoch 33/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 210.1424 - val_loss: 225.8563
Epoch 34/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 209.5914 - val_loss: 209.6308
Epoch 35/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 209.1104 - val_loss: 203.1530
Epoch 36/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 208.6420 - val_loss: 202.8212
Epoch 37/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 208.1784 - val_loss: 210.3598
Epoch 38/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 207.9045 - val_loss: 202.3671
Epoch 39/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 207.4831 - val_loss: 214.8886
Epoch 40/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 207.0883 - val_loss: 203.1600
Epoch 41/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 206.7951 - val_loss: 208.2100
Epoch 42/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 206.4309 - val_loss: 206.3289
Epoch 43/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 206.0656 - val_loss: 210.2620
Epoch 44/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 205.5333 - val_loss: 207.3291
Epoch 45/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 205.2800 - val_loss: 207.8365

         CHILD ACCURACY = 210.05081814239864


         PARENT ACCURACY = 214.24724719783927


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 7 <<<<<<<<<<<<<<<<<<<<<<<<<<<


 CHILD 2 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 40
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/40
2018-11-10 17:37:26.410899: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 17:37:26.416126: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 26s 3us/step - loss: 361.6661 - val_loss: 339.7689
Epoch 2/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 331.4576 - val_loss: 321.5450
Epoch 3/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 320.9752 - val_loss: 317.2748
Epoch 4/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3419 - val_loss: 317.0899
Epoch 5/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3031 - val_loss: 317.0907
Epoch 6/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0895
Epoch 7/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0919
Epoch 8/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3034 - val_loss: 317.0900
Epoch 9/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0896
Epoch 10/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0894
Epoch 11/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3033 - val_loss: 317.0893
Epoch 12/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3029 - val_loss: 317.0894
Epoch 13/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3031 - val_loss: 317.0908
Epoch 14/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3031 - val_loss: 317.0896
Epoch 15/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0898
Epoch 16/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0893
Epoch 17/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3031 - val_loss: 317.0894
Epoch 18/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0902
Epoch 19/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3030 - val_loss: 317.0895
Epoch 20/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3033 - val_loss: 317.0913
Epoch 21/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3033 - val_loss: 317.0905
Epoch 22/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3031 - val_loss: 317.0893
Epoch 23/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3033 - val_loss: 317.0907
Epoch 24/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0895
Epoch 25/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3031 - val_loss: 317.0910
Epoch 26/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0910
Epoch 27/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3033 - val_loss: 317.0919
Epoch 28/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3031 - val_loss: 317.0901
Epoch 29/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3034 - val_loss: 317.0898
Epoch 30/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3033 - val_loss: 317.0906
Epoch 31/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3031 - val_loss: 317.0923
Epoch 32/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3033 - val_loss: 317.0901
Epoch 33/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3033 - val_loss: 317.0914
Epoch 34/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0902
Epoch 35/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3033 - val_loss: 317.0895
Epoch 36/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0894
Epoch 37/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0894
Epoch 38/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0896
Epoch 39/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0898
Epoch 40/40
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0900

         CHILD ACCURACY = 314.87614944282114


         PARENT ACCURACY = 214.24724719783927


 CHILD 3 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 3000

         EPOCHS = 45
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-11-10 17:54:22.793627: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 17:54:22.799129: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 33s 4us/step - loss: 291.1407 - val_loss: 272.9120
Epoch 2/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 267.6271 - val_loss: 258.3258
Epoch 3/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 257.3211 - val_loss: 249.7920
Epoch 4/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 250.7229 - val_loss: 246.8755
Epoch 5/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 246.3001 - val_loss: 242.4721
Epoch 6/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 243.0854 - val_loss: 241.0063
Epoch 7/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 239.9794 - val_loss: 234.1241
Epoch 8/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 236.8896 - val_loss: 231.3482
Epoch 9/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 233.5475 - val_loss: 230.6987
Epoch 10/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 230.2080 - val_loss: 226.6855
Epoch 11/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 227.8565 - val_loss: 222.5507
Epoch 12/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 225.7831 - val_loss: 226.3404
Epoch 13/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 224.2342 - val_loss: 219.1153
Epoch 14/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 222.8296 - val_loss: 217.4201
Epoch 15/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 221.5093 - val_loss: 216.0568
Epoch 16/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 220.2395 - val_loss: 219.1033
Epoch 17/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 219.2823 - val_loss: 218.4518
Epoch 18/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 218.1591 - val_loss: 214.9629
Epoch 19/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 217.2424 - val_loss: 214.4887
Epoch 20/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 216.5076 - val_loss: 216.6615
Epoch 21/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 215.4997 - val_loss: 211.2490
Epoch 22/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 214.9059 - val_loss: 219.5158
Epoch 23/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 214.0042 - val_loss: 214.2982
Epoch 24/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 213.2185 - val_loss: 209.8809
Epoch 25/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 212.7277 - val_loss: 219.3470
Epoch 26/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 212.1788 - val_loss: 207.0061
Epoch 27/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 211.5124 - val_loss: 207.9546
Epoch 28/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 210.8893 - val_loss: 229.6089
Epoch 29/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 210.3190 - val_loss: 209.3051
Epoch 30/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 209.8952 - val_loss: 204.5181
Epoch 31/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 209.1521 - val_loss: 215.7551
Epoch 32/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 208.9186 - val_loss: 205.9547
Epoch 33/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 208.4995 - val_loss: 203.3941
Epoch 34/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 208.0619 - val_loss: 210.5428
Epoch 35/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 207.5194 - val_loss: 206.7127
Epoch 36/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 207.0537 - val_loss: 207.2819
Epoch 37/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 206.7741 - val_loss: 202.2835
Epoch 38/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 206.4588 - val_loss: 204.2972
Epoch 39/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 206.1257 - val_loss: 206.1289
Epoch 40/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 205.7567 - val_loss: 206.2446
Epoch 41/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 205.3372 - val_loss: 200.1629
Epoch 42/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 205.4889 - val_loss: 210.4701
Epoch 43/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 204.8706 - val_loss: 204.0983
Epoch 44/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 204.2115 - val_loss: 201.7903
Epoch 45/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 204.0994 - val_loss: 198.6619

         CHILD ACCURACY = 202.84271243458215


         PARENT ACCURACY = 214.24724719783927


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 8 <<<<<<<<<<<<<<<<<<<<<<<<<<<


 CHILD 4 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 45
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-11-10 18:19:04.940649: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 18:19:04.946601: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 26s 3us/step - loss: 300.6989 - val_loss: 281.8094
Epoch 2/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 276.3061 - val_loss: 276.3308
Epoch 3/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 271.7565 - val_loss: 270.2166
Epoch 4/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 264.2416 - val_loss: 265.8780
Epoch 5/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 256.7530 - val_loss: 262.7866
Epoch 6/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 251.3631 - val_loss: 250.3786
Epoch 7/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 247.1415 - val_loss: 255.4111
Epoch 8/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 243.6810 - val_loss: 239.3327
Epoch 9/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 240.8945 - val_loss: 242.0631
Epoch 10/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 238.2572 - val_loss: 238.8296
Epoch 11/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 235.7874 - val_loss: 230.7873
Epoch 12/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 233.0262 - val_loss: 255.5401
Epoch 13/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 230.5385 - val_loss: 232.5531
Epoch 14/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 228.3917 - val_loss: 231.2578
Epoch 15/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 226.5725 - val_loss: 222.6964
Epoch 16/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 225.0400 - val_loss: 231.6836
Epoch 17/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 223.7051 - val_loss: 230.2948
Epoch 18/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 222.2968 - val_loss: 236.2059
Epoch 19/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 221.3516 - val_loss: 225.5672
Epoch 20/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 220.1013 - val_loss: 227.7829
Epoch 21/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 219.3413 - val_loss: 225.1247
Epoch 22/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 218.5222 - val_loss: 221.5162
Epoch 23/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 217.8081 - val_loss: 227.1380
Epoch 24/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 216.9559 - val_loss: 224.8002
Epoch 25/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 216.1649 - val_loss: 222.0253
Epoch 26/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 215.6087 - val_loss: 216.8691
Epoch 27/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 214.8785 - val_loss: 220.9608
Epoch 28/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 214.3742 - val_loss: 228.0578
Epoch 29/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 213.7717 - val_loss: 219.9762
Epoch 30/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 213.1717 - val_loss: 216.2680
Epoch 31/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 212.5217 - val_loss: 221.9611
Epoch 32/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 211.9070 - val_loss: 211.0623
Epoch 33/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 211.6886 - val_loss: 231.4352
Epoch 34/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 211.1217 - val_loss: 257.3332
Epoch 35/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 210.5640 - val_loss: 216.4073
Epoch 36/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 210.1565 - val_loss: 205.7943
Epoch 37/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 209.7366 - val_loss: 229.5703
Epoch 38/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 209.3090 - val_loss: 209.8883
Epoch 39/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 208.9081 - val_loss: 214.9106
Epoch 40/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 208.6793 - val_loss: 233.4256
Epoch 41/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 208.0742 - val_loss: 206.9510
Epoch 42/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 207.8946 - val_loss: 227.0343
Epoch 43/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 207.6145 - val_loss: 207.0557
Epoch 44/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 207.2218 - val_loss: 228.3609
Epoch 45/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 206.9870 - val_loss: 226.3053

         CHILD ACCURACY = 236.94862360269568


         PARENT ACCURACY = 214.24724719783927



 QUEUE SIZE BEFORE GET = 8


 NODE SELECTED <<<------ Epochs = 45 -------- BatchSize = 3000 --------- Accuracy = 202.84271243458215 -------->>>


 CHILD 1 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 4000

         EPOCHS = 50
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/50
2018-11-10 18:38:26.093034: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 18:38:26.099586: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 29s 3us/step - loss: 295.5440 - val_loss: 275.0092
Epoch 2/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 272.7872 - val_loss: 266.3387
Epoch 3/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 263.3316 - val_loss: 257.0502
Epoch 4/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 255.6789 - val_loss: 248.4624
Epoch 5/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 250.6119 - val_loss: 254.2555
Epoch 6/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 246.8638 - val_loss: 243.5244
Epoch 7/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 243.5625 - val_loss: 240.6638
Epoch 8/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 240.8840 - val_loss: 236.0415
Epoch 9/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 238.5580 - val_loss: 235.8453
Epoch 10/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 236.3791 - val_loss: 232.5880
Epoch 11/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 233.9200 - val_loss: 228.6860
Epoch 12/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 231.2788 - val_loss: 226.1592
Epoch 13/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 228.6620 - val_loss: 223.3106
Epoch 14/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 226.3099 - val_loss: 223.6948
Epoch 15/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 224.4135 - val_loss: 223.4730
Epoch 16/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 222.8790 - val_loss: 218.4359
Epoch 17/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 221.4852 - val_loss: 217.6737
Epoch 18/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 220.1653 - val_loss: 221.0780
Epoch 19/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 219.0783 - val_loss: 218.6242
Epoch 20/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 218.0023 - val_loss: 224.5770
Epoch 21/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 217.2601 - val_loss: 210.5280
Epoch 22/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 216.2113 - val_loss: 215.2260
Epoch 23/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 215.4358 - val_loss: 216.5675
Epoch 24/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 214.6729 - val_loss: 210.5078
Epoch 25/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 214.2019 - val_loss: 213.0955
Epoch 26/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 213.3041 - val_loss: 208.9787
Epoch 27/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 212.6457 - val_loss: 245.9627
Epoch 28/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 212.0920 - val_loss: 209.7402
Epoch 29/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 211.5314 - val_loss: 209.6835
Epoch 30/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 210.9708 - val_loss: 206.4546
Epoch 31/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 210.1563 - val_loss: 213.0823
Epoch 32/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 209.9727 - val_loss: 218.1768
Epoch 33/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 209.2655 - val_loss: 210.1037
Epoch 34/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 208.7896 - val_loss: 203.9856
Epoch 35/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 208.2110 - val_loss: 220.9220
Epoch 36/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 207.7852 - val_loss: 208.3340
Epoch 37/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 207.3493 - val_loss: 233.2802
Epoch 38/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 206.9487 - val_loss: 208.8910
Epoch 39/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 206.5706 - val_loss: 206.6962
Epoch 40/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 206.1837 - val_loss: 203.5071
Epoch 41/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 205.7679 - val_loss: 204.5415
Epoch 42/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 205.4152 - val_loss: 216.5199
Epoch 43/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 205.1665 - val_loss: 200.8829
Epoch 44/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 204.6846 - val_loss: 205.9554
Epoch 45/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 204.2598 - val_loss: 203.5945
Epoch 46/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 203.9766 - val_loss: 206.8116
Epoch 47/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 203.6478 - val_loss: 212.6196
Epoch 48/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 203.5145 - val_loss: 202.2300
Epoch 49/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 203.1934 - val_loss: 207.3204
Epoch 50/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 202.7713 - val_loss: 197.5732

         CHILD ACCURACY = 206.58980999220236


         PARENT ACCURACY = 202.84271243458215


 CHILD 2 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 3000

         EPOCHS = 50
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/50
2018-11-10 19:02:04.151888: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 19:02:04.156427: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 290.8670 - val_loss: 273.5640
Epoch 2/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 272.0254 - val_loss: 266.7659
Epoch 3/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 261.2210 - val_loss: 264.9985
Epoch 4/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 253.6031 - val_loss: 246.9857
Epoch 5/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 248.8453 - val_loss: 244.7733
Epoch 6/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 245.3651 - val_loss: 242.4908
Epoch 7/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 242.5356 - val_loss: 237.3617
Epoch 8/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 240.4855 - val_loss: 236.7750
Epoch 9/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 238.4998 - val_loss: 242.0312
Epoch 10/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 236.3636 - val_loss: 231.4822
Epoch 11/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 233.8511 - val_loss: 229.3342
Epoch 12/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 231.0289 - val_loss: 231.2252
Epoch 13/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 228.6368 - val_loss: 221.7430
Epoch 14/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 226.7322 - val_loss: 221.7573
Epoch 15/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 224.8850 - val_loss: 220.1748
Epoch 16/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 223.5309 - val_loss: 219.3022
Epoch 17/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 222.2831 - val_loss: 221.1796
Epoch 18/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 221.0233 - val_loss: 220.4585
Epoch 19/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 220.0780 - val_loss: 221.0503
Epoch 20/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 219.0962 - val_loss: 211.8673
Epoch 21/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 218.1027 - val_loss: 219.4649
Epoch 22/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 217.2927 - val_loss: 212.7164
Epoch 23/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 216.5035 - val_loss: 209.3812
Epoch 24/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 215.6363 - val_loss: 215.0787
Epoch 25/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 214.9130 - val_loss: 209.1640
Epoch 26/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 214.3656 - val_loss: 217.6747
Epoch 27/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 213.5994 - val_loss: 216.0981
Epoch 28/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 212.9986 - val_loss: 217.3801
Epoch 29/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 212.5291 - val_loss: 208.9883
Epoch 30/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 212.0229 - val_loss: 207.6809
Epoch 31/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 211.3980 - val_loss: 214.2086
Epoch 32/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 210.7957 - val_loss: 209.6888
Epoch 33/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 210.5385 - val_loss: 211.7939
Epoch 34/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 210.0723 - val_loss: 212.8179
Epoch 35/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 209.3900 - val_loss: 214.4694
Epoch 36/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 209.3497 - val_loss: 212.0445
Epoch 37/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 208.6815 - val_loss: 211.5961
Epoch 38/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 208.2696 - val_loss: 205.1526
Epoch 39/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 208.0730 - val_loss: 204.2763
Epoch 40/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 207.7242 - val_loss: 214.1936
Epoch 41/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 207.2272 - val_loss: 216.6735
Epoch 42/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 206.8916 - val_loss: 211.0171
Epoch 43/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 206.6577 - val_loss: 203.5284
Epoch 44/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 206.1536 - val_loss: 208.1042
Epoch 45/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 205.8197 - val_loss: 204.3318
Epoch 46/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 205.5569 - val_loss: 206.0991
Epoch 47/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 205.2288 - val_loss: 202.8434
Epoch 48/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 204.7587 - val_loss: 205.8735
Epoch 49/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 204.5966 - val_loss: 200.4883
Epoch 50/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 204.1336 - val_loss: 205.2661

         CHILD ACCURACY = 202.55623386074333


         PARENT ACCURACY = 202.84271243458215


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 8 <<<<<<<<<<<<<<<<<<<<<<<<<<<


                         ********** BEST MODEL SAVED | EPOCHS = 50 | BATCH_SIZE = 3000 | ACCURACY = 202.55623386074333 ********




 CHILD 3 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 2000

         EPOCHS = 50
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/50
2018-11-10 19:29:31.360732: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 19:29:31.365433: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 43s 5us/step - loss: 287.5361 - val_loss: 272.6983
Epoch 2/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 268.5479 - val_loss: 258.9112
Epoch 3/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 257.0749 - val_loss: 250.9192
Epoch 4/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 250.9378 - val_loss: 245.6759
Epoch 5/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 246.8668 - val_loss: 242.0403
Epoch 6/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 243.5733 - val_loss: 239.4964
Epoch 7/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 240.8784 - val_loss: 233.6430
Epoch 8/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 237.6451 - val_loss: 231.3209
Epoch 9/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 234.3886 - val_loss: 232.0109
Epoch 10/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 231.4537 - val_loss: 229.9015
Epoch 11/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 228.9625 - val_loss: 222.8911
Epoch 12/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 227.0446 - val_loss: 227.1580
Epoch 13/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 225.3605 - val_loss: 224.8946
Epoch 14/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 223.9584 - val_loss: 221.1263
Epoch 15/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 222.4788 - val_loss: 222.1092
Epoch 16/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 221.1847 - val_loss: 215.7518
Epoch 17/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 220.1540 - val_loss: 214.6422
Epoch 18/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 219.1095 - val_loss: 221.5145
Epoch 19/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 218.3206 - val_loss: 213.7042
Epoch 20/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 217.4307 - val_loss: 215.8032
Epoch 21/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 216.4826 - val_loss: 211.7263
Epoch 22/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 215.9351 - val_loss: 215.9981
Epoch 23/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 215.1169 - val_loss: 210.0893
Epoch 24/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 214.3679 - val_loss: 213.7677
Epoch 25/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 213.7824 - val_loss: 219.0773
Epoch 26/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 213.2145 - val_loss: 215.2934
Epoch 27/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 212.6483 - val_loss: 209.7392
Epoch 28/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 211.9867 - val_loss: 209.2306
Epoch 29/50
9445953/9445953 [==============================] - 43s 4us/step - loss: 211.5750 - val_loss: 210.7653
Epoch 30/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 210.9521 - val_loss: 205.1196
Epoch 31/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 210.5333 - val_loss: 208.4044
Epoch 32/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 209.9534 - val_loss: 214.5951
Epoch 33/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 209.7087 - val_loss: 203.3278
Epoch 34/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 209.2128 - val_loss: 210.8209
Epoch 35/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 208.8869 - val_loss: 204.9238
Epoch 36/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 208.4584 - val_loss: 205.5472
Epoch 37/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 207.9706 - val_loss: 203.6357
Epoch 38/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 207.4404 - val_loss: 206.0142
Epoch 39/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 207.2644 - val_loss: 204.3028
Epoch 40/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 206.8670 - val_loss: 200.5042
Epoch 41/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 206.3896 - val_loss: 212.3663
Epoch 42/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 206.2649 - val_loss: 199.4975
Epoch 43/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 205.8107 - val_loss: 202.9338
Epoch 44/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 205.5333 - val_loss: 205.0896
Epoch 45/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 205.2789 - val_loss: 200.2274
Epoch 46/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 205.1403 - val_loss: 204.4631
Epoch 47/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 204.6458 - val_loss: 208.9568
Epoch 48/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 204.3896 - val_loss: 200.1496
Epoch 49/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 204.2260 - val_loss: 203.1064
Epoch 50/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 203.9207 - val_loss: 202.1908

         CHILD ACCURACY = 202.9063130839305


         PARENT ACCURACY = 202.84271243458215


 CHILD 4 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 2000

         EPOCHS = 40
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/40
2018-11-10 20:04:50.520145: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 20:04:50.526292: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 44s 5us/step - loss: 285.0748 - val_loss: 272.2174
Epoch 2/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 272.3060 - val_loss: 267.9653
Epoch 3/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 263.9206 - val_loss: 254.3370
Epoch 4/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 253.6294 - val_loss: 250.6070
Epoch 5/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 248.3237 - val_loss: 242.8585
Epoch 6/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 244.5631 - val_loss: 243.1090
Epoch 7/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 241.3727 - val_loss: 237.2415
Epoch 8/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 238.0166 - val_loss: 234.4805
Epoch 9/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 234.8917 - val_loss: 227.4770
Epoch 10/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 231.9029 - val_loss: 228.0962
Epoch 11/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 229.5547 - val_loss: 225.9914
Epoch 12/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 227.4766 - val_loss: 221.5490
Epoch 13/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 225.7405 - val_loss: 222.3245
Epoch 14/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 224.3114 - val_loss: 219.2755
Epoch 15/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 222.8151 - val_loss: 217.9660
Epoch 16/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 221.4871 - val_loss: 216.4806
Epoch 17/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 220.3340 - val_loss: 215.7827
Epoch 18/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 219.3546 - val_loss: 222.4147
Epoch 19/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 218.3817 - val_loss: 212.9160
Epoch 20/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 217.2909 - val_loss: 219.0703
Epoch 21/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 216.3380 - val_loss: 211.8142
Epoch 22/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 215.4580 - val_loss: 220.1562
Epoch 23/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 214.8998 - val_loss: 217.1189
Epoch 24/40
9445953/9445953 [==============================] - 49s 5us/step - loss: 213.9940 - val_loss: 223.9697
Epoch 25/40
9445953/9445953 [==============================] - 51s 5us/step - loss: 213.1809 - val_loss: 212.4563
Epoch 26/40
9445953/9445953 [==============================] - 44s 5us/step - loss: 212.6352 - val_loss: 211.5438
Epoch 27/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 212.1224 - val_loss: 209.0206
Epoch 28/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 211.5603 - val_loss: 212.4683
Epoch 29/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 211.1867 - val_loss: 208.9997
Epoch 30/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 210.6070 - val_loss: 209.6945
Epoch 31/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 209.9858 - val_loss: 205.5445
Epoch 32/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 209.6147 - val_loss: 208.7305
Epoch 33/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 209.1308 - val_loss: 206.2057
Epoch 34/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 208.7127 - val_loss: 203.4520
Epoch 35/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 208.3893 - val_loss: 203.4808
Epoch 36/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 207.8396 - val_loss: 204.3298
Epoch 37/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 207.4272 - val_loss: 205.8136
Epoch 38/40
9445953/9445953 [==============================] - 44s 5us/step - loss: 207.3287 - val_loss: 204.1393
Epoch 39/40
9445953/9445953 [==============================] - 43s 4us/step - loss: 206.8383 - val_loss: 202.1600
Epoch 40/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 206.3754 - val_loss: 207.5623

         CHILD ACCURACY = 202.84524684301272


         PARENT ACCURACY = 202.84271243458215


 CHILD 5 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 4000

         EPOCHS = 45
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-11-10 20:33:34.990036: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 20:33:34.994387: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 29s 3us/step - loss: 290.3427 - val_loss: 279.4992
Epoch 2/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 270.6599 - val_loss: 265.4871
Epoch 3/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 260.9577 - val_loss: 253.1600
Epoch 4/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 253.5354 - val_loss: 247.0500
Epoch 5/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 248.5762 - val_loss: 242.5407
Epoch 6/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 244.8480 - val_loss: 243.5426
Epoch 7/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 241.5809 - val_loss: 238.2620
Epoch 8/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 238.9150 - val_loss: 239.9123
Epoch 9/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 236.4455 - val_loss: 237.0675
Epoch 10/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 233.7130 - val_loss: 235.8459
Epoch 11/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 231.2968 - val_loss: 229.5475
Epoch 12/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 228.9101 - val_loss: 226.2423
Epoch 13/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 226.7640 - val_loss: 225.4809
Epoch 14/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 224.9097 - val_loss: 223.0040
Epoch 15/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 223.3079 - val_loss: 224.3713
Epoch 16/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 221.9071 - val_loss: 224.5569
Epoch 17/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 220.5212 - val_loss: 216.4139
Epoch 18/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 219.3073 - val_loss: 225.9616
Epoch 19/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 218.1842 - val_loss: 212.5282
Epoch 20/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 217.1409 - val_loss: 211.5598
Epoch 21/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 216.2756 - val_loss: 213.7999
Epoch 22/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 215.3351 - val_loss: 211.6376
Epoch 23/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 214.5757 - val_loss: 213.6492
Epoch 24/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 213.6725 - val_loss: 213.2375
Epoch 25/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 212.9639 - val_loss: 214.5522
Epoch 26/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 212.3037 - val_loss: 208.0497
Epoch 27/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 211.8133 - val_loss: 208.7094
Epoch 28/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 211.1450 - val_loss: 206.8328
Epoch 29/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 210.3190 - val_loss: 209.8799
Epoch 30/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 209.8488 - val_loss: 208.2888
Epoch 31/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 209.4073 - val_loss: 214.5496
Epoch 32/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 208.8982 - val_loss: 211.5767
Epoch 33/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 208.2531 - val_loss: 209.5818
Epoch 34/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 207.8616 - val_loss: 210.7913
Epoch 35/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 207.6178 - val_loss: 213.0202
Epoch 36/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 207.1873 - val_loss: 203.0950
Epoch 37/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 206.6115 - val_loss: 202.2024
Epoch 38/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 206.2410 - val_loss: 207.1067
Epoch 39/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 205.7743 - val_loss: 201.5539
Epoch 40/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 205.4606 - val_loss: 204.9298
Epoch 41/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 205.0993 - val_loss: 208.2271
Epoch 42/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 204.8675 - val_loss: 209.0570
Epoch 43/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 204.5595 - val_loss: 204.0263
Epoch 44/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 204.0114 - val_loss: 216.0202
Epoch 45/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 203.8536 - val_loss: 202.9418

         CHILD ACCURACY = 211.69968930092983


         PARENT ACCURACY = 202.84271243458215



 QUEUE SIZE BEFORE GET = 8


 NODE SELECTED <<<------ Epochs = 50 -------- BatchSize = 3000 --------- Accuracy = 202.55623386074333 -------->>>


 CHILD 1 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 4000

         EPOCHS = 50
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/50
2018-11-10 20:55:06.499027: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 20:55:06.503536: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 29s 3us/step - loss: 291.6964 - val_loss: 275.2641
Epoch 2/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 270.4812 - val_loss: 262.1877
Epoch 3/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 261.5150 - val_loss: 259.3570
Epoch 4/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 254.5254 - val_loss: 251.2818
Epoch 5/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 249.5717 - val_loss: 262.6710
Epoch 6/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 245.9648 - val_loss: 246.9596
Epoch 7/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 242.9095 - val_loss: 238.6847
Epoch 8/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 240.4630 - val_loss: 240.3617
Epoch 9/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 237.9961 - val_loss: 233.2046
Epoch 10/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 235.5706 - val_loss: 231.7780
Epoch 11/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 232.9283 - val_loss: 229.9243
Epoch 12/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 230.1797 - val_loss: 225.6405
Epoch 13/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 227.6224 - val_loss: 222.9463
Epoch 14/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 225.6691 - val_loss: 222.2260
Epoch 15/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 223.9580 - val_loss: 219.7019
Epoch 16/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 222.4832 - val_loss: 217.9044
Epoch 17/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 221.2797 - val_loss: 217.6735
Epoch 18/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 220.1091 - val_loss: 223.2291
Epoch 19/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 218.8558 - val_loss: 218.1671
Epoch 20/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 217.9827 - val_loss: 215.7275
Epoch 21/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 217.1562 - val_loss: 217.3626
Epoch 22/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 216.2762 - val_loss: 218.9689
Epoch 23/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 215.5271 - val_loss: 249.5690
Epoch 24/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 214.8147 - val_loss: 221.5624
Epoch 25/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 213.9852 - val_loss: 212.8069
Epoch 26/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 213.2383 - val_loss: 229.1322
Epoch 27/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 212.8401 - val_loss: 209.4329
Epoch 28/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 212.0270 - val_loss: 224.2922
Epoch 29/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 211.4245 - val_loss: 207.9854
Epoch 30/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 210.8414 - val_loss: 227.9151
Epoch 31/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 210.2682 - val_loss: 209.2468
Epoch 32/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 209.8984 - val_loss: 221.2196
Epoch 33/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 209.3587 - val_loss: 212.8645
Epoch 34/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 208.7568 - val_loss: 205.9594
Epoch 35/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 208.4270 - val_loss: 206.9845
Epoch 36/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 207.8089 - val_loss: 212.5867
Epoch 37/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 207.3297 - val_loss: 208.5692
Epoch 38/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 206.9812 - val_loss: 210.1349
Epoch 39/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 206.3709 - val_loss: 205.2390
Epoch 40/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 206.1653 - val_loss: 207.1527
Epoch 41/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 205.9077 - val_loss: 213.5277
Epoch 42/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 205.4020 - val_loss: 213.3228
Epoch 43/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 204.9038 - val_loss: 220.2696
Epoch 44/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 204.6108 - val_loss: 202.4855
Epoch 45/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 204.3941 - val_loss: 208.4107
Epoch 46/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 203.9008 - val_loss: 200.5905
Epoch 47/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 203.6517 - val_loss: 206.2612
Epoch 48/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 203.4220 - val_loss: 202.6135
Epoch 49/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 202.9461 - val_loss: 220.6962
Epoch 50/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 202.6454 - val_loss: 204.1525

         CHILD ACCURACY = 213.69539415496556


         PARENT ACCURACY = 202.55623386074333


 CHILD 2 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 2000

         EPOCHS = 55
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/55
2018-11-10 21:18:56.763848: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 21:18:56.768019: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 43s 5us/step - loss: 285.3970 - val_loss: 270.4557
Epoch 2/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 267.1289 - val_loss: 257.5991
Epoch 3/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 256.5578 - val_loss: 249.8862
Epoch 4/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 250.9687 - val_loss: 245.1348
Epoch 5/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 247.6663 - val_loss: 242.2655
Epoch 6/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 245.5085 - val_loss: 241.1162
Epoch 7/55
9445953/9445953 [==============================] - 47s 5us/step - loss: 243.5506 - val_loss: 241.6355
Epoch 8/55
9445953/9445953 [==============================] - 47s 5us/step - loss: 241.9603 - val_loss: 236.8931
Epoch 9/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 240.8170 - val_loss: 236.6826
Epoch 10/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 238.9235 - val_loss: 233.1583
Epoch 11/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 237.0005 - val_loss: 240.1166
Epoch 12/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 234.8972 - val_loss: 231.5188
Epoch 13/55
9445953/9445953 [==============================] - 46s 5us/step - loss: 232.1728 - val_loss: 234.8916
Epoch 14/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 229.7686 - val_loss: 223.7805
Epoch 15/55
9445953/9445953 [==============================] - 44s 5us/step - loss: 227.9198 - val_loss: 225.9163
Epoch 16/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 226.1314 - val_loss: 223.0511
Epoch 17/55
9445953/9445953 [==============================] - 44s 5us/step - loss: 224.6235 - val_loss: 218.6636
Epoch 18/55
9445953/9445953 [==============================] - 44s 5us/step - loss: 223.7308 - val_loss: 220.8751
Epoch 19/55
9445953/9445953 [==============================] - 44s 5us/step - loss: 222.3448 - val_loss: 219.1906
Epoch 20/55
9445953/9445953 [==============================] - 44s 5us/step - loss: 221.3907 - val_loss: 220.5329
Epoch 21/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 220.1121 - val_loss: 220.4403
Epoch 22/55
9445953/9445953 [==============================] - 44s 5us/step - loss: 219.4050 - val_loss: 219.2867
Epoch 23/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 218.5757 - val_loss: 225.5655
Epoch 24/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 218.0448 - val_loss: 215.1831
Epoch 25/55
9445953/9445953 [==============================] - 44s 5us/step - loss: 217.1418 - val_loss: 217.3199
Epoch 26/55
9445953/9445953 [==============================] - 44s 5us/step - loss: 216.4474 - val_loss: 215.6787
Epoch 27/55
9445953/9445953 [==============================] - 44s 5us/step - loss: 215.7132 - val_loss: 212.5214
Epoch 28/55
9445953/9445953 [==============================] - 46s 5us/step - loss: 215.1220 - val_loss: 212.3104
Epoch 29/55
9445953/9445953 [==============================] - 45s 5us/step - loss: 214.7451 - val_loss: 208.1462
Epoch 30/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 213.7537 - val_loss: 209.0308
Epoch 31/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 217.5105 - val_loss: 221.3126
Epoch 32/55
9445953/9445953 [==============================] - 45s 5us/step - loss: 241.8351 - val_loss: 220.3620
Epoch 33/55
9445953/9445953 [==============================] - 44s 5us/step - loss: 223.9337 - val_loss: 221.8481
Epoch 34/55
9445953/9445953 [==============================] - 44s 5us/step - loss: 217.8742 - val_loss: 210.8365
Epoch 35/55
9445953/9445953 [==============================] - 44s 5us/step - loss: 214.7054 - val_loss: 210.1394
Epoch 36/55
9445953/9445953 [==============================] - 44s 5us/step - loss: 213.3946 - val_loss: 209.0000
Epoch 37/55
9445953/9445953 [==============================] - 44s 5us/step - loss: 212.2945 - val_loss: 211.1986
Epoch 38/55
9445953/9445953 [==============================] - 44s 5us/step - loss: 211.6177 - val_loss: 209.6247
Epoch 39/55
9445953/9445953 [==============================] - 44s 5us/step - loss: 210.8014 - val_loss: 214.5306
Epoch 40/55
9445953/9445953 [==============================] - 44s 5us/step - loss: 210.9668 - val_loss: 206.0611
Epoch 41/55
9445953/9445953 [==============================] - 49s 5us/step - loss: 209.9416 - val_loss: 204.3852
Epoch 42/55
9445953/9445953 [==============================] - 47s 5us/step - loss: 209.1072 - val_loss: 211.0971
Epoch 43/55
9445953/9445953 [==============================] - 46s 5us/step - loss: 208.8927 - val_loss: 211.3647
Epoch 44/55
9445953/9445953 [==============================] - 49s 5us/step - loss: 208.0526 - val_loss: 203.7501
Epoch 45/55
9445953/9445953 [==============================] - 47s 5us/step - loss: 230.1439 - val_loss: 209.1877
Epoch 46/55
9445953/9445953 [==============================] - 46s 5us/step - loss: 208.5192 - val_loss: 201.5799
Epoch 47/55
9445953/9445953 [==============================] - 48s 5us/step - loss: 207.3620 - val_loss: 206.8751
Epoch 48/55
9445953/9445953 [==============================] - 47s 5us/step - loss: 207.8260 - val_loss: 210.7089
Epoch 49/55
9445953/9445953 [==============================] - 46s 5us/step - loss: 212.7374 - val_loss: 203.4786
Epoch 50/55
9445953/9445953 [==============================] - 49s 5us/step - loss: 207.7699 - val_loss: 204.5869
Epoch 51/55
9445953/9445953 [==============================] - 50s 5us/step - loss: 208.1828 - val_loss: 203.7992
Epoch 52/55
9445953/9445953 [==============================] - 49s 5us/step - loss: 206.9122 - val_loss: 201.0862
Epoch 53/55
9445953/9445953 [==============================] - 50s 5us/step - loss: 212.5547 - val_loss: 217.0416
Epoch 54/55
9445953/9445953 [==============================] - 48s 5us/step - loss: 207.1721 - val_loss: 204.8371
Epoch 55/55
9445953/9445953 [==============================] - 47s 5us/step - loss: 211.6255 - val_loss: 202.3233

         CHILD ACCURACY = 203.07798217833147


         PARENT ACCURACY = 202.55623386074333


 CHILD 3 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 3000

         EPOCHS = 55
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/55
2018-11-10 22:00:08.025103: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 22:00:08.031848: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 39s 4us/step - loss: 291.4638 - val_loss: 273.1653
Epoch 2/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 271.1221 - val_loss: 263.0888
Epoch 3/55
9445953/9445953 [==============================] - 39s 4us/step - loss: 261.0578 - val_loss: 260.7497
Epoch 4/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 253.6218 - val_loss: 249.4362
Epoch 5/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 248.7790 - val_loss: 245.7605
Epoch 6/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 245.1926 - val_loss: 240.6975
Epoch 7/55
9445953/9445953 [==============================] - 36s 4us/step - loss: 242.1347 - val_loss: 238.1670
Epoch 8/55
9445953/9445953 [==============================] - 36s 4us/step - loss: 239.6560 - val_loss: 240.5768
Epoch 9/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 237.3691 - val_loss: 233.4138
Epoch 10/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 234.8788 - val_loss: 230.5934
Epoch 11/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 232.3468 - val_loss: 231.6424
Epoch 12/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 230.0759 - val_loss: 227.8890
Epoch 13/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 228.3837 - val_loss: 225.9114
Epoch 14/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 226.8516 - val_loss: 248.8169
Epoch 15/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 225.6062 - val_loss: 219.4551
Epoch 16/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 224.1894 - val_loss: 224.9188
Epoch 17/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 223.0763 - val_loss: 222.1010
Epoch 18/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 221.9632 - val_loss: 219.0048
Epoch 19/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 221.0102 - val_loss: 221.5310
Epoch 20/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 220.1117 - val_loss: 214.3957
Epoch 21/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 219.3715 - val_loss: 214.8552
Epoch 22/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 218.5171 - val_loss: 214.8233
Epoch 23/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 217.9142 - val_loss: 216.8983
Epoch 24/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 217.1031 - val_loss: 214.0663
Epoch 25/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 216.7363 - val_loss: 213.5614
Epoch 26/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 216.0442 - val_loss: 221.7292
Epoch 27/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 215.6779 - val_loss: 213.4456
Epoch 28/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 215.0981 - val_loss: 210.6122
Epoch 29/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 214.3394 - val_loss: 221.5970
Epoch 30/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 214.1417 - val_loss: 226.4381
Epoch 31/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 213.5116 - val_loss: 211.6429
Epoch 32/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 213.0728 - val_loss: 209.5328
Epoch 33/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 212.8364 - val_loss: 207.4196
Epoch 34/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 212.0937 - val_loss: 207.8970
Epoch 35/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 211.9426 - val_loss: 212.8822
Epoch 36/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 211.6169 - val_loss: 207.6286
Epoch 37/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 211.0077 - val_loss: 212.0887
Epoch 38/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 210.5203 - val_loss: 208.4287
Epoch 39/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 210.2453 - val_loss: 211.6337
Epoch 40/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 209.6213 - val_loss: 214.3285
Epoch 41/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 209.3821 - val_loss: 207.3023
Epoch 42/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 208.9279 - val_loss: 207.5364
Epoch 43/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 208.2944 - val_loss: 204.6508
Epoch 44/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 208.0225 - val_loss: 205.9218
Epoch 45/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 207.5808 - val_loss: 204.4064
Epoch 46/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 207.2800 - val_loss: 201.9496
Epoch 47/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 206.9559 - val_loss: 205.4650
Epoch 48/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 206.5508 - val_loss: 206.0906
Epoch 49/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 206.3101 - val_loss: 204.4515
Epoch 50/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 206.1881 - val_loss: 203.0285
Epoch 51/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 205.7595 - val_loss: 202.5352
Epoch 52/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 205.6057 - val_loss: 210.7781
Epoch 53/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 205.1488 - val_loss: 202.3885
Epoch 54/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 204.8753 - val_loss: 204.0990
Epoch 55/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 204.6333 - val_loss: 220.8665

         CHILD ACCURACY = 214.00030945391498


         PARENT ACCURACY = 202.55623386074333


 CHILD 4 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 4000

         EPOCHS = 55
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/55
2018-11-10 22:31:11.200661: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 22:31:11.206071: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 29s 3us/step - loss: 294.7840 - val_loss: 274.1717
Epoch 2/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 273.1246 - val_loss: 268.5072
Epoch 3/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 264.6117 - val_loss: 260.6184
Epoch 4/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 255.9001 - val_loss: 248.4753
Epoch 5/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 250.1326 - val_loss: 248.1345
Epoch 6/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 246.1561 - val_loss: 240.5746
Epoch 7/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 242.9403 - val_loss: 238.8203
Epoch 8/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 240.3622 - val_loss: 236.5265
Epoch 9/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 237.7706 - val_loss: 248.6551
Epoch 10/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 234.8048 - val_loss: 234.8404
Epoch 11/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 231.6610 - val_loss: 228.6895
Epoch 12/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 229.1503 - val_loss: 225.1139
Epoch 13/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 227.0604 - val_loss: 224.0596
Epoch 14/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 225.3482 - val_loss: 220.9086
Epoch 15/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 223.7740 - val_loss: 219.8477
Epoch 16/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 222.4462 - val_loss: 226.9032
Epoch 17/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 221.3890 - val_loss: 215.8096
Epoch 18/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 220.2752 - val_loss: 214.1130
Epoch 19/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 219.3606 - val_loss: 216.8394
Epoch 20/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 218.4682 - val_loss: 219.2932
Epoch 21/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 217.5896 - val_loss: 228.8087
Epoch 22/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 216.9283 - val_loss: 213.1890
Epoch 23/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 216.0442 - val_loss: 210.6307
Epoch 24/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 215.2245 - val_loss: 213.1292
Epoch 25/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 214.7673 - val_loss: 212.3496
Epoch 26/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 214.1510 - val_loss: 212.3674
Epoch 27/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 213.6617 - val_loss: 219.2899
Epoch 28/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 212.9427 - val_loss: 210.8330
Epoch 29/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 212.5457 - val_loss: 210.7342
Epoch 30/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 211.8020 - val_loss: 213.1362
Epoch 31/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 211.3861 - val_loss: 209.7249
Epoch 32/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 211.1548 - val_loss: 217.8103
Epoch 33/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 210.3433 - val_loss: 207.6649
Epoch 34/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 210.0721 - val_loss: 206.4101
Epoch 35/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 209.6887 - val_loss: 214.7197
Epoch 36/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 209.3094 - val_loss: 205.5462
Epoch 37/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 208.8230 - val_loss: 209.8530
Epoch 38/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 208.6591 - val_loss: 206.9345
Epoch 39/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 208.1214 - val_loss: 202.4522
Epoch 40/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 207.7270 - val_loss: 208.0017
Epoch 41/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 207.4416 - val_loss: 207.5893
Epoch 42/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 207.0415 - val_loss: 207.1923
Epoch 43/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 206.7889 - val_loss: 202.0598
Epoch 44/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 206.6267 - val_loss: 202.6013
Epoch 45/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 206.2004 - val_loss: 204.0631
Epoch 46/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 205.8237 - val_loss: 228.0676
Epoch 47/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 205.8142 - val_loss: 204.4181
Epoch 48/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 205.4669 - val_loss: 209.5158
Epoch 49/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 205.1302 - val_loss: 206.6568
Epoch 50/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 204.7859 - val_loss: 206.1840
Epoch 51/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 204.5650 - val_loss: 206.2731
Epoch 52/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 204.2851 - val_loss: 200.6205
Epoch 53/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 204.1302 - val_loss: 202.5030
Epoch 54/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 203.7649 - val_loss: 207.9314
Epoch 55/55
9445953/9445953 [==============================] - 29s 3us/step - loss: 203.5518 - val_loss: 203.2614

         CHILD ACCURACY = 203.22511588362167


         PARENT ACCURACY = 202.55623386074333



 QUEUE SIZE BEFORE GET = 7


 NODE SELECTED <<<------ Epochs = 45 -------- BatchSize = 4000 --------- Accuracy = 210.05081814239864 -------->>>


 CHILD 1 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 45
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-11-10 22:57:27.213132: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 22:57:27.217270: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 27s 3us/step - loss: 294.9530 - val_loss: 274.2419
Epoch 2/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 275.5131 - val_loss: 281.8925
Epoch 3/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 269.3915 - val_loss: 262.9283
Epoch 4/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 260.1460 - val_loss: 254.4388
Epoch 5/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 253.6028 - val_loss: 255.3127
Epoch 6/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 249.3268 - val_loss: 247.8231
Epoch 7/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 245.8581 - val_loss: 259.7638
Epoch 8/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 242.9869 - val_loss: 241.3710
Epoch 9/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 240.4596 - val_loss: 236.8522
Epoch 10/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 237.8683 - val_loss: 238.5893
Epoch 11/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 235.3930 - val_loss: 232.1083
Epoch 12/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 232.6179 - val_loss: 230.6996
Epoch 13/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 230.1555 - val_loss: 253.4889
Epoch 14/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 227.7822 - val_loss: 233.1150
Epoch 15/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 225.9485 - val_loss: 226.1616
Epoch 16/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 224.3148 - val_loss: 225.5530
Epoch 17/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 222.7440 - val_loss: 230.8307
Epoch 18/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 221.6228 - val_loss: 222.4272
Epoch 19/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 220.3991 - val_loss: 217.0483
Epoch 20/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 219.3362 - val_loss: 224.1703
Epoch 21/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 218.2872 - val_loss: 225.5111
Epoch 22/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 217.4192 - val_loss: 223.4367
Epoch 23/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 216.5617 - val_loss: 219.2791
Epoch 24/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 215.8208 - val_loss: 229.7429
Epoch 25/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 215.1852 - val_loss: 224.7588
Epoch 26/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 214.5417 - val_loss: 241.0371
Epoch 27/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 213.9139 - val_loss: 220.8376
Epoch 28/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 213.2246 - val_loss: 223.1882
Epoch 29/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 212.7550 - val_loss: 223.8392
Epoch 30/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 212.0565 - val_loss: 224.0171
Epoch 31/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 211.4877 - val_loss: 217.0020
Epoch 32/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 211.0218 - val_loss: 220.4611
Epoch 33/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 210.5202 - val_loss: 217.0930
Epoch 34/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 210.0105 - val_loss: 216.4104
Epoch 35/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 209.3906 - val_loss: 223.6515
Epoch 36/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 209.2873 - val_loss: 215.6918
Epoch 37/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 208.6017 - val_loss: 223.1429
Epoch 38/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 208.1668 - val_loss: 227.4801
Epoch 39/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 207.9157 - val_loss: 227.1528
Epoch 40/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 207.5005 - val_loss: 206.5392
Epoch 41/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 207.1184 - val_loss: 217.6051
Epoch 42/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 206.7297 - val_loss: 207.2815
Epoch 43/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 206.2779 - val_loss: 211.4104
Epoch 44/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 206.1492 - val_loss: 217.5151
Epoch 45/45
9445953/9445953 [==============================] - 26s 3us/step - loss: 205.7471 - val_loss: 228.6452

         CHILD ACCURACY = 226.20015560289517


         PARENT ACCURACY = 210.05081814239864


 CHILD 2 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 50
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/50
2018-11-10 23:17:03.140217: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 23:17:03.145177: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 26s 3us/step - loss: 300.6116 - val_loss: 280.2638
Epoch 2/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 277.0052 - val_loss: 275.4299
Epoch 3/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 273.8994 - val_loss: 270.4499
Epoch 4/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 272.4181 - val_loss: 269.9877
Epoch 5/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 271.4677 - val_loss: 271.8901
Epoch 6/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 270.6891 - val_loss: 268.5635
Epoch 7/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 270.1034 - val_loss: 269.2207
Epoch 8/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 269.4437 - val_loss: 267.1505
Epoch 9/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 268.7318 - val_loss: 267.0928
Epoch 10/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 266.1828 - val_loss: 258.2706
Epoch 11/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 256.3548 - val_loss: 256.1546
Epoch 12/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 250.7861 - val_loss: 248.8472
Epoch 13/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 247.6868 - val_loss: 255.5620
Epoch 14/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 245.0666 - val_loss: 240.7456
Epoch 15/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 242.8267 - val_loss: 237.5306
Epoch 16/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 240.5253 - val_loss: 248.6813
Epoch 17/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 237.8999 - val_loss: 233.3192
Epoch 18/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 235.4248 - val_loss: 235.8144
Epoch 19/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 233.4061 - val_loss: 233.5728
Epoch 20/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 231.4532 - val_loss: 241.4273
Epoch 21/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 229.6460 - val_loss: 238.4151
Epoch 22/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 228.3828 - val_loss: 227.2566
Epoch 23/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 226.9824 - val_loss: 227.8114
Epoch 24/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 225.8660 - val_loss: 226.3280
Epoch 25/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 224.6830 - val_loss: 226.8668
Epoch 26/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 223.8644 - val_loss: 277.4134
Epoch 27/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 222.9714 - val_loss: 224.9024
Epoch 28/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 222.1058 - val_loss: 246.5353
Epoch 29/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 221.4969 - val_loss: 223.0735
Epoch 30/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 220.5077 - val_loss: 224.1234
Epoch 31/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 219.9780 - val_loss: 218.6137
Epoch 32/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 219.1458 - val_loss: 222.6903
Epoch 33/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 218.6578 - val_loss: 252.7466
Epoch 34/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 218.2081 - val_loss: 221.2996
Epoch 35/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 217.3421 - val_loss: 223.3613
Epoch 36/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 216.8873 - val_loss: 259.0278
Epoch 37/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 216.2173 - val_loss: 221.8688
Epoch 38/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 215.6377 - val_loss: 214.2324
Epoch 39/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 215.0513 - val_loss: 239.9622
Epoch 40/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 214.8467 - val_loss: 243.4127
Epoch 41/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 214.4903 - val_loss: 220.0821
Epoch 42/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 213.7019 - val_loss: 211.1856
Epoch 43/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 213.5420 - val_loss: 217.9387
Epoch 44/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 212.9630 - val_loss: 220.4205
Epoch 45/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 212.4818 - val_loss: 211.8664
Epoch 46/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 212.0935 - val_loss: 211.3782
Epoch 47/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 211.6673 - val_loss: 225.3343
Epoch 48/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 211.2004 - val_loss: 216.8873
Epoch 49/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 210.9679 - val_loss: 220.5497
Epoch 50/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 210.6047 - val_loss: 219.7227

         CHILD ACCURACY = 230.1369101288379


         PARENT ACCURACY = 210.05081814239864


 CHILD 3 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 4000

         EPOCHS = 50
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/50
2018-11-10 23:38:45.690284: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-10 23:38:45.696289: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 29s 3us/step - loss: 293.3727 - val_loss: 275.1460
Epoch 2/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 274.9364 - val_loss: 275.8217
Epoch 3/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 268.7485 - val_loss: 264.5845
Epoch 4/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 258.1382 - val_loss: 253.5904
Epoch 5/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 251.3749 - val_loss: 257.2897
Epoch 6/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 246.7915 - val_loss: 244.8636
Epoch 7/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 243.3184 - val_loss: 238.4677
Epoch 8/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 240.5717 - val_loss: 242.0849
Epoch 9/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 238.1623 - val_loss: 235.0397
Epoch 10/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 235.7899 - val_loss: 231.8701
Epoch 11/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 232.8533 - val_loss: 227.8695
Epoch 12/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 229.7430 - val_loss: 223.9427
Epoch 13/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 227.1958 - val_loss: 224.3060
Epoch 14/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 225.3285 - val_loss: 224.5535
Epoch 15/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 223.5894 - val_loss: 219.9786
Epoch 16/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 222.3139 - val_loss: 220.4504
Epoch 17/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 220.9697 - val_loss: 224.0810
Epoch 18/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 219.8262 - val_loss: 217.3947
Epoch 19/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 218.7714 - val_loss: 227.7313
Epoch 20/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 218.0036 - val_loss: 228.1148
Epoch 21/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 217.0452 - val_loss: 211.9105
Epoch 22/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 216.3961 - val_loss: 212.3507
Epoch 23/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 215.4559 - val_loss: 213.4741
Epoch 24/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 214.8162 - val_loss: 213.9476
Epoch 25/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 214.2125 - val_loss: 220.3160
Epoch 26/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 213.5223 - val_loss: 208.5840
Epoch 27/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 212.8657 - val_loss: 210.3671
Epoch 28/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 212.2664 - val_loss: 209.9949
Epoch 29/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 211.7395 - val_loss: 215.1349
Epoch 30/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 211.1583 - val_loss: 212.1895
Epoch 31/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 210.7176 - val_loss: 206.8757
Epoch 32/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 210.1421 - val_loss: 206.6431
Epoch 33/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 209.5399 - val_loss: 206.0879
Epoch 34/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 209.2046 - val_loss: 222.0370
Epoch 35/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 208.6440 - val_loss: 208.9316
Epoch 36/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 208.2307 - val_loss: 209.7957
Epoch 37/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 207.8702 - val_loss: 205.5008
Epoch 38/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 207.3441 - val_loss: 213.7250
Epoch 39/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 206.8769 - val_loss: 201.6048
Epoch 40/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 206.6429 - val_loss: 202.7226
Epoch 41/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 206.0886 - val_loss: 201.7943
Epoch 42/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 205.9415 - val_loss: 208.2955
Epoch 43/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 205.4537 - val_loss: 208.9379
Epoch 44/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 205.2609 - val_loss: 206.3833
Epoch 45/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 204.6819 - val_loss: 201.1198
Epoch 46/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 204.5420 - val_loss: 204.5920
Epoch 47/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 204.1512 - val_loss: 201.5873
Epoch 48/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 203.9026 - val_loss: 203.2338
Epoch 49/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 203.5805 - val_loss: 212.6863
Epoch 50/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 203.2987 - val_loss: 208.1780

         CHILD ACCURACY = 209.10942854792248


         PARENT ACCURACY = 210.05081814239864


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 7 <<<<<<<<<<<<<<<<<<<<<<<<<<<


 CHILD 4 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 3000

         EPOCHS = 50
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/50
2018-11-11 00:02:40.047487: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 00:02:40.060925: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 297.3375 - val_loss: 275.9586
Epoch 2/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 275.9355 - val_loss: 271.4581
Epoch 3/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 272.4097 - val_loss: 266.1852
Epoch 4/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 262.1123 - val_loss: 255.9017
Epoch 5/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 252.9132 - val_loss: 248.2197
Epoch 6/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 248.1473 - val_loss: 243.7252
Epoch 7/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 244.4915 - val_loss: 239.3258
Epoch 8/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 241.7137 - val_loss: 241.1988
Epoch 9/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 239.4154 - val_loss: 242.1784
Epoch 10/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 237.1519 - val_loss: 233.4488
Epoch 11/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 234.6999 - val_loss: 231.9316
Epoch 12/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 231.7830 - val_loss: 231.3993
Epoch 13/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 229.0231 - val_loss: 224.8520
Epoch 14/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 226.9306 - val_loss: 223.3031
Epoch 15/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 225.1999 - val_loss: 220.8766
Epoch 16/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 223.5613 - val_loss: 222.3904
Epoch 17/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 222.1464 - val_loss: 219.5244
Epoch 18/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 220.7282 - val_loss: 215.6829
Epoch 19/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 219.5381 - val_loss: 224.7599
Epoch 20/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 218.3344 - val_loss: 220.0888
Epoch 21/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 217.5697 - val_loss: 210.6955
Epoch 22/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 216.7605 - val_loss: 223.4789
Epoch 23/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 215.8943 - val_loss: 211.2404
Epoch 24/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 215.0615 - val_loss: 210.1460
Epoch 25/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 214.3687 - val_loss: 211.1290
Epoch 26/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 213.8097 - val_loss: 208.7192
Epoch 27/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 213.0711 - val_loss: 209.8164
Epoch 28/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 212.3881 - val_loss: 210.1970
Epoch 29/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 211.8881 - val_loss: 206.0346
Epoch 30/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 211.2812 - val_loss: 209.9342
Epoch 31/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 210.7543 - val_loss: 217.3720
Epoch 32/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 210.2788 - val_loss: 206.0487
Epoch 33/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 209.7256 - val_loss: 202.5007
Epoch 34/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 209.1250 - val_loss: 203.8548
Epoch 35/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 208.6403 - val_loss: 215.2913
Epoch 36/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 208.3837 - val_loss: 206.9044
Epoch 37/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 208.0112 - val_loss: 211.0457
Epoch 38/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 207.6302 - val_loss: 202.2294
Epoch 39/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 207.1445 - val_loss: 212.3760
Epoch 40/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 206.8725 - val_loss: 203.8686
Epoch 41/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 206.5574 - val_loss: 204.9103
Epoch 42/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 206.0399 - val_loss: 207.5516
Epoch 43/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 205.7273 - val_loss: 199.3095
Epoch 44/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 205.3089 - val_loss: 205.6157
Epoch 45/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 204.9003 - val_loss: 204.5048
Epoch 46/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 204.8007 - val_loss: 198.7870
Epoch 47/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 204.5281 - val_loss: 196.9070
Epoch 48/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 204.1958 - val_loss: 211.7772
Epoch 49/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 204.0829 - val_loss: 198.3767
Epoch 50/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 203.6419 - val_loss: 198.9550

         CHILD ACCURACY = 198.89580707438708


         PARENT ACCURACY = 210.05081814239864


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 8 <<<<<<<<<<<<<<<<<<<<<<<<<<<


                         ********** BEST MODEL SAVED | EPOCHS = 50 | BATCH_SIZE = 3000 | ACCURACY = 198.89580707438708 ********





 QUEUE SIZE BEFORE GET = 8


 NODE SELECTED <<<------ Epochs = 50 -------- BatchSize = 3000 --------- Accuracy = 198.89580707438708 -------->>>


 CHILD 1 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 4000

         EPOCHS = 50
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/50
2018-11-11 00:30:21.865292: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 00:30:21.870665: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 29s 3us/step - loss: 294.9261 - val_loss: 293.8780
Epoch 2/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 275.9926 - val_loss: 271.3465
Epoch 3/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 271.9777 - val_loss: 267.5102
Epoch 4/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 264.3284 - val_loss: 257.4422
Epoch 5/50
9445953/9445953 [==============================] - 30s 3us/step - loss: 255.6874 - val_loss: 250.4049
Epoch 6/50
9445953/9445953 [==============================] - 30s 3us/step - loss: 250.6724 - val_loss: 247.1652
Epoch 7/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 247.2897 - val_loss: 241.7600
Epoch 8/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 244.2825 - val_loss: 241.6020
Epoch 9/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 241.6466 - val_loss: 241.2412
Epoch 10/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 239.0103 - val_loss: 232.6139
Epoch 11/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 236.1424 - val_loss: 233.8855
Epoch 12/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 233.5665 - val_loss: 232.2117
Epoch 13/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 231.4247 - val_loss: 228.5192
Epoch 14/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 229.5969 - val_loss: 225.5727
Epoch 15/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 227.7161 - val_loss: 225.2103
Epoch 16/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 226.4563 - val_loss: 231.3207
Epoch 17/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 224.8817 - val_loss: 230.4563
Epoch 18/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 223.6702 - val_loss: 221.7568
Epoch 19/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 222.4663 - val_loss: 232.8453
Epoch 20/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 221.4009 - val_loss: 216.2687
Epoch 21/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 220.3297 - val_loss: 215.0848
Epoch 22/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 219.4552 - val_loss: 229.0370
Epoch 23/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 218.5599 - val_loss: 214.5440
Epoch 24/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 217.8370 - val_loss: 227.8075
Epoch 25/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 217.0347 - val_loss: 216.5210
Epoch 26/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 216.4920 - val_loss: 215.4006
Epoch 27/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 215.7572 - val_loss: 214.7744
Epoch 28/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 215.1352 - val_loss: 209.2697
Epoch 29/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 214.5535 - val_loss: 214.5235
Epoch 30/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 214.0074 - val_loss: 211.6413
Epoch 31/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 213.4324 - val_loss: 211.6445
Epoch 32/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 213.0247 - val_loss: 218.4426
Epoch 33/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 212.5102 - val_loss: 208.7672
Epoch 34/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 212.0356 - val_loss: 207.9486
Epoch 35/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 211.6052 - val_loss: 211.1303
Epoch 36/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 211.1582 - val_loss: 213.7644
Epoch 37/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 210.8230 - val_loss: 213.0607
Epoch 38/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 210.3289 - val_loss: 209.2939
Epoch 39/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 209.7941 - val_loss: 215.9803
Epoch 40/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 209.5355 - val_loss: 210.6021
Epoch 41/50
9445953/9445953 [==============================] - 28s 3us/step - loss: 209.1944 - val_loss: 212.0131
Epoch 42/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 209.0719 - val_loss: 204.2063
Epoch 43/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 208.4914 - val_loss: 206.7942
Epoch 44/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 208.0984 - val_loss: 204.0826
Epoch 45/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 207.8442 - val_loss: 214.8390
Epoch 46/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 207.2471 - val_loss: 205.3449
Epoch 47/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 207.1185 - val_loss: 210.2032
Epoch 48/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 206.7098 - val_loss: 209.1841
Epoch 49/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 206.3127 - val_loss: 201.4895
Epoch 50/50
9445953/9445953 [==============================] - 29s 3us/step - loss: 206.0830 - val_loss: 209.5859

         CHILD ACCURACY = 208.67535221655996


         PARENT ACCURACY = 198.89580707438708


 CHILD 2 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 3000

         EPOCHS = 55
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/55
2018-11-11 00:54:22.784915: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 00:54:22.790330: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 293.7603 - val_loss: 273.2579
Epoch 2/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 271.4297 - val_loss: 265.6353
Epoch 3/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 262.3871 - val_loss: 256.4987
Epoch 4/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 256.3742 - val_loss: 251.1146
Epoch 5/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 252.0754 - val_loss: 248.7011
Epoch 6/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 248.8715 - val_loss: 245.0441
Epoch 7/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 246.0651 - val_loss: 242.9405
Epoch 8/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 243.4644 - val_loss: 240.4652
Epoch 9/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 240.9978 - val_loss: 236.8779
Epoch 10/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 238.5276 - val_loss: 234.1916
Epoch 11/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 236.1352 - val_loss: 229.9430
Epoch 12/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 233.6411 - val_loss: 230.1470
Epoch 13/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 231.1690 - val_loss: 229.2198
Epoch 14/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 229.0725 - val_loss: 223.1880
Epoch 15/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 227.2316 - val_loss: 236.5363
Epoch 16/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 225.3562 - val_loss: 220.3504
Epoch 17/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 224.2340 - val_loss: 221.0063
Epoch 18/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 223.0851 - val_loss: 219.0593
Epoch 19/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 221.8895 - val_loss: 217.1488
Epoch 20/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 221.0350 - val_loss: 216.3025
Epoch 21/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 220.0263 - val_loss: 221.6082
Epoch 22/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 218.9445 - val_loss: 221.0076
Epoch 23/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 218.0490 - val_loss: 218.7514
Epoch 24/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 217.3676 - val_loss: 214.6069
Epoch 25/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 216.7860 - val_loss: 215.9432
Epoch 26/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 216.0106 - val_loss: 218.5710
Epoch 27/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 215.2752 - val_loss: 213.9280
Epoch 28/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 214.6015 - val_loss: 209.8911
Epoch 29/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 213.9886 - val_loss: 212.7782
Epoch 30/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 213.4607 - val_loss: 211.6301
Epoch 31/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 212.9366 - val_loss: 210.1315
Epoch 32/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 212.4150 - val_loss: 209.9901
Epoch 33/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 212.0682 - val_loss: 206.7751
Epoch 34/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 211.5305 - val_loss: 208.6251
Epoch 35/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 211.0478 - val_loss: 208.8474
Epoch 36/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 210.6593 - val_loss: 208.0128
Epoch 37/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 210.1964 - val_loss: 238.5849
Epoch 38/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 209.9110 - val_loss: 210.9473
Epoch 39/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 209.5700 - val_loss: 204.9705
Epoch 40/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 208.9639 - val_loss: 209.3215
Epoch 41/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 208.5555 - val_loss: 207.5546
Epoch 42/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 208.3880 - val_loss: 205.6399
Epoch 43/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 208.0747 - val_loss: 204.9267
Epoch 44/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 207.6583 - val_loss: 215.7893
Epoch 45/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 207.2719 - val_loss: 207.8257
Epoch 46/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 207.3380 - val_loss: 205.1311
Epoch 47/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 206.8768 - val_loss: 202.4019
Epoch 48/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 206.5902 - val_loss: 209.1818
Epoch 49/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 206.3142 - val_loss: 206.6652
Epoch 50/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 205.9467 - val_loss: 207.2999
Epoch 51/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 205.7026 - val_loss: 207.1468
Epoch 52/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 205.6086 - val_loss: 201.8379
Epoch 53/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 204.9805 - val_loss: 222.6575
Epoch 54/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 204.8842 - val_loss: 205.5940
Epoch 55/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 204.7309 - val_loss: 202.0723

         CHILD ACCURACY = 211.02983578429462


         PARENT ACCURACY = 198.89580707438708


 CHILD 3 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 2000

         EPOCHS = 55
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/55
2018-11-11 01:24:51.841317: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 01:24:51.846403: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 43s 5us/step - loss: 341.5970 - val_loss: 318.3530
Epoch 2/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 319.4487 - val_loss: 317.0902
Epoch 3/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3033 - val_loss: 317.0922
Epoch 4/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3033 - val_loss: 317.0899
Epoch 5/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 319.3034 - val_loss: 317.0912
Epoch 6/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 319.3033 - val_loss: 317.0893
Epoch 7/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 319.3034 - val_loss: 317.0908
Epoch 8/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 319.3033 - val_loss: 317.0899
Epoch 9/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 319.3034 - val_loss: 317.0902
Epoch 10/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 319.3034 - val_loss: 317.0910
Epoch 11/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 319.3033 - val_loss: 317.0895
Epoch 12/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 319.3035 - val_loss: 317.0905
Epoch 13/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 319.3035 - val_loss: 317.0917
Epoch 14/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 319.3033 - val_loss: 317.0904
Epoch 15/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 319.3034 - val_loss: 317.0903
Epoch 16/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3033 - val_loss: 317.0894
Epoch 17/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 319.3034 - val_loss: 317.0901
Epoch 18/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3033 - val_loss: 317.0896
Epoch 19/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3032 - val_loss: 317.0896
Epoch 20/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 319.3032 - val_loss: 317.0926
Epoch 21/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3033 - val_loss: 317.0893
Epoch 22/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3033 - val_loss: 317.0928
Epoch 23/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3036 - val_loss: 317.0903
Epoch 24/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3034 - val_loss: 317.0893
Epoch 25/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3035 - val_loss: 317.0898
Epoch 26/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3035 - val_loss: 317.0895
Epoch 27/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3034 - val_loss: 317.0916
Epoch 28/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3035 - val_loss: 317.0913
Epoch 29/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3033 - val_loss: 317.0896
Epoch 30/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3034 - val_loss: 317.0921
Epoch 31/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3036 - val_loss: 317.0898
Epoch 32/55
9445953/9445953 [==============================] - 43s 5us/step - loss: 319.3035 - val_loss: 317.0898
Epoch 33/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3034 - val_loss: 317.0895
Epoch 34/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3034 - val_loss: 317.0895
Epoch 35/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3033 - val_loss: 317.0898
Epoch 36/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3035 - val_loss: 317.0900
Epoch 37/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3033 - val_loss: 317.0922
Epoch 38/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3032 - val_loss: 317.0936
Epoch 39/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3035 - val_loss: 317.0896
Epoch 40/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3033 - val_loss: 317.0901
Epoch 41/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3033 - val_loss: 317.0902
Epoch 42/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3034 - val_loss: 317.0896
Epoch 43/55
9445953/9445953 [==============================] - 43s 4us/step - loss: 319.3034 - val_loss: 317.0915
Epoch 44/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3033 - val_loss: 317.0900
Epoch 45/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3034 - val_loss: 317.0917
Epoch 46/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3034 - val_loss: 317.0894
Epoch 47/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3034 - val_loss: 317.0895
Epoch 48/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3033 - val_loss: 317.0896
Epoch 49/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3032 - val_loss: 317.0904
Epoch 50/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3035 - val_loss: 317.0894
Epoch 51/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3035 - val_loss: 317.0903
Epoch 52/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3033 - val_loss: 317.0894
Epoch 53/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3033 - val_loss: 317.0920
Epoch 54/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3035 - val_loss: 317.0910
Epoch 55/55
9445953/9445953 [==============================] - 42s 4us/step - loss: 319.3035 - val_loss: 317.0902

         CHILD ACCURACY = 314.87791160219297


         PARENT ACCURACY = 198.89580707438708


 CHILD 4 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 2000

         EPOCHS = 45
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-11-11 02:03:43.478135: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 02:03:43.483445: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 43s 5us/step - loss: 286.2719 - val_loss: 269.6305
Epoch 2/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 266.0322 - val_loss: 258.5750
Epoch 3/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 257.1327 - val_loss: 256.2019
Epoch 4/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 251.7591 - val_loss: 250.7972
Epoch 5/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 247.8582 - val_loss: 243.1661
Epoch 6/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 245.0682 - val_loss: 242.2710
Epoch 7/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 242.6201 - val_loss: 237.3554
Epoch 8/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 240.4161 - val_loss: 235.2374
Epoch 9/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 237.8870 - val_loss: 239.4189
Epoch 10/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 234.7898 - val_loss: 229.3527
Epoch 11/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 231.8774 - val_loss: 230.6752
Epoch 12/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 229.5560 - val_loss: 223.9123
Epoch 13/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 227.6829 - val_loss: 223.4262
Epoch 14/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 226.1625 - val_loss: 219.8981
Epoch 15/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 224.7280 - val_loss: 218.9842
Epoch 16/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 223.4370 - val_loss: 220.3833
Epoch 17/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 222.5246 - val_loss: 226.7881
Epoch 18/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 221.1917 - val_loss: 221.4099
Epoch 19/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 220.4965 - val_loss: 219.7048
Epoch 20/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 219.5589 - val_loss: 216.4284
Epoch 21/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 218.6497 - val_loss: 217.4841
Epoch 22/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 217.8550 - val_loss: 213.0559
Epoch 23/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 217.0158 - val_loss: 217.6071
Epoch 24/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 216.4202 - val_loss: 214.8056
Epoch 25/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 215.6205 - val_loss: 211.2766
Epoch 26/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 214.9388 - val_loss: 213.8393
Epoch 27/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 214.4552 - val_loss: 216.8583
Epoch 28/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 213.7963 - val_loss: 210.6091
Epoch 29/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 213.1851 - val_loss: 208.7179
Epoch 30/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 212.7070 - val_loss: 214.1814
Epoch 31/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 212.1674 - val_loss: 207.6590
Epoch 32/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 211.6359 - val_loss: 208.5798
Epoch 33/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 211.2783 - val_loss: 210.7186
Epoch 34/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 210.8859 - val_loss: 205.7480
Epoch 35/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 210.3679 - val_loss: 210.6091
Epoch 36/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 209.9301 - val_loss: 204.7452
Epoch 37/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 209.6705 - val_loss: 202.8796
Epoch 38/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 209.1214 - val_loss: 203.2731
Epoch 39/45
9445953/9445953 [==============================] - 43s 4us/step - loss: 208.7736 - val_loss: 208.2169
Epoch 40/45
9445953/9445953 [==============================] - 45s 5us/step - loss: 208.3810 - val_loss: 205.2206
Epoch 41/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 208.1834 - val_loss: 212.5615
Epoch 42/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 207.6895 - val_loss: 210.6982
Epoch 43/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 207.3028 - val_loss: 213.1221
Epoch 44/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 206.9658 - val_loss: 207.1892
Epoch 45/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 206.7223 - val_loss: 205.3037

         CHILD ACCURACY = 210.98647895749514


         PARENT ACCURACY = 198.89580707438708



 QUEUE SIZE BEFORE GET = 7


 NODE SELECTED <<<------ Epochs = 50 -------- BatchSize = 4000 --------- Accuracy = 209.10942854792248 -------->>>


 CHILD 1 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 3000

         EPOCHS = 50
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/50
2018-11-11 02:35:38.991332: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 02:35:38.996751: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 293.5423 - val_loss: 287.5607
Epoch 2/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 274.7593 - val_loss: 270.3778
Epoch 3/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 269.8573 - val_loss: 263.1499
Epoch 4/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 260.1621 - val_loss: 252.5367
Epoch 5/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 253.1729 - val_loss: 249.8114
Epoch 6/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 248.4603 - val_loss: 246.1183
Epoch 7/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 244.8165 - val_loss: 239.1820
Epoch 8/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 241.9152 - val_loss: 241.4793
Epoch 9/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 239.3843 - val_loss: 240.0100
Epoch 10/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 237.0271 - val_loss: 247.3274
Epoch 11/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 234.5849 - val_loss: 234.9522
Epoch 12/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 231.9209 - val_loss: 228.2063
Epoch 13/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 229.5070 - val_loss: 230.5688
Epoch 14/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 227.3435 - val_loss: 222.4540
Epoch 15/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 225.4827 - val_loss: 218.5123
Epoch 16/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 223.8337 - val_loss: 223.1906
Epoch 17/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 222.6461 - val_loss: 231.5952
Epoch 18/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 221.3758 - val_loss: 216.8413
Epoch 19/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 220.2181 - val_loss: 224.8803
Epoch 20/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 219.0648 - val_loss: 226.8888
Epoch 21/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 218.2766 - val_loss: 218.9641
Epoch 22/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 217.3753 - val_loss: 223.9409
Epoch 23/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 216.5620 - val_loss: 215.0665
Epoch 24/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 215.7675 - val_loss: 213.2081
Epoch 25/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 215.1942 - val_loss: 213.9437
Epoch 26/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 214.3592 - val_loss: 223.4163
Epoch 27/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 213.7078 - val_loss: 209.2948
Epoch 28/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 212.9683 - val_loss: 212.6256
Epoch 29/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 212.2644 - val_loss: 205.7312
Epoch 30/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 212.0788 - val_loss: 212.0266
Epoch 31/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 211.3837 - val_loss: 209.5697
Epoch 32/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 210.7348 - val_loss: 203.4113
Epoch 33/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 210.2428 - val_loss: 207.7305
Epoch 34/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 209.8296 - val_loss: 210.0249
Epoch 35/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 209.1973 - val_loss: 205.5024
Epoch 36/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 208.5869 - val_loss: 205.4194
Epoch 37/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 208.4991 - val_loss: 208.5804
Epoch 38/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 208.0167 - val_loss: 208.7889
Epoch 39/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 207.6639 - val_loss: 204.2409
Epoch 40/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 207.2853 - val_loss: 209.5241
Epoch 41/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 206.8095 - val_loss: 203.5593
Epoch 42/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 206.4734 - val_loss: 204.9165
Epoch 43/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 205.9191 - val_loss: 204.8596
Epoch 44/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 205.6011 - val_loss: 204.6275
Epoch 45/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 205.1453 - val_loss: 201.6924
Epoch 46/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 204.9296 - val_loss: 199.8580
Epoch 47/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 204.5456 - val_loss: 204.5386
Epoch 48/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 204.1832 - val_loss: 202.8082
Epoch 49/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 203.5656 - val_loss: 201.7613
Epoch 50/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 203.4970 - val_loss: 203.7864

         CHILD ACCURACY = 202.49939837223877


         PARENT ACCURACY = 209.10942854792248


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 7 <<<<<<<<<<<<<<<<<<<<<<<<<<<


 CHILD 2 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 55
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/55
2018-11-11 03:03:18.992255: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 03:03:18.997293: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 26s 3us/step - loss: 303.1378 - val_loss: 277.8152
Epoch 2/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 276.2580 - val_loss: 272.3016
Epoch 3/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 269.3708 - val_loss: 261.8832
Epoch 4/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 260.1832 - val_loss: 258.1351
Epoch 5/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 252.8693 - val_loss: 254.1630
Epoch 6/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 248.1503 - val_loss: 250.7487
Epoch 7/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 244.4917 - val_loss: 246.1898
Epoch 8/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 241.5307 - val_loss: 239.2744
Epoch 9/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 238.6626 - val_loss: 277.5954
Epoch 10/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 236.1320 - val_loss: 237.9732
Epoch 11/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 233.4707 - val_loss: 248.1219
Epoch 12/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 230.6384 - val_loss: 231.8810
Epoch 13/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 228.1572 - val_loss: 227.8405
Epoch 14/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 225.8611 - val_loss: 233.8567
Epoch 15/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 223.7635 - val_loss: 230.0934
Epoch 16/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 222.4422 - val_loss: 226.6738
Epoch 17/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 220.8995 - val_loss: 222.2661
Epoch 18/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 219.4491 - val_loss: 226.3643
Epoch 19/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 218.6177 - val_loss: 227.4685
Epoch 20/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 217.3859 - val_loss: 225.1636
Epoch 21/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 216.3900 - val_loss: 215.8624
Epoch 22/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 215.7357 - val_loss: 214.5550
Epoch 23/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 214.7535 - val_loss: 213.2655
Epoch 24/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 213.9415 - val_loss: 218.8532
Epoch 25/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 213.1637 - val_loss: 230.8579
Epoch 26/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 212.5963 - val_loss: 221.0261
Epoch 27/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 211.7429 - val_loss: 219.0838
Epoch 28/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 211.3066 - val_loss: 227.1151
Epoch 29/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 210.6811 - val_loss: 207.9016
Epoch 30/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 210.2764 - val_loss: 245.7193
Epoch 31/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 209.7510 - val_loss: 214.9306
Epoch 32/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 209.0516 - val_loss: 206.1320
Epoch 33/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 208.5930 - val_loss: 206.3687
Epoch 34/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 208.0096 - val_loss: 234.4816
Epoch 35/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 207.7357 - val_loss: 230.3633
Epoch 36/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 207.0324 - val_loss: 206.7199
Epoch 37/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 206.8603 - val_loss: 209.5465
Epoch 38/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 206.4127 - val_loss: 205.9276
Epoch 39/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 205.8916 - val_loss: 211.5356
Epoch 40/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 205.4813 - val_loss: 224.1726
Epoch 41/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 205.3540 - val_loss: 226.2344
Epoch 42/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 205.0570 - val_loss: 206.8157
Epoch 43/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 204.4656 - val_loss: 247.0165
Epoch 44/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 204.1840 - val_loss: 227.3092
Epoch 45/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 203.8782 - val_loss: 200.2092
Epoch 46/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 203.6623 - val_loss: 213.3746
Epoch 47/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 203.3687 - val_loss: 231.5237
Epoch 48/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 202.8636 - val_loss: 208.1557
Epoch 49/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 202.6315 - val_loss: 214.3980
Epoch 50/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 202.3137 - val_loss: 207.5009
Epoch 51/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 202.0315 - val_loss: 204.1706
Epoch 52/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 201.8619 - val_loss: 223.0622
Epoch 53/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 201.5748 - val_loss: 198.0753
Epoch 54/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 201.3811 - val_loss: 205.6577
Epoch 55/55
9445953/9445953 [==============================] - 26s 3us/step - loss: 200.8328 - val_loss: 224.2870

         CHILD ACCURACY = 224.12844626421713


         PARENT ACCURACY = 209.10942854792248


 CHILD 3 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 50
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/50
2018-11-11 03:27:09.598669: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 03:27:09.603885: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 26s 3us/step - loss: 362.4365 - val_loss: 340.0974
Epoch 2/50
9445953/9445953 [==============================] - 25s 3us/step - loss: 331.6743 - val_loss: 321.6548
Epoch 3/50
9445953/9445953 [==============================] - 25s 3us/step - loss: 321.0306 - val_loss: 317.2862
Epoch 4/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3456 - val_loss: 317.0895
Epoch 5/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3031 - val_loss: 317.0903
Epoch 6/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3031 - val_loss: 317.0897
Epoch 7/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3032 - val_loss: 317.0901
Epoch 8/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3032 - val_loss: 317.0893
Epoch 9/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3032 - val_loss: 317.0898
Epoch 10/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3033 - val_loss: 317.0913
Epoch 11/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3032 - val_loss: 317.0893
Epoch 12/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3031 - val_loss: 317.0894
Epoch 13/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3033 - val_loss: 317.0905
Epoch 14/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3032 - val_loss: 317.0896
Epoch 15/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3032 - val_loss: 317.0909
Epoch 16/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3033 - val_loss: 317.0900
Epoch 17/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3032 - val_loss: 317.0903
Epoch 18/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3032 - val_loss: 317.0900
Epoch 19/50
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0895
Epoch 20/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3032 - val_loss: 317.0904
Epoch 21/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3033 - val_loss: 317.0896
Epoch 22/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3032 - val_loss: 317.0895
Epoch 23/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3033 - val_loss: 317.0896
Epoch 24/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3032 - val_loss: 317.0898
Epoch 25/50
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0895
Epoch 26/50
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3031 - val_loss: 317.0925
Epoch 27/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3031 - val_loss: 317.0930
Epoch 28/50
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3033 - val_loss: 317.0895
Epoch 29/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3032 - val_loss: 317.0894
Epoch 30/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3031 - val_loss: 317.0893
Epoch 31/50
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3029 - val_loss: 317.0943
Epoch 32/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3034 - val_loss: 317.0898
Epoch 33/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3031 - val_loss: 317.0922
Epoch 34/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3033 - val_loss: 317.0910
Epoch 35/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3032 - val_loss: 317.0893
Epoch 36/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3033 - val_loss: 317.0894
Epoch 37/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3033 - val_loss: 317.0902
Epoch 38/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3033 - val_loss: 317.0900
Epoch 39/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3032 - val_loss: 317.0906
Epoch 40/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3031 - val_loss: 317.0904
Epoch 41/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3032 - val_loss: 317.0893
Epoch 42/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3034 - val_loss: 317.0899
Epoch 43/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3033 - val_loss: 317.0893
Epoch 44/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3032 - val_loss: 317.0894
Epoch 45/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3032 - val_loss: 317.0895
Epoch 46/50
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0904
Epoch 47/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3033 - val_loss: 317.0907
Epoch 48/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3032 - val_loss: 317.0895
Epoch 49/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3031 - val_loss: 317.0910
Epoch 50/50
9445953/9445953 [==============================] - 26s 3us/step - loss: 319.3033 - val_loss: 317.0903

         CHILD ACCURACY = 314.87752599553926


         PARENT ACCURACY = 209.10942854792248


 CHILD 4 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 3000

         EPOCHS = 55
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/55
2018-11-11 03:48:30.144030: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 03:48:30.148895: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 295.8556 - val_loss: 293.4696
Epoch 2/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 272.9247 - val_loss: 264.2460
Epoch 3/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 261.8106 - val_loss: 257.9799
Epoch 4/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 253.6886 - val_loss: 247.3754
Epoch 5/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 249.1288 - val_loss: 243.8812
Epoch 6/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 246.0080 - val_loss: 243.2718
Epoch 7/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 243.1741 - val_loss: 241.0211
Epoch 8/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 240.7373 - val_loss: 234.7638
Epoch 9/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 238.6897 - val_loss: 233.5153
Epoch 10/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 236.5094 - val_loss: 238.4695
Epoch 11/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 234.0917 - val_loss: 231.4665
Epoch 12/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 231.1613 - val_loss: 227.4657
Epoch 13/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 228.9460 - val_loss: 224.9699
Epoch 14/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 226.9938 - val_loss: 222.5523
Epoch 15/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 225.1911 - val_loss: 222.0008
Epoch 16/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 223.7089 - val_loss: 222.6122
Epoch 17/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 222.5437 - val_loss: 221.9420
Epoch 18/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 221.3764 - val_loss: 221.5404
Epoch 19/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 220.3985 - val_loss: 218.9881
Epoch 20/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 219.3398 - val_loss: 218.8198
Epoch 21/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 218.4443 - val_loss: 223.8455
Epoch 22/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 217.6723 - val_loss: 213.0251
Epoch 23/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 216.9938 - val_loss: 213.4758
Epoch 24/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 216.1822 - val_loss: 213.9198
Epoch 25/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 215.6211 - val_loss: 213.4159
Epoch 26/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 214.9201 - val_loss: 210.1884
Epoch 27/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 214.2403 - val_loss: 209.2425
Epoch 28/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 213.6230 - val_loss: 207.8566
Epoch 29/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 212.7835 - val_loss: 207.4487
Epoch 30/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 212.2856 - val_loss: 213.3791
Epoch 31/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 211.8315 - val_loss: 208.3030
Epoch 32/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 211.3083 - val_loss: 209.0220
Epoch 33/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 210.9678 - val_loss: 206.9327
Epoch 34/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 210.3973 - val_loss: 206.4812
Epoch 35/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 209.8792 - val_loss: 210.3980
Epoch 36/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 209.4580 - val_loss: 208.5314
Epoch 37/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 209.0382 - val_loss: 205.7720
Epoch 38/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 208.9177 - val_loss: 230.0144
Epoch 39/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 208.3258 - val_loss: 204.1448
Epoch 40/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 207.9845 - val_loss: 212.6405
Epoch 41/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 207.6376 - val_loss: 203.9032
Epoch 42/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 207.3600 - val_loss: 232.6833
Epoch 43/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 207.0123 - val_loss: 204.7018
Epoch 44/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 206.6288 - val_loss: 205.1071
Epoch 45/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 206.4352 - val_loss: 203.6228
Epoch 46/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 205.9243 - val_loss: 200.8606
Epoch 47/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 205.7936 - val_loss: 208.2783
Epoch 48/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 205.4940 - val_loss: 205.7935
Epoch 49/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 205.2795 - val_loss: 199.9877
Epoch 50/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 204.9900 - val_loss: 204.8695
Epoch 51/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 204.8339 - val_loss: 203.9092
Epoch 52/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 204.3896 - val_loss: 200.4078
Epoch 53/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 204.1650 - val_loss: 209.4420
Epoch 54/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 203.8957 - val_loss: 204.3253
Epoch 55/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 203.5974 - val_loss: 201.3839

         CHILD ACCURACY = 203.76755200295798


         PARENT ACCURACY = 209.10942854792248


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 8 <<<<<<<<<<<<<<<<<<<<<<<<<<<


 CHILD 5 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 4000

         EPOCHS = 45
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-11-11 04:18:52.911497: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 04:18:52.915759: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 29s 3us/step - loss: 292.3953 - val_loss: 273.8902
Epoch 2/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 273.8754 - val_loss: 269.8680
Epoch 3/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 266.9431 - val_loss: 260.7337
Epoch 4/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 256.4753 - val_loss: 253.0627
Epoch 5/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 250.6431 - val_loss: 247.3817
Epoch 6/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 246.5089 - val_loss: 242.5797
Epoch 7/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 243.4570 - val_loss: 253.5574
Epoch 8/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 240.8904 - val_loss: 239.1258
Epoch 9/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 238.5604 - val_loss: 244.5103
Epoch 10/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 236.6182 - val_loss: 232.4181
Epoch 11/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 234.4491 - val_loss: 231.1841
Epoch 12/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 232.1824 - val_loss: 229.2772
Epoch 13/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 230.2501 - val_loss: 227.1542
Epoch 14/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 228.1834 - val_loss: 226.1262
Epoch 15/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 226.2577 - val_loss: 228.6767
Epoch 16/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 224.9528 - val_loss: 221.1015
Epoch 17/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 223.5897 - val_loss: 222.5734
Epoch 18/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 222.4658 - val_loss: 224.5175
Epoch 19/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 221.2138 - val_loss: 226.4164
Epoch 20/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 220.3061 - val_loss: 225.4525
Epoch 21/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 219.2637 - val_loss: 218.1555
Epoch 22/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 218.4678 - val_loss: 215.2074
Epoch 23/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 217.7347 - val_loss: 222.0724
Epoch 24/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 216.8396 - val_loss: 229.5059
Epoch 25/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 216.2917 - val_loss: 214.9116
Epoch 26/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 215.3705 - val_loss: 212.4670
Epoch 27/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 214.9443 - val_loss: 215.6847
Epoch 28/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 214.2726 - val_loss: 219.8930
Epoch 29/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 213.5632 - val_loss: 225.1982
Epoch 30/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 213.1215 - val_loss: 214.8573
Epoch 31/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 212.4763 - val_loss: 208.2694
Epoch 32/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 211.9700 - val_loss: 208.4878
Epoch 33/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 211.7310 - val_loss: 226.1198
Epoch 34/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 211.0844 - val_loss: 209.6161
Epoch 35/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 210.6412 - val_loss: 205.7456
Epoch 36/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 210.2202 - val_loss: 207.1224
Epoch 37/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 209.9291 - val_loss: 225.4029
Epoch 38/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 209.3774 - val_loss: 217.0273
Epoch 39/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 209.0841 - val_loss: 207.3502
Epoch 40/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 208.5535 - val_loss: 210.4464
Epoch 41/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 208.2324 - val_loss: 213.2244
Epoch 42/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 207.7990 - val_loss: 206.3051
Epoch 43/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 207.5817 - val_loss: 205.9680
Epoch 44/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 207.2579 - val_loss: 204.9220
Epoch 45/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 206.8500 - val_loss: 208.0318

         CHILD ACCURACY = 205.24129393018507


         PARENT ACCURACY = 209.10942854792248


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 9 <<<<<<<<<<<<<<<<<<<<<<<<<<<



 QUEUE SIZE BEFORE GET = 9


 NODE SELECTED <<<------ Epochs = 50 -------- BatchSize = 3000 --------- Accuracy = 202.49939837223877 -------->>>


 CHILD 1 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 2000

         EPOCHS = 50
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/50
2018-11-11 04:40:21.637326: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 04:40:21.643260: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 43s 5us/step - loss: 289.8312 - val_loss: 273.9420
Epoch 2/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 275.3478 - val_loss: 273.0995
Epoch 3/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 273.7452 - val_loss: 271.8678
Epoch 4/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 273.0335 - val_loss: 270.8219
Epoch 5/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 272.5114 - val_loss: 270.7288
Epoch 6/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 272.1134 - val_loss: 270.0927
Epoch 7/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 271.6534 - val_loss: 269.0596
Epoch 8/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 271.4286 - val_loss: 270.6748
Epoch 9/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 271.3041 - val_loss: 269.3135
Epoch 10/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 271.0824 - val_loss: 272.7892
Epoch 11/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 270.8541 - val_loss: 271.0323
Epoch 12/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 270.6877 - val_loss: 268.6845
Epoch 13/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 270.6093 - val_loss: 268.7440
Epoch 14/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 270.3510 - val_loss: 269.2647
Epoch 15/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 270.1849 - val_loss: 268.3448
Epoch 16/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 269.9831 - val_loss: 267.8578
Epoch 17/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 269.8491 - val_loss: 268.0453
Epoch 18/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 269.8215 - val_loss: 268.0620
Epoch 19/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 269.7909 - val_loss: 267.6464
Epoch 20/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 269.6032 - val_loss: 267.6784
Epoch 21/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 269.5322 - val_loss: 266.9968
Epoch 22/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 269.6145 - val_loss: 267.5073
Epoch 23/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 269.4078 - val_loss: 267.8109
Epoch 24/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 269.2435 - val_loss: 268.8317
Epoch 25/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 269.3519 - val_loss: 267.0825
Epoch 26/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 269.1457 - val_loss: 266.8682
Epoch 27/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 268.9458 - val_loss: 267.3159
Epoch 28/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 269.0555 - val_loss: 271.8035
Epoch 29/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 268.9303 - val_loss: 267.1624
Epoch 30/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 269.3449 - val_loss: 266.9089
Epoch 31/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 268.6533 - val_loss: 267.0307
Epoch 32/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 268.5889 - val_loss: 267.2404
Epoch 33/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 268.3089 - val_loss: 265.8005
Epoch 34/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 268.1405 - val_loss: 266.0465
Epoch 35/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 268.4386 - val_loss: 266.8277
Epoch 36/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 268.0309 - val_loss: 266.3967
Epoch 37/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 267.8161 - val_loss: 266.4957
Epoch 38/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 267.7202 - val_loss: 264.8469
Epoch 39/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 267.5413 - val_loss: 265.3201
Epoch 40/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 267.3688 - val_loss: 264.5800
Epoch 41/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 267.4314 - val_loss: 265.6045
Epoch 42/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 267.2745 - val_loss: 265.1942
Epoch 43/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 267.0536 - val_loss: 265.6526
Epoch 44/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 267.1395 - val_loss: 265.6081
Epoch 45/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 266.8511 - val_loss: 263.8938
Epoch 46/50
9445953/9445953 [==============================] - 43s 4us/step - loss: 265.2519 - val_loss: 259.6403
Epoch 47/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 262.3262 - val_loss: 257.6380
Epoch 48/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 259.1868 - val_loss: 255.2034
Epoch 49/50
9445953/9445953 [==============================] - 43s 5us/step - loss: 256.2042 - val_loss: 259.4941
Epoch 50/50
9445953/9445953 [==============================] - 42s 4us/step - loss: 254.4992 - val_loss: 248.0990

         CHILD ACCURACY = 252.16311337415033


         PARENT ACCURACY = 202.49939837223877


 CHILD 2 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 4000

         EPOCHS = 45
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-11-11 05:15:51.668953: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 05:15:51.675353: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 29s 3us/step - loss: 295.1557 - val_loss: 272.0169
Epoch 2/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 271.3629 - val_loss: 267.5471
Epoch 3/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 261.6616 - val_loss: 255.1292
Epoch 4/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 254.7210 - val_loss: 249.5138
Epoch 5/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 249.7614 - val_loss: 243.6699
Epoch 6/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 245.7196 - val_loss: 243.6581
Epoch 7/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 242.2395 - val_loss: 237.6894
Epoch 8/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 239.5236 - val_loss: 235.5114
Epoch 9/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 236.9525 - val_loss: 234.4053
Epoch 10/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 234.6312 - val_loss: 233.1100
Epoch 11/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 232.3976 - val_loss: 230.0108
Epoch 12/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 230.2848 - val_loss: 225.8157
Epoch 13/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 228.2237 - val_loss: 228.2741
Epoch 14/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 226.3772 - val_loss: 221.4736
Epoch 15/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 224.8549 - val_loss: 222.3579
Epoch 16/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 223.3671 - val_loss: 220.6001
Epoch 17/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 222.0967 - val_loss: 223.4940
Epoch 18/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 221.0322 - val_loss: 222.9723
Epoch 19/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 219.9650 - val_loss: 218.4818
Epoch 20/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 218.8966 - val_loss: 214.9055
Epoch 21/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 218.1153 - val_loss: 215.5429
Epoch 22/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 217.2230 - val_loss: 218.3486
Epoch 23/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 216.3408 - val_loss: 216.1077
Epoch 24/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 215.7179 - val_loss: 217.5263
Epoch 25/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 214.8855 - val_loss: 214.9058
Epoch 26/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 214.3215 - val_loss: 225.1024
Epoch 27/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 213.4620 - val_loss: 209.2951
Epoch 28/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 213.0695 - val_loss: 214.1476
Epoch 29/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 212.5940 - val_loss: 215.7947
Epoch 30/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 211.7161 - val_loss: 211.0872
Epoch 31/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 211.3011 - val_loss: 217.2153
Epoch 32/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 210.6822 - val_loss: 211.2959
Epoch 33/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 210.1933 - val_loss: 207.0898
Epoch 34/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 209.9370 - val_loss: 213.0931
Epoch 35/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 209.4924 - val_loss: 207.3247
Epoch 36/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 209.0025 - val_loss: 216.4520
Epoch 37/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 208.6881 - val_loss: 215.8819
Epoch 38/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 208.2282 - val_loss: 204.2005
Epoch 39/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 207.8005 - val_loss: 204.4580
Epoch 40/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 207.4715 - val_loss: 205.7016
Epoch 41/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 206.9949 - val_loss: 204.0553
Epoch 42/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 206.5957 - val_loss: 205.6180
Epoch 43/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 206.1026 - val_loss: 206.4820
Epoch 44/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 205.9130 - val_loss: 218.5958
Epoch 45/45
9445953/9445953 [==============================] - 29s 3us/step - loss: 205.5756 - val_loss: 203.2356

         CHILD ACCURACY = 210.91894724445729


         PARENT ACCURACY = 202.49939837223877


 CHILD 3 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 3000

         EPOCHS = 55
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/55
2018-11-11 05:37:21.317247: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 05:37:21.322799: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 290.5940 - val_loss: 276.4390
Epoch 2/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 268.9408 - val_loss: 258.9978
Epoch 3/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 258.6835 - val_loss: 251.0022
Epoch 4/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 252.0679 - val_loss: 248.7022
Epoch 5/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 247.6044 - val_loss: 242.6450
Epoch 6/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 244.2073 - val_loss: 242.3322
Epoch 7/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 241.4980 - val_loss: 237.9170
Epoch 8/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 239.1358 - val_loss: 235.0942
Epoch 9/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 236.8341 - val_loss: 232.6235
Epoch 10/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 234.2970 - val_loss: 235.1315
Epoch 11/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 231.5131 - val_loss: 228.0162
Epoch 12/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 228.6806 - val_loss: 226.6215
Epoch 13/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 226.2428 - val_loss: 222.7280
Epoch 14/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 224.5495 - val_loss: 226.1117
Epoch 15/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 222.9469 - val_loss: 220.5747
Epoch 16/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 221.5501 - val_loss: 214.3560
Epoch 17/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 220.4177 - val_loss: 218.8703
Epoch 18/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 219.3178 - val_loss: 220.3415
Epoch 19/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 218.4413 - val_loss: 220.1675
Epoch 20/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 217.5312 - val_loss: 209.9743
Epoch 21/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 216.5418 - val_loss: 222.8870
Epoch 22/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 215.6851 - val_loss: 211.5422
Epoch 23/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 214.9184 - val_loss: 208.7000
Epoch 24/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 214.1371 - val_loss: 211.4740
Epoch 25/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 213.5221 - val_loss: 206.4251
Epoch 26/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 212.7391 - val_loss: 209.6385
Epoch 27/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 212.1990 - val_loss: 210.9912
Epoch 28/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 211.5391 - val_loss: 210.7151
Epoch 29/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 211.0044 - val_loss: 216.6248
Epoch 30/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 210.3633 - val_loss: 206.7190
Epoch 31/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 209.8380 - val_loss: 210.5174
Epoch 32/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 209.5202 - val_loss: 213.6327
Epoch 33/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 208.8664 - val_loss: 203.9384
Epoch 34/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 208.3462 - val_loss: 204.1532
Epoch 35/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 207.8906 - val_loss: 222.4448
Epoch 36/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 207.5533 - val_loss: 212.8127
Epoch 37/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 207.0802 - val_loss: 204.5790
Epoch 38/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 206.7726 - val_loss: 204.2561
Epoch 39/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 206.3894 - val_loss: 215.7321
Epoch 40/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 206.0601 - val_loss: 205.2970
Epoch 41/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 205.7168 - val_loss: 204.9791
Epoch 42/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 205.2656 - val_loss: 211.8567
Epoch 43/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 204.9595 - val_loss: 202.9149
Epoch 44/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 204.8073 - val_loss: 201.7581
Epoch 45/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 204.4331 - val_loss: 210.9317
Epoch 46/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 203.9391 - val_loss: 206.9215
Epoch 47/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 203.6732 - val_loss: 200.0757
Epoch 48/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 203.5004 - val_loss: 203.7466
Epoch 49/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 203.3773 - val_loss: 200.7325
Epoch 50/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 205.8488 - val_loss: 200.9298
Epoch 51/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 203.2290 - val_loss: 203.3974
Epoch 52/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 203.0371 - val_loss: 199.6536
Epoch 53/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 203.0153 - val_loss: 220.6931
Epoch 54/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 202.2522 - val_loss: 203.4389
Epoch 55/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 202.6136 - val_loss: 199.3645

         CHILD ACCURACY = 208.8454899276233


         PARENT ACCURACY = 202.49939837223877


 CHILD 4 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 2000

         EPOCHS = 45
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-11-11 06:07:41.811156: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 06:07:41.818867: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 43s 5us/step - loss: 285.9443 - val_loss: 276.8338
Epoch 2/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 274.0738 - val_loss: 270.3797
Epoch 3/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 270.6624 - val_loss: 263.5294
Epoch 4/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 260.8162 - val_loss: 255.6459
Epoch 5/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 254.4718 - val_loss: 248.0304
Epoch 6/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 249.8088 - val_loss: 243.8349
Epoch 7/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 246.4011 - val_loss: 241.8622
Epoch 8/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 243.2770 - val_loss: 237.9532
Epoch 9/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 240.3919 - val_loss: 236.8780
Epoch 10/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 236.5449 - val_loss: 234.7112
Epoch 11/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 232.4983 - val_loss: 226.8852
Epoch 12/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 229.7629 - val_loss: 234.2795
Epoch 13/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 227.3942 - val_loss: 226.9388
Epoch 14/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 225.5539 - val_loss: 219.9245
Epoch 15/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 223.8473 - val_loss: 218.4090
Epoch 16/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 222.5543 - val_loss: 220.9094
Epoch 17/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 221.1575 - val_loss: 217.0566
Epoch 18/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 220.1164 - val_loss: 219.3589
Epoch 19/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 219.0556 - val_loss: 212.7713
Epoch 20/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 218.2923 - val_loss: 214.0667
Epoch 21/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 217.3594 - val_loss: 214.4063
Epoch 22/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 216.7173 - val_loss: 215.6836
Epoch 23/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 215.8849 - val_loss: 211.1448
Epoch 24/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 215.2469 - val_loss: 211.4812
Epoch 25/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 214.4765 - val_loss: 212.2179
Epoch 26/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 213.8714 - val_loss: 215.2727
Epoch 27/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 213.2415 - val_loss: 211.7050
Epoch 28/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 212.7728 - val_loss: 207.4178
Epoch 29/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 212.0395 - val_loss: 207.5719
Epoch 30/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 211.4865 - val_loss: 207.1531
Epoch 31/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 210.9290 - val_loss: 209.6984
Epoch 32/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 210.6640 - val_loss: 207.8850
Epoch 33/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 210.2547 - val_loss: 209.3305
Epoch 34/45
9445953/9445953 [==============================] - 44s 5us/step - loss: 209.7615 - val_loss: 210.1500
Epoch 35/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 209.5111 - val_loss: 208.9289
Epoch 36/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 209.0738 - val_loss: 202.2395
Epoch 37/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 208.6348 - val_loss: 206.1095
Epoch 38/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 208.8619 - val_loss: 204.8228
Epoch 39/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 207.8533 - val_loss: 203.6164
Epoch 40/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 207.6843 - val_loss: 209.4251
Epoch 41/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 207.3050 - val_loss: 203.4753
Epoch 42/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 207.1534 - val_loss: 205.8086
Epoch 43/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 206.5951 - val_loss: 203.9090
Epoch 44/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 206.6678 - val_loss: 201.4036
Epoch 45/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 206.0868 - val_loss: 215.6985

         CHILD ACCURACY = 206.784096340679


         PARENT ACCURACY = 202.49939837223877



 QUEUE SIZE BEFORE GET = 8


 NODE SELECTED <<<------ Epochs = 55 -------- BatchSize = 3000 --------- Accuracy = 203.76755200295798 -------->>>


 CHILD 1 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 4000

         EPOCHS = 55
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/55
2018-11-11 06:39:44.671145: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 06:39:44.676557: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 29s 3us/step - loss: 356.7815 - val_loss: 333.1913
Epoch 2/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 326.1092 - val_loss: 318.3086
Epoch 3/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.5814 - val_loss: 317.0893
Epoch 4/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0909
Epoch 5/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3031 - val_loss: 317.0892
Epoch 6/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3033 - val_loss: 317.0907
Epoch 7/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0918
Epoch 8/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3034 - val_loss: 317.0903
Epoch 9/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3033 - val_loss: 317.0893
Epoch 10/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0929
Epoch 11/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0900
Epoch 12/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3034 - val_loss: 317.0905
Epoch 13/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3033 - val_loss: 317.0900
Epoch 14/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3031 - val_loss: 317.0893
Epoch 15/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3034 - val_loss: 317.0897
Epoch 16/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3031 - val_loss: 317.0894
Epoch 17/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0893
Epoch 18/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0893
Epoch 19/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3033 - val_loss: 317.0907
Epoch 20/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3033 - val_loss: 317.0905
Epoch 21/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3034 - val_loss: 317.0900
Epoch 22/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3033 - val_loss: 317.0917
Epoch 23/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3033 - val_loss: 317.0899
Epoch 24/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0911
Epoch 25/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3033 - val_loss: 317.0906
Epoch 26/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0924
Epoch 27/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0896
Epoch 28/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0901
Epoch 29/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0897
Epoch 30/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3034 - val_loss: 317.0897
Epoch 31/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3033 - val_loss: 317.0894
Epoch 32/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3033 - val_loss: 317.0895
Epoch 33/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0916
Epoch 34/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0894
Epoch 35/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0903
Epoch 36/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0901
Epoch 37/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3031 - val_loss: 317.0921
Epoch 38/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3033 - val_loss: 317.0896
Epoch 39/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3033 - val_loss: 317.0904
Epoch 40/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3033 - val_loss: 317.0895
Epoch 41/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0899
Epoch 42/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3033 - val_loss: 317.0898
Epoch 43/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3030 - val_loss: 317.0898
Epoch 44/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3031 - val_loss: 317.0893
Epoch 45/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3033 - val_loss: 317.0896
Epoch 46/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3033 - val_loss: 317.0917
Epoch 47/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3034 - val_loss: 317.0894
Epoch 48/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0894
Epoch 49/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0894
Epoch 50/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0902
Epoch 51/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0902
Epoch 52/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3033 - val_loss: 317.0896
Epoch 53/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3031 - val_loss: 317.0894
Epoch 54/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3033 - val_loss: 317.0898
Epoch 55/55
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0893

         CHILD ACCURACY = 314.8758227926885


         PARENT ACCURACY = 203.76755200295798


 CHILD 2 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 2000

         EPOCHS = 60
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/60
2018-11-11 07:05:30.940015: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 07:05:30.944881: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 43s 5us/step - loss: 291.3395 - val_loss: 273.0215
Epoch 2/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 268.1868 - val_loss: 261.3117
Epoch 3/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 257.3229 - val_loss: 255.5111
Epoch 4/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 251.3225 - val_loss: 250.0781
Epoch 5/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 247.3680 - val_loss: 248.0657
Epoch 6/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 244.5309 - val_loss: 241.2381
Epoch 7/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 241.9709 - val_loss: 237.7508
Epoch 8/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 239.2228 - val_loss: 237.1653
Epoch 9/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 235.8093 - val_loss: 233.9787
Epoch 10/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 232.8514 - val_loss: 233.8942
Epoch 11/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 230.5668 - val_loss: 226.4211
Epoch 12/60
9445953/9445953 [==============================] - 42s 4us/step - loss: 228.7821 - val_loss: 224.8941
Epoch 13/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 226.9252 - val_loss: 222.3868
Epoch 14/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 225.4855 - val_loss: 222.1047
Epoch 15/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 224.1665 - val_loss: 224.8218
Epoch 16/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 223.0525 - val_loss: 217.1847
Epoch 17/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 221.9765 - val_loss: 219.8535
Epoch 18/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 220.9028 - val_loss: 220.8452
Epoch 19/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 219.8403 - val_loss: 214.3085
Epoch 20/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 219.0106 - val_loss: 214.2274
Epoch 21/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 218.3552 - val_loss: 216.6202
Epoch 22/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 217.5756 - val_loss: 213.1444
Epoch 23/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 216.7891 - val_loss: 213.6702
Epoch 24/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 216.0299 - val_loss: 219.5372
Epoch 25/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 215.4864 - val_loss: 212.7641
Epoch 26/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 214.9122 - val_loss: 227.5420
Epoch 27/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 214.3783 - val_loss: 209.7822
Epoch 28/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 213.8605 - val_loss: 217.3832
Epoch 29/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 213.1986 - val_loss: 209.8832
Epoch 30/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 212.6254 - val_loss: 206.9647
Epoch 31/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 212.3304 - val_loss: 218.7964
Epoch 32/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 212.4960 - val_loss: 209.1039
Epoch 33/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 211.6930 - val_loss: 207.2931
Epoch 34/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 210.9909 - val_loss: 207.8207
Epoch 35/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 210.7868 - val_loss: 210.3285
Epoch 36/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 210.3437 - val_loss: 208.7587
Epoch 37/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 209.8697 - val_loss: 206.4416
Epoch 38/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 209.4682 - val_loss: 206.8626
Epoch 39/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 209.1885 - val_loss: 206.7164
Epoch 40/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 208.7301 - val_loss: 208.1588
Epoch 41/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 208.5193 - val_loss: 204.9150
Epoch 42/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 208.1968 - val_loss: 200.9098
Epoch 43/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 207.8052 - val_loss: 204.8290
Epoch 44/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 207.8119 - val_loss: 212.9212
Epoch 45/60
9445953/9445953 [==============================] - 44s 5us/step - loss: 207.3966 - val_loss: 203.7149
Epoch 46/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 207.2912 - val_loss: 210.3758
Epoch 47/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 206.9211 - val_loss: 199.4971
Epoch 48/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 206.8503 - val_loss: 203.2336
Epoch 49/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 206.6091 - val_loss: 202.5999
Epoch 50/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 206.5913 - val_loss: 204.3714
Epoch 51/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 206.2876 - val_loss: 200.3094
Epoch 52/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 206.7078 - val_loss: 201.1690
Epoch 53/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 206.3278 - val_loss: 201.7304
Epoch 54/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 206.1962 - val_loss: 203.0660
Epoch 55/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 205.6003 - val_loss: 211.8591
Epoch 56/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 206.0093 - val_loss: 206.4663
Epoch 57/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 205.1273 - val_loss: 204.3630
Epoch 58/60
9445953/9445953 [==============================] - 42s 4us/step - loss: 206.9777 - val_loss: 201.5740
Epoch 59/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 205.2820 - val_loss: 198.6489
Epoch 60/60
9445953/9445953 [==============================] - 43s 5us/step - loss: 204.9869 - val_loss: 214.6845

         CHILD ACCURACY = 204.04171347040952


         PARENT ACCURACY = 203.76755200295798


 CHILD 3 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 3000

         EPOCHS = 60
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/60
2018-11-11 07:48:28.388005: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 07:48:28.392947: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 33s 3us/step - loss: 350.6325 - val_loss: 325.5000
Epoch 2/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 321.6005 - val_loss: 317.1184
Epoch 3/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3069 - val_loss: 317.0903
Epoch 4/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3028 - val_loss: 317.0893
Epoch 5/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3032 - val_loss: 317.0956
Epoch 6/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3033 - val_loss: 317.0899
Epoch 7/60
9445953/9445953 [==============================] - 32s 3us/step - loss: 319.3033 - val_loss: 317.0902
Epoch 8/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3032 - val_loss: 317.0897
Epoch 9/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3031 - val_loss: 317.0912
Epoch 10/60
9445953/9445953 [==============================] - 32s 3us/step - loss: 319.3034 - val_loss: 317.0900
Epoch 11/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3033 - val_loss: 317.0903
Epoch 12/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3034 - val_loss: 317.0899
Epoch 13/60
9445953/9445953 [==============================] - 32s 3us/step - loss: 319.3033 - val_loss: 317.0904
Epoch 14/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3035 - val_loss: 317.0903
Epoch 15/60
9445953/9445953 [==============================] - 32s 3us/step - loss: 319.3033 - val_loss: 317.0908
Epoch 16/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3034 - val_loss: 317.0908
Epoch 17/60
9445953/9445953 [==============================] - 32s 3us/step - loss: 319.3033 - val_loss: 317.0903
Epoch 18/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3033 - val_loss: 317.0910
Epoch 19/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3032 - val_loss: 317.0895
Epoch 20/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3033 - val_loss: 317.0897
Epoch 21/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3030 - val_loss: 317.0893
Epoch 22/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3033 - val_loss: 317.0920
Epoch 23/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3033 - val_loss: 317.0904
Epoch 24/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3033 - val_loss: 317.0912
Epoch 25/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3034 - val_loss: 317.0913
Epoch 26/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3034 - val_loss: 317.0896
Epoch 27/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3032 - val_loss: 317.0915
Epoch 28/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3034 - val_loss: 317.0894
Epoch 29/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3032 - val_loss: 317.0893
Epoch 30/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3032 - val_loss: 317.0893
Epoch 31/60
9445953/9445953 [==============================] - 32s 3us/step - loss: 319.3033 - val_loss: 317.0915
Epoch 32/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3034 - val_loss: 317.0897
Epoch 33/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3031 - val_loss: 317.0893
Epoch 34/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3032 - val_loss: 317.0938
Epoch 35/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3033 - val_loss: 317.0931
Epoch 36/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3034 - val_loss: 317.0909
Epoch 37/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3032 - val_loss: 317.0909
Epoch 38/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3033 - val_loss: 317.0892
Epoch 39/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3034 - val_loss: 317.0900
Epoch 40/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3032 - val_loss: 317.0893
Epoch 41/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3034 - val_loss: 317.0893
Epoch 42/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3034 - val_loss: 317.0899
Epoch 43/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3030 - val_loss: 317.0895
Epoch 44/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3032 - val_loss: 317.0894
Epoch 45/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3034 - val_loss: 317.0895
Epoch 46/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3034 - val_loss: 317.0917
Epoch 47/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3033 - val_loss: 317.0894
Epoch 48/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3031 - val_loss: 317.0918
Epoch 49/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3033 - val_loss: 317.0898
Epoch 50/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3034 - val_loss: 317.0902
Epoch 51/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3034 - val_loss: 317.0898
Epoch 52/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3034 - val_loss: 317.0905
Epoch 53/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3032 - val_loss: 317.0894
Epoch 54/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3034 - val_loss: 317.0894
Epoch 55/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3033 - val_loss: 317.0902
Epoch 56/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3030 - val_loss: 317.0893
Epoch 57/60
9445953/9445953 [==============================] - 32s 3us/step - loss: 319.3034 - val_loss: 317.0901
Epoch 58/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3032 - val_loss: 317.0893
Epoch 59/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3034 - val_loss: 317.0900
Epoch 60/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 319.3033 - val_loss: 317.0896

         CHILD ACCURACY = 314.8761376113201


         PARENT ACCURACY = 203.76755200295798


 CHILD 4 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 4000

         EPOCHS = 60
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/60
2018-11-11 08:21:06.674992: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 08:21:06.680845: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 29s 3us/step - loss: 294.3409 - val_loss: 275.0635
Epoch 2/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 274.4352 - val_loss: 277.2405
Epoch 3/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 265.6391 - val_loss: 262.7139
Epoch 4/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 256.9265 - val_loss: 255.1289
Epoch 5/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 250.8857 - val_loss: 243.4763
Epoch 6/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 246.7298 - val_loss: 240.9067
Epoch 7/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 243.3823 - val_loss: 238.9159
Epoch 8/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 240.7186 - val_loss: 236.6162
Epoch 9/60
9445953/9445953 [==============================] - 28s 3us/step - loss: 238.6229 - val_loss: 239.9118
Epoch 10/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 236.4745 - val_loss: 232.3626
Epoch 11/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 234.6237 - val_loss: 247.5023
Epoch 12/60
9445953/9445953 [==============================] - 28s 3us/step - loss: 232.2489 - val_loss: 232.6334
Epoch 13/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 229.6816 - val_loss: 230.7091
Epoch 14/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 226.9080 - val_loss: 225.7374
Epoch 15/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 224.5023 - val_loss: 221.2172
Epoch 16/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 222.7040 - val_loss: 231.7908
Epoch 17/60
9445953/9445953 [==============================] - 28s 3us/step - loss: 221.2140 - val_loss: 222.8511
Epoch 18/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 220.1208 - val_loss: 220.5664
Epoch 19/60
9445953/9445953 [==============================] - 28s 3us/step - loss: 218.8739 - val_loss: 216.6607
Epoch 20/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 217.7587 - val_loss: 238.4019
Epoch 21/60
9445953/9445953 [==============================] - 28s 3us/step - loss: 216.9168 - val_loss: 219.8644
Epoch 22/60
9445953/9445953 [==============================] - 28s 3us/step - loss: 216.1560 - val_loss: 227.5158
Epoch 23/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 215.0919 - val_loss: 214.3110
Epoch 24/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 214.6890 - val_loss: 211.8434
Epoch 25/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 213.8136 - val_loss: 225.6020
Epoch 26/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 213.3319 - val_loss: 206.8210
Epoch 27/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 212.5088 - val_loss: 211.4501
Epoch 28/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 212.0374 - val_loss: 214.8395
Epoch 29/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 211.3464 - val_loss: 210.9228
Epoch 30/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 210.8709 - val_loss: 208.0321
Epoch 31/60
9445953/9445953 [==============================] - 28s 3us/step - loss: 210.2141 - val_loss: 206.9850
Epoch 32/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 209.7037 - val_loss: 213.9080
Epoch 33/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 209.2111 - val_loss: 205.6788
Epoch 34/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 208.9179 - val_loss: 207.3663
Epoch 35/60
9445953/9445953 [==============================] - 28s 3us/step - loss: 208.1845 - val_loss: 203.0819
Epoch 36/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 207.9424 - val_loss: 229.9080
Epoch 37/60
9445953/9445953 [==============================] - 28s 3us/step - loss: 207.2793 - val_loss: 222.6343
Epoch 38/60
9445953/9445953 [==============================] - 28s 3us/step - loss: 206.9141 - val_loss: 219.7061
Epoch 39/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 206.3175 - val_loss: 223.6399
Epoch 40/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 206.0502 - val_loss: 215.6119
Epoch 41/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 205.6782 - val_loss: 204.1073
Epoch 42/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 205.3147 - val_loss: 208.6949
Epoch 43/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 204.7659 - val_loss: 219.3295
Epoch 44/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 204.4537 - val_loss: 209.5463
Epoch 45/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 204.2163 - val_loss: 208.8458
Epoch 46/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 203.7073 - val_loss: 238.0364
Epoch 47/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 203.5203 - val_loss: 197.8915
Epoch 48/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 203.0714 - val_loss: 208.9290
Epoch 49/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 202.9788 - val_loss: 207.2229
Epoch 50/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 202.4935 - val_loss: 219.5731
Epoch 51/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 202.1187 - val_loss: 202.5436
Epoch 52/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 201.8544 - val_loss: 210.4447
Epoch 53/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 201.4352 - val_loss: 200.0384
Epoch 54/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 201.4202 - val_loss: 215.8463
Epoch 55/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 200.8955 - val_loss: 199.9691
Epoch 56/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 200.7650 - val_loss: 203.2123
Epoch 57/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 200.4774 - val_loss: 202.8045
Epoch 58/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 200.1940 - val_loss: 199.9978
Epoch 59/60
9445953/9445953 [==============================] - 28s 3us/step - loss: 199.9687 - val_loss: 201.2118
Epoch 60/60
9445953/9445953 [==============================] - 29s 3us/step - loss: 199.8327 - val_loss: 210.4727

         CHILD ACCURACY = 207.1252117100665


         PARENT ACCURACY = 203.76755200295798



 QUEUE SIZE BEFORE GET = 7


 NODE SELECTED <<<------ Epochs = 45 -------- BatchSize = 4000 --------- Accuracy = 205.24129393018507 -------->>>


 CHILD 1 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 4000

         EPOCHS = 40
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/40
2018-11-11 08:49:42.606240: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 08:49:42.611127: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 29s 3us/step - loss: 289.9987 - val_loss: 271.9521
Epoch 2/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 269.2307 - val_loss: 261.2228
Epoch 3/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 259.6806 - val_loss: 254.0422
Epoch 4/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 252.7449 - val_loss: 245.8516
Epoch 5/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 247.7548 - val_loss: 241.6400
Epoch 6/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 244.1245 - val_loss: 247.6116
Epoch 7/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 241.1611 - val_loss: 240.8840
Epoch 8/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 238.5975 - val_loss: 232.4939
Epoch 9/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 235.9906 - val_loss: 228.5767
Epoch 10/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 233.1960 - val_loss: 236.6439
Epoch 11/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 230.5747 - val_loss: 228.8666
Epoch 12/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 228.2714 - val_loss: 222.8762
Epoch 13/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 226.4369 - val_loss: 221.0913
Epoch 14/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 224.8788 - val_loss: 222.5956
Epoch 15/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 223.3285 - val_loss: 219.8390
Epoch 16/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 221.9025 - val_loss: 227.9801
Epoch 17/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 220.8319 - val_loss: 223.1402
Epoch 18/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 219.5993 - val_loss: 214.4519
Epoch 19/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 218.3800 - val_loss: 219.3727
Epoch 20/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 217.6905 - val_loss: 221.4425
Epoch 21/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 216.9110 - val_loss: 218.8489
Epoch 22/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 215.9936 - val_loss: 212.5850
Epoch 23/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 215.0595 - val_loss: 225.2311
Epoch 24/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 214.4488 - val_loss: 217.7002
Epoch 25/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 213.5775 - val_loss: 209.4571
Epoch 26/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 212.8845 - val_loss: 210.7538
Epoch 27/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 212.1868 - val_loss: 208.5051
Epoch 28/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 211.7620 - val_loss: 215.7782
Epoch 29/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 211.1295 - val_loss: 221.6052
Epoch 30/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 210.5399 - val_loss: 208.8237
Epoch 31/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 210.0145 - val_loss: 213.3126
Epoch 32/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 209.5826 - val_loss: 204.5062
Epoch 33/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 209.0129 - val_loss: 209.8081
Epoch 34/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 208.5026 - val_loss: 211.2449
Epoch 35/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 208.1032 - val_loss: 217.6789
Epoch 36/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 207.6765 - val_loss: 220.5627
Epoch 37/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 207.1502 - val_loss: 204.6441
Epoch 38/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 206.6524 - val_loss: 211.3958
Epoch 39/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 206.3055 - val_loss: 208.8604
Epoch 40/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 205.9529 - val_loss: 204.6900

         CHILD ACCURACY = 208.2798720005916


         PARENT ACCURACY = 205.24129393018507


 CHILD 2 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 3000

         EPOCHS = 40
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/40
2018-11-11 09:08:45.534520: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 09:08:45.539448: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 290.3040 - val_loss: 271.9857
Epoch 2/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 271.3105 - val_loss: 264.9650
Epoch 3/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 261.0432 - val_loss: 257.8781
Epoch 4/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 253.6880 - val_loss: 252.1022
Epoch 5/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 248.8084 - val_loss: 244.8245
Epoch 6/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 245.0407 - val_loss: 242.4238
Epoch 7/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 242.4502 - val_loss: 240.1721
Epoch 8/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 240.1795 - val_loss: 234.8443
Epoch 9/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 237.9382 - val_loss: 233.2740
Epoch 10/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 236.0944 - val_loss: 235.7560
Epoch 11/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 233.9426 - val_loss: 230.7350
Epoch 12/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 231.7810 - val_loss: 230.6259
Epoch 13/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 229.9779 - val_loss: 226.2605
Epoch 14/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 228.2829 - val_loss: 226.2810
Epoch 15/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 226.6497 - val_loss: 224.2861
Epoch 16/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 225.3132 - val_loss: 222.4092
Epoch 17/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 224.1420 - val_loss: 217.8788
Epoch 18/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 222.8641 - val_loss: 221.5148
Epoch 19/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 221.9852 - val_loss: 217.9642
Epoch 20/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 221.0733 - val_loss: 222.6569
Epoch 21/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 220.0679 - val_loss: 221.2520
Epoch 22/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 219.1701 - val_loss: 215.6869
Epoch 23/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 218.3662 - val_loss: 213.1434
Epoch 24/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 217.8062 - val_loss: 214.8856
Epoch 25/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 216.9839 - val_loss: 217.1381
Epoch 26/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 216.2348 - val_loss: 217.5227
Epoch 27/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 215.6351 - val_loss: 213.0216
Epoch 28/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 214.9884 - val_loss: 211.2932
Epoch 29/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 214.2532 - val_loss: 221.7984
Epoch 30/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 213.9623 - val_loss: 209.1870
Epoch 31/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 213.2425 - val_loss: 217.1423
Epoch 32/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 212.7797 - val_loss: 213.1496
Epoch 33/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 212.2284 - val_loss: 205.8129
Epoch 34/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 211.5715 - val_loss: 213.0227
Epoch 35/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 211.3356 - val_loss: 207.6815
Epoch 36/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 210.8027 - val_loss: 210.2191
Epoch 37/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 210.6043 - val_loss: 205.2352
Epoch 38/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 209.9389 - val_loss: 205.6663
Epoch 39/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 209.7464 - val_loss: 207.7918
Epoch 40/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 209.0585 - val_loss: 204.0108

         CHILD ACCURACY = 201.51506594389141


         PARENT ACCURACY = 205.24129393018507


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 7 <<<<<<<<<<<<<<<<<<<<<<<<<<<


 CHILD 3 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 40
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/40
2018-11-11 09:30:52.899211: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 09:30:52.903304: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 26s 3us/step - loss: 298.9680 - val_loss: 282.7364
Epoch 2/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 277.4426 - val_loss: 277.4548
Epoch 3/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 272.9288 - val_loss: 288.1397
Epoch 4/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 266.5201 - val_loss: 259.5965
Epoch 5/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 257.4713 - val_loss: 266.7098
Epoch 6/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 251.4916 - val_loss: 256.0412
Epoch 7/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 247.2193 - val_loss: 243.8394
Epoch 8/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 244.1308 - val_loss: 250.2195
Epoch 9/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 241.5018 - val_loss: 238.5191
Epoch 10/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 239.3896 - val_loss: 254.0171
Epoch 11/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 237.3962 - val_loss: 246.5766
Epoch 12/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 235.3566 - val_loss: 242.9796
Epoch 13/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 233.2056 - val_loss: 238.5634
Epoch 14/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 231.1859 - val_loss: 241.3030
Epoch 15/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 229.3072 - val_loss: 229.1605
Epoch 16/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 227.6105 - val_loss: 228.1693
Epoch 17/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 226.0111 - val_loss: 227.0142
Epoch 18/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 224.7973 - val_loss: 225.2845
Epoch 19/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 223.6285 - val_loss: 235.8336
Epoch 20/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 222.5352 - val_loss: 225.2732
Epoch 21/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 221.5342 - val_loss: 220.4834
Epoch 22/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 220.6966 - val_loss: 231.9048
Epoch 23/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 219.8066 - val_loss: 228.5808
Epoch 24/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 219.0734 - val_loss: 242.2272
Epoch 25/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 218.1848 - val_loss: 214.9857
Epoch 26/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 217.6154 - val_loss: 220.4601
Epoch 27/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 216.9386 - val_loss: 219.2889
Epoch 28/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 216.1849 - val_loss: 225.3876
Epoch 29/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 215.7928 - val_loss: 242.4224
Epoch 30/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 215.2166 - val_loss: 222.4832
Epoch 31/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 214.5549 - val_loss: 221.9581
Epoch 32/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 214.1764 - val_loss: 214.9714
Epoch 33/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 213.6973 - val_loss: 212.0264
Epoch 34/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 213.1950 - val_loss: 215.3032
Epoch 35/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 212.7627 - val_loss: 211.7325
Epoch 36/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 212.3870 - val_loss: 211.0320
Epoch 37/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 211.9916 - val_loss: 220.3843
Epoch 38/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 211.4442 - val_loss: 223.7498
Epoch 39/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 211.1715 - val_loss: 222.9975
Epoch 40/40
9445953/9445953 [==============================] - 26s 3us/step - loss: 210.5770 - val_loss: 225.1796

         CHILD ACCURACY = 234.85954191856212


         PARENT ACCURACY = 205.24129393018507


 CHILD 4 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 3000

         EPOCHS = 45
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-11-11 09:48:13.004141: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 09:48:13.009487: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 291.1458 - val_loss: 273.8682
Epoch 2/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 268.5955 - val_loss: 259.3285
Epoch 3/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 258.6503 - val_loss: 257.1458
Epoch 4/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 252.3711 - val_loss: 246.8333
Epoch 5/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 248.0150 - val_loss: 248.7194
Epoch 6/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 244.8197 - val_loss: 240.5461
Epoch 7/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 242.0663 - val_loss: 239.1034
Epoch 8/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 239.5269 - val_loss: 235.2858
Epoch 9/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 236.8856 - val_loss: 234.0070
Epoch 10/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 234.0012 - val_loss: 233.6727
Epoch 11/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 231.1331 - val_loss: 226.7512
Epoch 12/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 228.6562 - val_loss: 224.1851
Epoch 13/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 226.4717 - val_loss: 224.4745
Epoch 14/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 224.8943 - val_loss: 220.0715
Epoch 15/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 223.2571 - val_loss: 222.3560
Epoch 16/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 221.9524 - val_loss: 216.7777
Epoch 17/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 220.7013 - val_loss: 220.3194
Epoch 18/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 219.5461 - val_loss: 213.5479
Epoch 19/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 218.5940 - val_loss: 212.1274
Epoch 20/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 217.6293 - val_loss: 211.5124
Epoch 21/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 216.8689 - val_loss: 215.1051
Epoch 22/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 215.8778 - val_loss: 219.5710
Epoch 23/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 214.9936 - val_loss: 215.2154
Epoch 24/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 214.2923 - val_loss: 216.9201
Epoch 25/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 213.8578 - val_loss: 208.3483
Epoch 26/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 213.0601 - val_loss: 215.0925
Epoch 27/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 212.5566 - val_loss: 217.3179
Epoch 28/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 212.0350 - val_loss: 212.0396
Epoch 29/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 211.4285 - val_loss: 209.3284
Epoch 30/45
9445953/9445953 [==============================] - 38s 4us/step - loss: 210.8475 - val_loss: 210.0166
Epoch 31/45
9445953/9445953 [==============================] - 41s 4us/step - loss: 210.2891 - val_loss: 208.9561
Epoch 32/45
9445953/9445953 [==============================] - 44s 5us/step - loss: 209.7457 - val_loss: 204.6841
Epoch 33/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 209.4623 - val_loss: 206.2906
Epoch 34/45
9445953/9445953 [==============================] - 46s 5us/step - loss: 208.8902 - val_loss: 207.9915
Epoch 35/45
9445953/9445953 [==============================] - 48s 5us/step - loss: 208.4573 - val_loss: 216.2409
Epoch 36/45
9445953/9445953 [==============================] - 44s 5us/step - loss: 208.0470 - val_loss: 208.2281
Epoch 37/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 207.7365 - val_loss: 206.2559
Epoch 38/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 207.3396 - val_loss: 222.0278
Epoch 39/45
9445953/9445953 [==============================] - 44s 5us/step - loss: 207.1749 - val_loss: 209.0114
Epoch 40/45
9445953/9445953 [==============================] - 47s 5us/step - loss: 206.6917 - val_loss: 203.5134
Epoch 41/45
9445953/9445953 [==============================] - 45s 5us/step - loss: 206.2465 - val_loss: 204.8412
Epoch 42/45
9445953/9445953 [==============================] - 45s 5us/step - loss: 206.0350 - val_loss: 202.5892
Epoch 43/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 205.6272 - val_loss: 202.9783
Epoch 44/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 205.2896 - val_loss: 206.5758
Epoch 45/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 205.0385 - val_loss: 205.2061

         CHILD ACCURACY = 203.17708960797904


         PARENT ACCURACY = 205.24129393018507


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 8 <<<<<<<<<<<<<<<<<<<<<<<<<<<



 QUEUE SIZE BEFORE GET = 8


 NODE SELECTED <<<------ Epochs = 40 -------- BatchSize = 3000 --------- Accuracy = 201.51506594389141 -------->>>


 CHILD 1 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 2000

         EPOCHS = 35
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/35
2018-11-11 10:15:32.196408: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 10:15:32.201391: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 43s 5us/step - loss: 286.3016 - val_loss: 272.1372
Epoch 2/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 266.1286 - val_loss: 258.0019
Epoch 3/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 256.4222 - val_loss: 248.7176
Epoch 4/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 250.7869 - val_loss: 246.0325
Epoch 5/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 247.1485 - val_loss: 242.6351
Epoch 6/35
9445953/9445953 [==============================] - 44s 5us/step - loss: 244.2491 - val_loss: 243.2884
Epoch 7/35
9445953/9445953 [==============================] - 47s 5us/step - loss: 241.9317 - val_loss: 237.7702
Epoch 8/35
9445953/9445953 [==============================] - 47s 5us/step - loss: 239.7101 - val_loss: 237.5151
Epoch 9/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 237.8281 - val_loss: 235.4981
Epoch 10/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 235.5371 - val_loss: 232.0279
Epoch 11/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 232.7941 - val_loss: 227.1043
Epoch 12/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 229.8487 - val_loss: 224.5039
Epoch 13/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 227.5119 - val_loss: 231.8787
Epoch 14/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 225.5776 - val_loss: 223.4891
Epoch 15/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 223.9080 - val_loss: 217.3578
Epoch 16/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 222.5384 - val_loss: 224.4545
Epoch 17/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 221.2379 - val_loss: 223.3888
Epoch 18/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 220.0893 - val_loss: 214.5437
Epoch 19/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 219.2030 - val_loss: 216.0419
Epoch 20/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 218.2650 - val_loss: 211.9514
Epoch 21/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 224.7650 - val_loss: 276.2249
Epoch 22/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 264.7832 - val_loss: 254.3017
Epoch 23/35
9445953/9445953 [==============================] - 44s 5us/step - loss: 252.4435 - val_loss: 244.4518
Epoch 24/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 244.8004 - val_loss: 237.6571
Epoch 25/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 241.0880 - val_loss: 234.2621
Epoch 26/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 236.9675 - val_loss: 231.2809
Epoch 27/35
9445953/9445953 [==============================] - 43s 5us/step - loss: 234.1718 - val_loss: 229.6921
Epoch 28/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 231.5629 - val_loss: 226.9935
Epoch 29/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 230.1552 - val_loss: 223.7737
Epoch 30/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 230.6554 - val_loss: 221.7871
Epoch 31/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 226.4936 - val_loss: 224.5043
Epoch 32/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 226.6409 - val_loss: 222.3770
Epoch 33/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 225.7713 - val_loss: 217.4391
Epoch 34/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 230.0880 - val_loss: 222.0932
Epoch 35/35
9445953/9445953 [==============================] - 42s 4us/step - loss: 224.7305 - val_loss: 218.1132

         CHILD ACCURACY = 213.20360892211363


         PARENT ACCURACY = 201.51506594389141


 CHILD 2 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 3000

         EPOCHS = 35
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/35
2018-11-11 10:40:28.111004: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 10:40:28.116056: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 33s 4us/step - loss: 288.9553 - val_loss: 275.1938
Epoch 2/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 269.8848 - val_loss: 262.0224
Epoch 3/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 259.5525 - val_loss: 252.8131
Epoch 4/35
9445953/9445953 [==============================] - 33s 4us/step - loss: 252.5236 - val_loss: 245.3703
Epoch 5/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 247.7932 - val_loss: 242.1084
Epoch 6/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 244.1506 - val_loss: 238.5737
Epoch 7/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 241.1451 - val_loss: 242.4622
Epoch 8/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 237.8701 - val_loss: 234.3620
Epoch 9/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 234.1825 - val_loss: 226.2146
Epoch 10/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 230.6190 - val_loss: 224.6184
Epoch 11/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 227.8211 - val_loss: 222.6680
Epoch 12/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 225.6112 - val_loss: 223.4672
Epoch 13/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 223.7197 - val_loss: 219.7226
Epoch 14/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 222.1697 - val_loss: 225.5301
Epoch 15/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 220.6650 - val_loss: 216.3148
Epoch 16/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 219.5162 - val_loss: 215.6405
Epoch 17/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 218.2181 - val_loss: 215.7273
Epoch 18/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 217.3989 - val_loss: 216.6150
Epoch 19/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 216.3116 - val_loss: 214.7140
Epoch 20/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 215.3489 - val_loss: 217.5109
Epoch 21/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 214.4686 - val_loss: 213.2179
Epoch 22/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 213.5290 - val_loss: 213.9710
Epoch 23/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 212.9442 - val_loss: 208.9800
Epoch 24/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 212.2273 - val_loss: 207.6011
Epoch 25/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 211.4401 - val_loss: 218.2015
Epoch 26/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 210.8635 - val_loss: 214.2073
Epoch 27/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 210.2376 - val_loss: 207.4431
Epoch 28/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 209.6359 - val_loss: 205.0420
Epoch 29/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 208.9429 - val_loss: 217.5228
Epoch 30/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 208.5963 - val_loss: 207.1472
Epoch 31/35
9445953/9445953 [==============================] - 33s 3us/step - loss: 207.7598 - val_loss: 206.2114
Epoch 32/35
9445953/9445953 [==============================] - 33s 4us/step - loss: 207.4292 - val_loss: 217.8579
Epoch 33/35
9445953/9445953 [==============================] - 36s 4us/step - loss: 206.8934 - val_loss: 207.3783
Epoch 34/35
9445953/9445953 [==============================] - 39s 4us/step - loss: 206.4167 - val_loss: 206.1009
Epoch 35/35
9445953/9445953 [==============================] - 37s 4us/step - loss: 205.8086 - val_loss: 212.7928

         CHILD ACCURACY = 215.42800763566902


         PARENT ACCURACY = 201.51506594389141


 CHILD 3 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 4000

         EPOCHS = 35
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/35
2018-11-11 10:59:52.598637: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 10:59:52.611101: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 29s 3us/step - loss: 293.5762 - val_loss: 277.4320
Epoch 2/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 274.7085 - val_loss: 274.5120
Epoch 3/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 269.1207 - val_loss: 269.9104
Epoch 4/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 259.5332 - val_loss: 254.8016
Epoch 5/35
9445953/9445953 [==============================] - 29s 3us/step - loss: 252.8359 - val_loss: 250.8539
Epoch 6/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 248.3053 - val_loss: 247.6948
Epoch 7/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 244.8939 - val_loss: 240.4914
Epoch 8/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 242.0822 - val_loss: 238.3681
Epoch 9/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 239.8921 - val_loss: 236.9535
Epoch 10/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 237.7005 - val_loss: 234.6262
Epoch 11/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 235.8325 - val_loss: 234.1829
Epoch 12/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 233.7106 - val_loss: 231.0568
Epoch 13/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 231.4583 - val_loss: 229.4739
Epoch 14/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 229.0845 - val_loss: 236.4723
Epoch 15/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 226.8492 - val_loss: 223.7473
Epoch 16/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 225.0042 - val_loss: 223.2646
Epoch 17/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 223.5198 - val_loss: 219.9766
Epoch 18/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 222.1029 - val_loss: 219.3466
Epoch 19/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 220.8880 - val_loss: 219.1048
Epoch 20/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 219.7936 - val_loss: 219.9299
Epoch 21/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 218.6824 - val_loss: 221.5106
Epoch 22/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 217.8351 - val_loss: 222.4490
Epoch 23/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 216.8311 - val_loss: 212.2370
Epoch 24/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 216.0898 - val_loss: 217.3969
Epoch 25/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 215.2774 - val_loss: 211.0096
Epoch 26/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 214.5237 - val_loss: 211.9512
Epoch 27/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 213.8298 - val_loss: 224.4323
Epoch 28/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 213.2400 - val_loss: 207.8208
Epoch 29/35
9445953/9445953 [==============================] - 29s 3us/step - loss: 212.5057 - val_loss: 209.2864
Epoch 30/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 211.8528 - val_loss: 213.5295
Epoch 31/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 211.4224 - val_loss: 217.2395
Epoch 32/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 210.9589 - val_loss: 214.4758
Epoch 33/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 210.1094 - val_loss: 206.4624
Epoch 34/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 209.7951 - val_loss: 206.9411
Epoch 35/35
9445953/9445953 [==============================] - 28s 3us/step - loss: 209.4628 - val_loss: 205.3347

         CHILD ACCURACY = 206.52540564415875


         PARENT ACCURACY = 201.51506594389141


 CHILD 4 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 2000

         EPOCHS = 40
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/40
2018-11-11 11:16:27.835398: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 11:16:27.841751: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 43s 5us/step - loss: 284.4502 - val_loss: 271.2452
Epoch 2/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 267.3697 - val_loss: 257.6103
Epoch 3/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 255.9977 - val_loss: 249.3648
Epoch 4/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 250.1813 - val_loss: 245.1616
Epoch 5/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 246.1818 - val_loss: 241.7860
Epoch 6/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 243.0878 - val_loss: 237.8544
Epoch 7/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 240.5783 - val_loss: 236.1853
Epoch 8/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 238.3820 - val_loss: 235.7965
Epoch 9/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 236.4451 - val_loss: 233.0186
Epoch 10/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 234.1680 - val_loss: 231.6514
Epoch 11/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 231.3232 - val_loss: 226.9324
Epoch 12/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 228.1380 - val_loss: 225.5942
Epoch 13/40
9445953/9445953 [==============================] - 43s 4us/step - loss: 225.6033 - val_loss: 221.5924
Epoch 14/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 223.8271 - val_loss: 220.5642
Epoch 15/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 222.1886 - val_loss: 223.2543
Epoch 16/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 221.0515 - val_loss: 224.2672
Epoch 17/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 220.0152 - val_loss: 215.4356
Epoch 18/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 218.7163 - val_loss: 214.1768
Epoch 19/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 217.8667 - val_loss: 216.6061
Epoch 20/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 216.8290 - val_loss: 212.9428
Epoch 21/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 216.2206 - val_loss: 214.2454
Epoch 22/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 215.3240 - val_loss: 216.2770
Epoch 23/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 214.5917 - val_loss: 211.4917
Epoch 24/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 213.9100 - val_loss: 207.8294
Epoch 25/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 213.6173 - val_loss: 208.8671
Epoch 26/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 212.7487 - val_loss: 206.1950
Epoch 27/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 211.9973 - val_loss: 208.7335
Epoch 28/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 211.6770 - val_loss: 214.0650
Epoch 29/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 211.2700 - val_loss: 206.0872
Epoch 30/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 210.7558 - val_loss: 205.0208
Epoch 31/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 210.4236 - val_loss: 208.1851
Epoch 32/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 209.8564 - val_loss: 203.5126
Epoch 33/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 209.4299 - val_loss: 216.5801
Epoch 34/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 208.6825 - val_loss: 209.0478
Epoch 35/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 208.1097 - val_loss: 211.0309
Epoch 36/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 207.7438 - val_loss: 201.4710
Epoch 37/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 207.5670 - val_loss: 204.3735
Epoch 38/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 206.9829 - val_loss: 208.6148
Epoch 39/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 206.6297 - val_loss: 205.3058
Epoch 40/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 206.0997 - val_loss: 203.4504

         CHILD ACCURACY = 204.05242053916592


         PARENT ACCURACY = 201.51506594389141



 QUEUE SIZE BEFORE GET = 7


 NODE SELECTED <<<------ Epochs = 45 -------- BatchSize = 3000 --------- Accuracy = 203.17708960797904 -------->>>


 CHILD 1 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 4000

         EPOCHS = 40
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/40
2018-11-11 11:44:57.989218: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 11:44:57.994934: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 29s 3us/step - loss: 292.0204 - val_loss: 274.2736
Epoch 2/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 274.4287 - val_loss: 270.8325
Epoch 3/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 272.0657 - val_loss: 269.3306
Epoch 4/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 270.0009 - val_loss: 268.9917
Epoch 5/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 260.1647 - val_loss: 253.7718
Epoch 6/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 250.6128 - val_loss: 244.2495
Epoch 7/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 245.1745 - val_loss: 238.2366
Epoch 8/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 240.9145 - val_loss: 235.9059
Epoch 9/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 237.1261 - val_loss: 231.1676
Epoch 10/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 233.6867 - val_loss: 230.4989
Epoch 11/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 230.8855 - val_loss: 228.9667
Epoch 12/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 228.5311 - val_loss: 225.0874
Epoch 13/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 226.2609 - val_loss: 230.3060
Epoch 14/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 224.7264 - val_loss: 223.5471
Epoch 15/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 223.1353 - val_loss: 226.8094
Epoch 16/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 222.0553 - val_loss: 219.1068
Epoch 17/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 220.7172 - val_loss: 228.8673
Epoch 18/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 219.5106 - val_loss: 213.4366
Epoch 19/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 218.5685 - val_loss: 213.1737
Epoch 20/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 217.6397 - val_loss: 216.8079
Epoch 21/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 216.9595 - val_loss: 222.7183
Epoch 22/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 216.0759 - val_loss: 214.2054
Epoch 23/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 215.2882 - val_loss: 212.8323
Epoch 24/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 214.5911 - val_loss: 222.5776
Epoch 25/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 213.9124 - val_loss: 219.7027
Epoch 26/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 213.2617 - val_loss: 211.7508
Epoch 27/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 212.5607 - val_loss: 212.4225
Epoch 28/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 211.9915 - val_loss: 210.5330
Epoch 29/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 211.3375 - val_loss: 212.1092
Epoch 30/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 210.8985 - val_loss: 214.1118
Epoch 31/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 210.3104 - val_loss: 207.8585
Epoch 32/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 209.9106 - val_loss: 207.9876
Epoch 33/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 209.4074 - val_loss: 206.7207
Epoch 34/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 209.0032 - val_loss: 214.0316
Epoch 35/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 208.4332 - val_loss: 207.5885
Epoch 36/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 207.9203 - val_loss: 209.3177
Epoch 37/40
9445953/9445953 [==============================] - 29s 3us/step - loss: 207.4298 - val_loss: 206.6305
Epoch 38/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 207.2006 - val_loss: 206.4139
Epoch 39/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 206.6574 - val_loss: 208.6185
Epoch 40/40
9445953/9445953 [==============================] - 28s 3us/step - loss: 206.3918 - val_loss: 210.3549

         CHILD ACCURACY = 209.0890366005683


         PARENT ACCURACY = 203.17708960797904


 CHILD 2 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 3000

         EPOCHS = 40
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/40
2018-11-11 12:03:56.347704: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 12:03:56.353178: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 288.5859 - val_loss: 269.7624
Epoch 2/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 266.7802 - val_loss: 256.8702
Epoch 3/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 257.0675 - val_loss: 254.6406
Epoch 4/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 251.0108 - val_loss: 246.8169
Epoch 5/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 247.0919 - val_loss: 244.5727
Epoch 6/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 243.8558 - val_loss: 243.8852
Epoch 7/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 241.1864 - val_loss: 237.9655
Epoch 8/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 238.6402 - val_loss: 242.8176
Epoch 9/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 236.1830 - val_loss: 230.8142
Epoch 10/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 233.0921 - val_loss: 229.8961
Epoch 11/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 230.1890 - val_loss: 228.8388
Epoch 12/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 227.9316 - val_loss: 226.4791
Epoch 13/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 225.9251 - val_loss: 224.3775
Epoch 14/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 224.4967 - val_loss: 222.8965
Epoch 15/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 223.0163 - val_loss: 217.1659
Epoch 16/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 221.8515 - val_loss: 218.6071
Epoch 17/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 220.6303 - val_loss: 217.6824
Epoch 18/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 219.8342 - val_loss: 219.1346
Epoch 19/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 218.8048 - val_loss: 218.0567
Epoch 20/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 217.6789 - val_loss: 217.8793
Epoch 21/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 216.9618 - val_loss: 215.8556
Epoch 22/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 215.9494 - val_loss: 216.5379
Epoch 23/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 215.2337 - val_loss: 215.8491
Epoch 24/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 214.5772 - val_loss: 209.9895
Epoch 25/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 213.7248 - val_loss: 228.9484
Epoch 26/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 213.1547 - val_loss: 212.7706
Epoch 27/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 212.4660 - val_loss: 215.1272
Epoch 28/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 211.9992 - val_loss: 208.6467
Epoch 29/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 211.3252 - val_loss: 204.9997
Epoch 30/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 210.7714 - val_loss: 220.9533
Epoch 31/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 210.2809 - val_loss: 214.8810
Epoch 32/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 209.6015 - val_loss: 224.3139
Epoch 33/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 209.3297 - val_loss: 208.9393
Epoch 34/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 208.4230 - val_loss: 204.6406
Epoch 35/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 208.0378 - val_loss: 208.9436
Epoch 36/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 207.8349 - val_loss: 207.3569
Epoch 37/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 207.2874 - val_loss: 211.0233
Epoch 38/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 206.9747 - val_loss: 202.6163
Epoch 39/40
9445953/9445953 [==============================] - 33s 3us/step - loss: 206.5327 - val_loss: 206.6879
Epoch 40/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 206.2943 - val_loss: 208.3273

         CHILD ACCURACY = 207.55513543659583


         PARENT ACCURACY = 203.17708960797904


 CHILD 3 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 2000

         EPOCHS = 40
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/40
2018-11-11 12:26:00.125957: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-11-11 12:26:00.132591: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 42s 4us/step - loss: 341.7418 - val_loss: 318.3579
Epoch 2/40
3340000/9445953 [=========>....................] - ETA: 27s - loss: 323.4755
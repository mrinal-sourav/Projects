
C:\Users\mrinal\Documents\code_stuff\Carom Billiards Source>python nn_a_star_train.py
C:\Users\mrinal\AppData\Local\Programs\Python\Python36\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/55
2018-07-19 15:53:01.000887: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2018-07-19 15:53:02.100524: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1212] Found device 0 with properties:
name: GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:01:00.0
totalMemory: 4.00GiB freeMemory: 3.30GiB
2018-07-19 15:53:02.108391: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 15:53:03.698951: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3032 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 16s 2us/step - loss: 320.4981 - val_loss: 312.8911
Epoch 2/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 311.1427 - val_loss: 297.9083
Epoch 3/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 297.6562 - val_loss: 286.6113
Epoch 4/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 288.3471 - val_loss: 284.7070
Epoch 5/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 284.0152 - val_loss: 277.1051
Epoch 6/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 280.9938 - val_loss: 279.7887
Epoch 7/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 279.2067 - val_loss: 275.8227
Epoch 8/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 277.7761 - val_loss: 275.0943
Epoch 9/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 276.7578 - val_loss: 272.8328
Epoch 10/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 275.8951 - val_loss: 272.7101
Epoch 11/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 275.2446 - val_loss: 272.6621
Epoch 12/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 274.6057 - val_loss: 275.1137
Epoch 13/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 274.1793 - val_loss: 271.5142
Epoch 14/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 273.6196 - val_loss: 270.8879
Epoch 15/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 273.1094 - val_loss: 269.7816
Epoch 16/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 272.9947 - val_loss: 269.6686
Epoch 17/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 272.4752 - val_loss: 269.7777
Epoch 18/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 272.1239 - val_loss: 269.1143
Epoch 19/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 271.9713 - val_loss: 270.3120
Epoch 20/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 271.4858 - val_loss: 268.9094
Epoch 21/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 271.2971 - val_loss: 268.4627
Epoch 22/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 271.0364 - val_loss: 270.0078
Epoch 23/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 270.7653 - val_loss: 268.5516
Epoch 24/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 270.5640 - val_loss: 269.1117
Epoch 25/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 270.3085 - val_loss: 269.6689
Epoch 26/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 270.1252 - val_loss: 267.0100
Epoch 27/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 269.7435 - val_loss: 267.3614
Epoch 28/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 269.5729 - val_loss: 266.5395
Epoch 29/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 269.2058 - val_loss: 266.4194
Epoch 30/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 268.8711 - val_loss: 268.2058
Epoch 31/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 268.4899 - val_loss: 266.6148
Epoch 32/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 267.6270 - val_loss: 262.6949
Epoch 33/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 265.1345 - val_loss: 260.9509
Epoch 34/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 262.6700 - val_loss: 257.6942
Epoch 35/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 260.6437 - val_loss: 256.8393
Epoch 36/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 259.1210 - val_loss: 252.6747
Epoch 37/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 257.6113 - val_loss: 253.4753
Epoch 38/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 256.4970 - val_loss: 249.9934
Epoch 39/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 255.3397 - val_loss: 250.7289
Epoch 40/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 254.2794 - val_loss: 249.3699
Epoch 41/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 253.2357 - val_loss: 254.5349
Epoch 42/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 252.5465 - val_loss: 246.4561
Epoch 43/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 251.7736 - val_loss: 246.4361
Epoch 44/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 251.0546 - val_loss: 248.5053
Epoch 45/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 250.3254 - val_loss: 243.8523
Epoch 46/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 249.5476 - val_loss: 248.0063
Epoch 47/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 249.0111 - val_loss: 242.6254
Epoch 48/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 248.3471 - val_loss: 246.1166
Epoch 49/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 247.9332 - val_loss: 241.9399
Epoch 50/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 247.5573 - val_loss: 242.4591
Epoch 51/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 246.7852 - val_loss: 239.8664
Epoch 52/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 246.2896 - val_loss: 240.7720
Epoch 53/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 245.9429 - val_loss: 238.9550
Epoch 54/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 245.5730 - val_loss: 239.3678
Epoch 55/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 245.1897 - val_loss: 237.6272

 ###### inititial_accuracy = 232.61220405002524



 QUEUE SIZE BEFORE GET = 1


 NODE SELECTED <<<------ Epochs = 55 -------- BatchSize = 24000 --------- Accuracy = 232.61220405002524 -------->>>


 CHILD 1 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 24000

         EPOCHS = 50
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/50
2018-07-19 16:04:26.557461: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 16:04:26.563891: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 13s 1us/step - loss: 320.7756 - val_loss: 312.6597
Epoch 2/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 314.7861 - val_loss: 303.6578
Epoch 3/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 303.1268 - val_loss: 282.9614
Epoch 4/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 285.1891 - val_loss: 279.5697
Epoch 5/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 281.1087 - val_loss: 276.7153
Epoch 6/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 279.2161 - val_loss: 275.2122
Epoch 7/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 277.9648 - val_loss: 273.3762
Epoch 8/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 277.2060 - val_loss: 273.9591
Epoch 9/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 276.4466 - val_loss: 273.0588
Epoch 10/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 275.9326 - val_loss: 271.9511
Epoch 11/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 275.3466 - val_loss: 271.5172
Epoch 12/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 274.9844 - val_loss: 271.1475
Epoch 13/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 274.4663 - val_loss: 272.2891
Epoch 14/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 274.0932 - val_loss: 272.9778
Epoch 15/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 273.7187 - val_loss: 274.3791
Epoch 16/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 273.3792 - val_loss: 270.0772
Epoch 17/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 272.9329 - val_loss: 270.2217
Epoch 18/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 272.6282 - val_loss: 269.0184
Epoch 19/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 272.3529 - val_loss: 269.0245
Epoch 20/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 272.1266 - val_loss: 269.6181
Epoch 21/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 271.8193 - val_loss: 269.0142
Epoch 22/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 271.4998 - val_loss: 268.4334
Epoch 23/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 271.3114 - val_loss: 268.2462
Epoch 24/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 271.0527 - val_loss: 268.1750
Epoch 25/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 270.8401 - val_loss: 268.3398
Epoch 26/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 270.4890 - val_loss: 269.0527
Epoch 27/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 270.3164 - val_loss: 268.1385
Epoch 28/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 270.0791 - val_loss: 266.7346
Epoch 29/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 269.7693 - val_loss: 267.0768
Epoch 30/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 269.4692 - val_loss: 267.4298
Epoch 31/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 269.2189 - val_loss: 266.1737
Epoch 32/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 268.9225 - val_loss: 266.1930
Epoch 33/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 268.5313 - val_loss: 267.1285
Epoch 34/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 268.1265 - val_loss: 265.1406
Epoch 35/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 266.9765 - val_loss: 261.8611
Epoch 36/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 264.9631 - val_loss: 260.3221
Epoch 37/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 262.6331 - val_loss: 260.8559
Epoch 38/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 260.9793 - val_loss: 258.2137
Epoch 39/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 259.2361 - val_loss: 254.5358
Epoch 40/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 258.1720 - val_loss: 256.8027
Epoch 41/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 256.7037 - val_loss: 251.2405
Epoch 42/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 255.6840 - val_loss: 253.8943
Epoch 43/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 254.8704 - val_loss: 252.4506
Epoch 44/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 253.8649 - val_loss: 249.9569
Epoch 45/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 253.2486 - val_loss: 249.8514
Epoch 46/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 252.5296 - val_loss: 245.7690
Epoch 47/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 251.9233 - val_loss: 248.3516
Epoch 48/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 251.3225 - val_loss: 243.8699
Epoch 49/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 251.0207 - val_loss: 244.6056
Epoch 50/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 250.3873 - val_loss: 245.7329

         CHILD ACCURACY = 240.11651878625293


         PARENT ACCURACY = 232.61220405002524


 CHILD 2 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 30000

         EPOCHS = 55
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/55
2018-07-19 16:14:44.567307: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 16:14:44.574013: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 12s 1us/step - loss: 317.6305 - val_loss: 311.9766
Epoch 2/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 307.2347 - val_loss: 321.7379
Epoch 3/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 294.2188 - val_loss: 294.1764
Epoch 4/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 288.2745 - val_loss: 282.0452
Epoch 5/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 285.1288 - val_loss: 284.1292
Epoch 6/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 282.6905 - val_loss: 283.2450
Epoch 7/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 280.7800 - val_loss: 281.4791
Epoch 8/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 279.4408 - val_loss: 275.0002
Epoch 9/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 278.2634 - val_loss: 274.7919
Epoch 10/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 277.4871 - val_loss: 273.9260
Epoch 11/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 276.7978 - val_loss: 273.5465
Epoch 12/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 276.0644 - val_loss: 273.1929
Epoch 13/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 275.6228 - val_loss: 272.6796
Epoch 14/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 275.1801 - val_loss: 273.1075
Epoch 15/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 274.6672 - val_loss: 273.5442
Epoch 16/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 274.3231 - val_loss: 272.8500
Epoch 17/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 273.8405 - val_loss: 270.7827
Epoch 18/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 273.5802 - val_loss: 270.5386
Epoch 19/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 273.3682 - val_loss: 270.4740
Epoch 20/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 272.9269 - val_loss: 271.3393
Epoch 21/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 272.7057 - val_loss: 271.9183
Epoch 22/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 272.3529 - val_loss: 269.3362
Epoch 23/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 271.8970 - val_loss: 270.2854
Epoch 24/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 271.5061 - val_loss: 268.5480
Epoch 25/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 270.8585 - val_loss: 267.8631
Epoch 26/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 269.9840 - val_loss: 270.6338
Epoch 27/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 269.0265 - val_loss: 268.8534
Epoch 28/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 267.6862 - val_loss: 263.0994
Epoch 29/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 266.3666 - val_loss: 269.2730
Epoch 30/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 264.9759 - val_loss: 267.8531
Epoch 31/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 263.7039 - val_loss: 259.4131
Epoch 32/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 262.5997 - val_loss: 259.1441
Epoch 33/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 261.5141 - val_loss: 260.4760
Epoch 34/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 260.6002 - val_loss: 258.4921
Epoch 35/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 259.6249 - val_loss: 254.3030
Epoch 36/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 258.7737 - val_loss: 257.4621
Epoch 37/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 257.9699 - val_loss: 252.2292
Epoch 38/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 257.2732 - val_loss: 251.7313
Epoch 39/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 256.4102 - val_loss: 251.5689
Epoch 40/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 255.9867 - val_loss: 251.1984
Epoch 41/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 255.5189 - val_loss: 252.4443
Epoch 42/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 254.7589 - val_loss: 251.3567
Epoch 43/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 254.3629 - val_loss: 248.4703
Epoch 44/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 253.7739 - val_loss: 249.7045
Epoch 45/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 253.3164 - val_loss: 250.8324
Epoch 46/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 252.8951 - val_loss: 249.8665
Epoch 47/55
9445953/9445953 [==============================] - 11s 1us/step - loss: 252.4728 - val_loss: 246.7056
Epoch 48/55
9445953/9445953 [==============================] - 11s 1us/step - loss: 252.0791 - val_loss: 246.8843
Epoch 49/55
9445953/9445953 [==============================] - 11s 1us/step - loss: 251.7516 - val_loss: 246.8051
Epoch 50/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 251.3749 - val_loss: 246.5845
Epoch 51/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 250.8781 - val_loss: 247.1578
Epoch 52/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 250.5182 - val_loss: 249.4513
Epoch 53/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 250.1233 - val_loss: 249.1063
Epoch 54/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 249.8960 - val_loss: 244.0813
Epoch 55/55
9445953/9445953 [==============================] - 12s 1us/step - loss: 249.3423 - val_loss: 243.4151

         CHILD ACCURACY = 243.05713177502216


         PARENT ACCURACY = 232.61220405002524


 CHILD 3 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 18000

         EPOCHS = 55
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/55
2018-07-19 16:25:31.076063: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 16:25:31.081090: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 14s 1us/step - loss: 326.1019 - val_loss: 314.6308
Epoch 2/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 320.0019 - val_loss: 314.4410
Epoch 3/55
9445953/9445953 [==============================] - 14s 1us/step - loss: 311.7335 - val_loss: 290.4615
Epoch 4/55
9445953/9445953 [==============================] - 14s 1us/step - loss: 287.1619 - val_loss: 281.3095
Epoch 5/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 283.6973 - val_loss: 279.8970
Epoch 6/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 281.3562 - val_loss: 278.1497
Epoch 7/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 279.3854 - val_loss: 275.6519
Epoch 8/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 278.0457 - val_loss: 274.9691
Epoch 9/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 277.3002 - val_loss: 276.9789
Epoch 10/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 276.5902 - val_loss: 273.8317
Epoch 11/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 275.9436 - val_loss: 272.9587
Epoch 12/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 275.3302 - val_loss: 272.4504
Epoch 13/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 274.8864 - val_loss: 275.9489
Epoch 14/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 274.4493 - val_loss: 271.6529
Epoch 15/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 274.0779 - val_loss: 271.7117
Epoch 16/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 273.7866 - val_loss: 271.3014
Epoch 17/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 273.4715 - val_loss: 272.8061
Epoch 18/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 273.3034 - val_loss: 270.9253
Epoch 19/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 273.0299 - val_loss: 270.8357
Epoch 20/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 272.8519 - val_loss: 270.4215
Epoch 21/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 272.7325 - val_loss: 270.2939
Epoch 22/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 272.5115 - val_loss: 271.1411
Epoch 23/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 272.3425 - val_loss: 270.8352
Epoch 24/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 272.1731 - val_loss: 270.8327
Epoch 25/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 272.0387 - val_loss: 269.4012
Epoch 26/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 271.8070 - val_loss: 269.0650
Epoch 27/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 271.6704 - val_loss: 269.8003
Epoch 28/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 271.5710 - val_loss: 269.7976
Epoch 29/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 271.3247 - val_loss: 268.9673
Epoch 30/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 271.2038 - val_loss: 270.5332
Epoch 31/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 271.0969 - val_loss: 270.3398
Epoch 32/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 270.9614 - val_loss: 269.1965
Epoch 33/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 270.7567 - val_loss: 268.6594
Epoch 34/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 270.6793 - val_loss: 271.3215
Epoch 35/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 270.5758 - val_loss: 270.4399
Epoch 36/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 270.4699 - val_loss: 269.2703
Epoch 37/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 270.3782 - val_loss: 267.7236
Epoch 38/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 270.2914 - val_loss: 268.9199
Epoch 39/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 270.1880 - val_loss: 269.6131
Epoch 40/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 270.0586 - val_loss: 268.2561
Epoch 41/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 269.9607 - val_loss: 268.9549
Epoch 42/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 269.8026 - val_loss: 269.0581
Epoch 43/55
9445953/9445953 [==============================] - 14s 1us/step - loss: 269.7167 - val_loss: 268.3493
Epoch 44/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 269.6071 - val_loss: 268.5119
Epoch 45/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 269.4715 - val_loss: 268.0853
Epoch 46/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 269.2635 - val_loss: 268.3381
Epoch 47/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 269.1082 - val_loss: 268.7922
Epoch 48/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 268.9230 - val_loss: 267.8034
Epoch 49/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 268.5778 - val_loss: 266.6048
Epoch 50/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 267.8016 - val_loss: 263.5804
Epoch 51/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 265.5345 - val_loss: 261.2566
Epoch 52/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 262.9640 - val_loss: 257.7972
Epoch 53/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 260.9695 - val_loss: 256.9131
Epoch 54/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 259.4143 - val_loss: 257.1113
Epoch 55/55
9445953/9445953 [==============================] - 13s 1us/step - loss: 258.1200 - val_loss: 256.4387

         CHILD ACCURACY = 253.76318725439899


         PARENT ACCURACY = 232.61220405002524


 CHILD 4 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 18000

         EPOCHS = 60
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/60
2018-07-19 16:37:34.442069: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 16:37:34.448150: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 14s 1us/step - loss: 322.0109 - val_loss: 315.8664
Epoch 2/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 312.3241 - val_loss: 336.0979
Epoch 3/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 291.6800 - val_loss: 284.9711
Epoch 4/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 287.5996 - val_loss: 284.9529
Epoch 5/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 286.2643 - val_loss: 284.9588
Epoch 6/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 285.4709 - val_loss: 282.4743
Epoch 7/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 284.8833 - val_loss: 282.2084
Epoch 8/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 284.3816 - val_loss: 285.2338
Epoch 9/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 283.9854 - val_loss: 282.5585
Epoch 10/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 283.7688 - val_loss: 281.7860
Epoch 11/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 283.2895 - val_loss: 286.9470
Epoch 12/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 282.6985 - val_loss: 284.6689
Epoch 13/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 282.2826 - val_loss: 282.4334
Epoch 14/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 282.1862 - val_loss: 283.5674
Epoch 15/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 281.8147 - val_loss: 287.1672
Epoch 16/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 281.5954 - val_loss: 281.1229
Epoch 17/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 281.4170 - val_loss: 280.9818
Epoch 18/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 281.2152 - val_loss: 282.9266
Epoch 19/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 281.1038 - val_loss: 279.8777
Epoch 20/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 280.9273 - val_loss: 279.9399
Epoch 21/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 280.8357 - val_loss: 280.8800
Epoch 22/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 280.6763 - val_loss: 279.3592
Epoch 23/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 280.4139 - val_loss: 280.2900
Epoch 24/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 280.0540 - val_loss: 278.5997
Epoch 25/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 279.6815 - val_loss: 282.3990
Epoch 26/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 279.2899 - val_loss: 277.7859
Epoch 27/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 278.8633 - val_loss: 278.1221
Epoch 28/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 278.3898 - val_loss: 277.8968
Epoch 29/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 277.8339 - val_loss: 276.3749
Epoch 30/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 277.1795 - val_loss: 275.9926
Epoch 31/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 275.3544 - val_loss: 272.0316
Epoch 32/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 272.2126 - val_loss: 270.8322
Epoch 33/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 270.6080 - val_loss: 269.8391
Epoch 34/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 269.6358 - val_loss: 266.2478
Epoch 35/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 268.7062 - val_loss: 266.5683
Epoch 36/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 267.8479 - val_loss: 267.1318
Epoch 37/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 267.1493 - val_loss: 266.4059
Epoch 38/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 266.4984 - val_loss: 264.9493
Epoch 39/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 266.0753 - val_loss: 266.0116
Epoch 40/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 265.5576 - val_loss: 263.2888
Epoch 41/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 265.1822 - val_loss: 264.5230
Epoch 42/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 264.8116 - val_loss: 262.4317
Epoch 43/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 264.4409 - val_loss: 262.5981
Epoch 44/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 264.0341 - val_loss: 263.2343
Epoch 45/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 263.7564 - val_loss: 262.0820
Epoch 46/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 263.4283 - val_loss: 260.3855
Epoch 47/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 263.1500 - val_loss: 261.3594
Epoch 48/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 262.8393 - val_loss: 262.9883
Epoch 49/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 262.5319 - val_loss: 262.0530
Epoch 50/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 262.3344 - val_loss: 260.6585
Epoch 51/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 262.1881 - val_loss: 259.8505
Epoch 52/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 261.8680 - val_loss: 258.9018
Epoch 53/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 261.6909 - val_loss: 259.1389
Epoch 54/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 261.4327 - val_loss: 258.7033
Epoch 55/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 261.1722 - val_loss: 259.2452
Epoch 56/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 261.0018 - val_loss: 265.1190
Epoch 57/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 260.9194 - val_loss: 257.2441
Epoch 58/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 260.7306 - val_loss: 261.9476
Epoch 59/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 260.5368 - val_loss: 261.9252
Epoch 60/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 260.4295 - val_loss: 259.7487

         CHILD ACCURACY = 259.77869134967307


         PARENT ACCURACY = 232.61220405002524


 CHILD 5 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 30000

         EPOCHS = 60
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/60
2018-07-19 16:50:47.737326: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 16:50:47.742971: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 12s 1us/step - loss: 324.0995 - val_loss: 315.8852
Epoch 2/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 315.2201 - val_loss: 310.7614
Epoch 3/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 311.1355 - val_loss: 306.9818
Epoch 4/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 307.6465 - val_loss: 298.7745
Epoch 5/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 299.6355 - val_loss: 292.9317
Epoch 6/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 294.1506 - val_loss: 290.9748
Epoch 7/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 291.6208 - val_loss: 289.8743
Epoch 8/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 290.2506 - val_loss: 286.7286
Epoch 9/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 289.1694 - val_loss: 295.2667
Epoch 10/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 288.3660 - val_loss: 285.2338
Epoch 11/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 287.5708 - val_loss: 284.8604
Epoch 12/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 286.9388 - val_loss: 287.9088
Epoch 13/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 286.2206 - val_loss: 284.1526
Epoch 14/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 285.6571 - val_loss: 285.7632
Epoch 15/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 284.9120 - val_loss: 282.3612
Epoch 16/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 284.3188 - val_loss: 281.7262
Epoch 17/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 283.6189 - val_loss: 280.9293
Epoch 18/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 282.9360 - val_loss: 282.9026
Epoch 19/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 282.6968 - val_loss: 281.8653
Epoch 20/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 282.3053 - val_loss: 280.9334
Epoch 21/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 282.2112 - val_loss: 281.3048
Epoch 22/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 281.9433 - val_loss: 284.9351
Epoch 23/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 281.8765 - val_loss: 283.4329
Epoch 24/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 281.7060 - val_loss: 281.4122
Epoch 25/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 281.5686 - val_loss: 281.1609
Epoch 26/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 281.5219 - val_loss: 280.1773
Epoch 27/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 281.4527 - val_loss: 283.7923
Epoch 28/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 281.3054 - val_loss: 282.1858
Epoch 29/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 280.8727 - val_loss: 280.3294
Epoch 30/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 280.4090 - val_loss: 278.3817
Epoch 31/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 279.8433 - val_loss: 279.3331
Epoch 32/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 279.2620 - val_loss: 277.8174
Epoch 33/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 278.7795 - val_loss: 278.3555
Epoch 34/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 278.2315 - val_loss: 279.4471
Epoch 35/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 277.6081 - val_loss: 275.2932
Epoch 36/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 277.0452 - val_loss: 275.3131
Epoch 37/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 276.5892 - val_loss: 274.3129
Epoch 38/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 275.9846 - val_loss: 274.5523
Epoch 39/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 275.5512 - val_loss: 273.4720
Epoch 40/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 275.0782 - val_loss: 273.8640
Epoch 41/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 274.6606 - val_loss: 274.2452
Epoch 42/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 274.3609 - val_loss: 273.1576
Epoch 43/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 274.0459 - val_loss: 272.5548
Epoch 44/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 273.6637 - val_loss: 272.0932
Epoch 45/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 273.3168 - val_loss: 272.3491
Epoch 46/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 273.0638 - val_loss: 274.1555
Epoch 47/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 272.8089 - val_loss: 273.9120
Epoch 48/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 272.4547 - val_loss: 270.2677
Epoch 49/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 272.1075 - val_loss: 270.7962
Epoch 50/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 271.9179 - val_loss: 270.6859
Epoch 51/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 271.7083 - val_loss: 270.2558
Epoch 52/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 271.3555 - val_loss: 270.4743
Epoch 53/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 271.1507 - val_loss: 270.1734
Epoch 54/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 270.8891 - val_loss: 270.3859
Epoch 55/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 270.7721 - val_loss: 270.7718
Epoch 56/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 270.6645 - val_loss: 271.7964
Epoch 57/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 270.4406 - val_loss: 269.4087
Epoch 58/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 270.1656 - val_loss: 270.3693
Epoch 59/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 270.2013 - val_loss: 269.5621
Epoch 60/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 269.9551 - val_loss: 272.4215

         CHILD ACCURACY = 270.6901282288216


         PARENT ACCURACY = 232.61220405002524


 CHILD 6 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 18000

         EPOCHS = 50
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/50
2018-07-19 17:02:37.149189: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 17:02:37.157481: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 14s 1us/step - loss: 320.7329 - val_loss: 303.0692
Epoch 2/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 296.0459 - val_loss: 286.2460
Epoch 3/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 288.0301 - val_loss: 285.6195
Epoch 4/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 285.1441 - val_loss: 281.1583
Epoch 5/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 283.3346 - val_loss: 279.5021
Epoch 6/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 281.5690 - val_loss: 280.5336
Epoch 7/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 279.9517 - val_loss: 276.2604
Epoch 8/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 278.6678 - val_loss: 274.6889
Epoch 9/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 277.3470 - val_loss: 275.0460
Epoch 10/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 276.1729 - val_loss: 274.5975
Epoch 11/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 274.6490 - val_loss: 270.5458
Epoch 12/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 273.1990 - val_loss: 271.3408
Epoch 13/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 271.6363 - val_loss: 268.0731
Epoch 14/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 270.1999 - val_loss: 267.0535
Epoch 15/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 268.4869 - val_loss: 271.4873
Epoch 16/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 267.0316 - val_loss: 266.4800
Epoch 17/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 265.5001 - val_loss: 260.5819
Epoch 18/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 264.2844 - val_loss: 260.0366
Epoch 19/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 262.9756 - val_loss: 257.7308
Epoch 20/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 261.9617 - val_loss: 257.1288
Epoch 21/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 260.9498 - val_loss: 257.3189
Epoch 22/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 259.9604 - val_loss: 256.2157
Epoch 23/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 259.2774 - val_loss: 254.1277
Epoch 24/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 258.3846 - val_loss: 252.5315
Epoch 25/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 257.5238 - val_loss: 254.5878
Epoch 26/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 256.9201 - val_loss: 251.0390
Epoch 27/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 256.2418 - val_loss: 251.2252
Epoch 28/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 255.7847 - val_loss: 250.2900
Epoch 29/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 255.1772 - val_loss: 249.7150
Epoch 30/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 254.4996 - val_loss: 248.5975
Epoch 31/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 254.1295 - val_loss: 249.2226
Epoch 32/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 253.7191 - val_loss: 250.7043
Epoch 33/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 253.0988 - val_loss: 251.0723
Epoch 34/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 252.5903 - val_loss: 250.4980
Epoch 35/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 252.2604 - val_loss: 246.4806
Epoch 36/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 251.6893 - val_loss: 246.4287
Epoch 37/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 251.3096 - val_loss: 245.6691
Epoch 38/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 250.7879 - val_loss: 249.0441
Epoch 39/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 250.6007 - val_loss: 243.7270
Epoch 40/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 250.1204 - val_loss: 243.1640
Epoch 41/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 249.6128 - val_loss: 244.1561
Epoch 42/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 249.3277 - val_loss: 247.7299
Epoch 43/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 248.9592 - val_loss: 243.9744
Epoch 44/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 248.6417 - val_loss: 243.0841
Epoch 45/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 248.2795 - val_loss: 244.7673
Epoch 46/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 248.1177 - val_loss: 241.7145
Epoch 47/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 247.7115 - val_loss: 243.4255
Epoch 48/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 247.4764 - val_loss: 244.6399
Epoch 49/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 247.1381 - val_loss: 241.1782
Epoch 50/50
9445953/9445953 [==============================] - 13s 1us/step - loss: 246.9241 - val_loss: 242.4223

         CHILD ACCURACY = 238.52038166863824


         PARENT ACCURACY = 232.61220405002524


 CHILD 7 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 30000

         EPOCHS = 50
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/50
2018-07-19 17:13:31.821325: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 17:13:31.826778: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 12s 1us/step - loss: 319.8203 - val_loss: 312.5986
Epoch 2/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 309.0556 - val_loss: 298.1737
Epoch 3/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 296.2828 - val_loss: 293.7535
Epoch 4/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 288.0969 - val_loss: 281.2124
Epoch 5/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 284.3173 - val_loss: 279.7115
Epoch 6/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 282.4624 - val_loss: 286.3985
Epoch 7/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 280.9906 - val_loss: 279.2338
Epoch 8/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 280.0679 - val_loss: 281.8062
Epoch 9/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 278.8504 - val_loss: 275.9450
Epoch 10/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 277.7866 - val_loss: 273.6876
Epoch 11/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 276.7320 - val_loss: 272.4989
Epoch 12/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 275.7311 - val_loss: 271.1434
Epoch 13/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 274.9561 - val_loss: 271.1060
Epoch 14/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 273.9929 - val_loss: 271.8051
Epoch 15/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 273.2404 - val_loss: 269.1990
Epoch 16/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 272.5850 - val_loss: 268.2745
Epoch 17/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 271.5814 - val_loss: 269.6144
Epoch 18/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 271.0696 - val_loss: 269.4685
Epoch 19/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 270.4748 - val_loss: 268.4467
Epoch 20/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 269.8783 - val_loss: 269.1055
Epoch 21/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 269.4230 - val_loss: 267.8765
Epoch 22/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 268.6668 - val_loss: 266.8953
Epoch 23/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 268.3676 - val_loss: 268.9545
Epoch 24/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 267.7055 - val_loss: 263.5391
Epoch 25/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 267.3570 - val_loss: 264.1563
Epoch 26/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 266.7931 - val_loss: 264.0918
Epoch 27/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 266.3931 - val_loss: 262.5294
Epoch 28/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 265.9967 - val_loss: 263.6953
Epoch 29/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 265.5456 - val_loss: 262.1007
Epoch 30/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 265.2360 - val_loss: 262.2989
Epoch 31/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 265.0408 - val_loss: 262.5336
Epoch 32/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 264.5060 - val_loss: 263.5644
Epoch 33/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 264.1941 - val_loss: 261.9192
Epoch 34/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 263.9602 - val_loss: 263.5408
Epoch 35/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 263.7630 - val_loss: 260.3791
Epoch 36/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 263.3284 - val_loss: 260.7466
Epoch 37/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 263.1316 - val_loss: 261.2084
Epoch 38/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 262.7524 - val_loss: 260.5618
Epoch 39/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 262.5810 - val_loss: 260.6866
Epoch 40/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 262.3793 - val_loss: 260.7535
Epoch 41/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 261.9883 - val_loss: 262.2993
Epoch 42/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 261.8289 - val_loss: 265.2244
Epoch 43/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 261.5879 - val_loss: 258.2213
Epoch 44/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 261.3589 - val_loss: 261.0964
Epoch 45/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 261.2727 - val_loss: 257.6625
Epoch 46/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 261.0031 - val_loss: 258.1907
Epoch 47/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 260.8838 - val_loss: 260.8385
Epoch 48/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 260.5506 - val_loss: 257.1236
Epoch 49/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 260.4513 - val_loss: 257.9957
Epoch 50/50
9445953/9445953 [==============================] - 12s 1us/step - loss: 260.2135 - val_loss: 257.3622

         CHILD ACCURACY = 256.1351945021423


         PARENT ACCURACY = 232.61220405002524


 CHILD 8 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 24000

         EPOCHS = 60
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/60
2018-07-19 17:23:21.534842: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 17:23:21.539875: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 13s 1us/step - loss: 317.8629 - val_loss: 319.8200
Epoch 2/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 309.0426 - val_loss: 300.2050
Epoch 3/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 292.5297 - val_loss: 286.4938
Epoch 4/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 283.5774 - val_loss: 277.8725
Epoch 5/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 280.7677 - val_loss: 275.7781
Epoch 6/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 279.3735 - val_loss: 282.4777
Epoch 7/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 278.2288 - val_loss: 277.4839
Epoch 8/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 277.5004 - val_loss: 276.0789
Epoch 9/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 276.7821 - val_loss: 273.3002
Epoch 10/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 276.0912 - val_loss: 276.6292
Epoch 11/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 275.4750 - val_loss: 274.0029
Epoch 12/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 275.0861 - val_loss: 273.1978
Epoch 13/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 274.5943 - val_loss: 273.2874
Epoch 14/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 274.1730 - val_loss: 272.6000
Epoch 15/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 273.9028 - val_loss: 270.8762
Epoch 16/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 273.5906 - val_loss: 271.6645
Epoch 17/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 273.4216 - val_loss: 270.8429
Epoch 18/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 273.1853 - val_loss: 270.7830
Epoch 19/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 272.8438 - val_loss: 270.8235
Epoch 20/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 272.7348 - val_loss: 269.9814
Epoch 21/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 272.4986 - val_loss: 270.3731
Epoch 22/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 272.2981 - val_loss: 270.8537
Epoch 23/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 272.0719 - val_loss: 272.7423
Epoch 24/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 271.9885 - val_loss: 271.5590
Epoch 25/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 271.7573 - val_loss: 270.5564
Epoch 26/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 271.5659 - val_loss: 271.7017
Epoch 27/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 271.4569 - val_loss: 268.9186
Epoch 28/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 271.2637 - val_loss: 268.9637
Epoch 29/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 271.1294 - val_loss: 269.1677
Epoch 30/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 270.8861 - val_loss: 268.3495
Epoch 31/60
9445953/9445953 [==============================] - 13s 1us/step - loss: 270.7406 - val_loss: 269.4170
Epoch 32/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 270.7133 - val_loss: 268.7303
Epoch 33/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 270.4131 - val_loss: 267.9057
Epoch 34/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 270.2309 - val_loss: 268.1076
Epoch 35/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 270.0639 - val_loss: 269.6206
Epoch 36/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 269.6244 - val_loss: 267.3118
Epoch 37/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 269.0705 - val_loss: 269.5902
Epoch 38/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 268.4082 - val_loss: 264.8369
Epoch 39/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 267.4569 - val_loss: 263.8548
Epoch 40/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 266.3725 - val_loss: 263.3109
Epoch 41/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 265.1324 - val_loss: 262.6243
Epoch 42/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 263.6139 - val_loss: 259.1327
Epoch 43/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 262.1178 - val_loss: 257.1856
Epoch 44/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 260.7238 - val_loss: 257.9120
Epoch 45/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 259.5476 - val_loss: 256.1409
Epoch 46/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 258.5781 - val_loss: 253.1945
Epoch 47/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 257.4573 - val_loss: 252.3110
Epoch 48/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 256.5146 - val_loss: 251.0084
Epoch 49/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 255.6873 - val_loss: 250.3985
Epoch 50/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 254.9995 - val_loss: 250.5844
Epoch 51/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 254.1613 - val_loss: 247.5233
Epoch 52/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 253.6321 - val_loss: 246.6180
Epoch 53/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 253.0189 - val_loss: 246.4318
Epoch 54/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 252.5293 - val_loss: 249.2396
Epoch 55/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 251.8326 - val_loss: 251.0033
Epoch 56/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 251.5037 - val_loss: 244.6663
Epoch 57/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 251.0663 - val_loss: 246.4621
Epoch 58/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 250.5011 - val_loss: 247.0040
Epoch 59/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 250.3690 - val_loss: 248.2712
Epoch 60/60
9445953/9445953 [==============================] - 12s 1us/step - loss: 249.8070 - val_loss: 251.0582

         CHILD ACCURACY = 245.96190838509813


         PARENT ACCURACY = 232.61220405002524


 NODES EXPLORED:
(60, 30000)
(50, 18000)
(60, 18000)
(50, 30000)
(55, 30000)
(55, 18000)
(60, 24000)
(50, 24000)



 #########################  TRAINING COMPLETED  ###############################



C:\Users\mrinal\Documents\code_stuff\Carom Billiards Source>
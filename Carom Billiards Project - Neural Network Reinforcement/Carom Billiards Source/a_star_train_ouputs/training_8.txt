
C:\Users\mrinal\Documents\code_stuff\Carom Billiards Source>python nn_a_star_train.py
C:\Users\mrinal\AppData\Local\Programs\Python\Python36\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/65
2018-07-19 10:34:50.897943: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2018-07-19 10:34:52.078731: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1212] Found device 0 with properties:
name: GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:01:00.0
totalMemory: 4.00GiB freeMemory: 3.30GiB
2018-07-19 10:34:52.088207: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 10:34:53.502182: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3032 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 20s 2us/step - loss: 320.3372 - val_loss: 312.0818
Epoch 2/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 310.1454 - val_loss: 334.7176
Epoch 3/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 301.4950 - val_loss: 291.1776
Epoch 4/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 288.4395 - val_loss: 281.6947
Epoch 5/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 282.9535 - val_loss: 280.3450
Epoch 6/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 280.6047 - val_loss: 278.1356
Epoch 7/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 279.1208 - val_loss: 275.9606
Epoch 8/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 278.1330 - val_loss: 274.7478
Epoch 9/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 277.5076 - val_loss: 274.9555
Epoch 10/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 276.8295 - val_loss: 274.1302
Epoch 11/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 276.5985 - val_loss: 272.8440
Epoch 12/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 275.9235 - val_loss: 273.6644
Epoch 13/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 275.2981 - val_loss: 273.0635
Epoch 14/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 274.2867 - val_loss: 270.6099                   Epoch 15/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.9091 - val_loss: 271.4832
Epoch 16/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 271.5726 - val_loss: 267.2264                   Epoch 17/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 269.9387 - val_loss: 267.7436
Epoch 18/65                                                                                                             9445953/9445953 [==============================] - 16s 2us/step - loss: 268.4614 - val_loss: 270.5887
Epoch 19/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 266.9755 - val_loss: 261.6413                   Epoch 20/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 265.6546 - val_loss: 262.8162
Epoch 21/65                                                                                                             9445953/9445953 [==============================] - 16s 2us/step - loss: 264.4453 - val_loss: 263.0194
Epoch 22/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 263.3999 - val_loss: 259.4247                   Epoch 23/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 262.1720 - val_loss: 260.0482
Epoch 24/65                                                                                                             9445953/9445953 [==============================] - 16s 2us/step - loss: 261.1848 - val_loss: 257.8363
Epoch 25/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 260.0048 - val_loss: 258.2892                   Epoch 26/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 258.9255 - val_loss: 261.8384
Epoch 27/65                                                                                                             9445953/9445953 [==============================] - 16s 2us/step - loss: 257.5393 - val_loss: 253.4401
Epoch 28/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 254.7303 - val_loss: 249.0942
Epoch 29/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 251.5982 - val_loss: 245.7733
Epoch 30/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 249.1271 - val_loss: 248.7927
Epoch 31/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 246.2437 - val_loss: 246.5062
Epoch 32/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 244.2405 - val_loss: 249.1061
Epoch 33/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 242.2319 - val_loss: 241.1444
Epoch 34/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 240.3382 - val_loss: 236.9373
Epoch 35/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 238.6912 - val_loss: 233.3948
Epoch 36/65                                                                                                             9445953/9445953 [==============================] - 16s 2us/step - loss: 236.8924 - val_loss: 240.3249
Epoch 37/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 235.5825 - val_loss: 239.7873                   Epoch 38/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 234.6546 - val_loss: 230.5457
Epoch 39/65                                                                                                             9445953/9445953 [==============================] - 16s 2us/step - loss: 233.3605 - val_loss: 239.2562
Epoch 40/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 231.9259 - val_loss: 232.6333                   Epoch 41/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 230.9549 - val_loss: 231.9295
Epoch 42/65                                                                                                             9445953/9445953 [==============================] - 16s 2us/step - loss: 229.9234 - val_loss: 234.3539
Epoch 43/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 228.8436 - val_loss: 229.4477                   Epoch 44/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 227.9847 - val_loss: 229.0808
Epoch 45/65                                                                                                             9445953/9445953 [==============================] - 16s 2us/step - loss: 227.0723 - val_loss: 226.6201
Epoch 46/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 226.1677 - val_loss: 228.5742                   Epoch 47/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 225.0435 - val_loss: 229.0388
Epoch 48/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 224.7734 - val_loss: 229.3185
Epoch 49/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 223.7910 - val_loss: 228.3981
Epoch 50/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 223.1199 - val_loss: 231.1345
Epoch 51/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 222.4732 - val_loss: 221.2339
Epoch 52/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 221.8156 - val_loss: 235.5758
Epoch 53/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 221.1352 - val_loss: 225.6252
Epoch 54/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 220.6884 - val_loss: 225.4974
Epoch 55/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 219.8310 - val_loss: 222.4940
Epoch 56/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 219.7365 - val_loss: 223.5165
Epoch 57/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 218.6297 - val_loss: 226.9212
Epoch 58/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 218.5352 - val_loss: 227.7902
Epoch 59/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 217.8568 - val_loss: 219.6182
Epoch 60/65                                                                                                             9445953/9445953 [==============================] - 16s 2us/step - loss: 217.4331 - val_loss: 222.4750
Epoch 61/65                                                                                                             9445953/9445953 [==============================] - 16s 2us/step - loss: 216.8674 - val_loss: 217.6303
Epoch 62/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 216.6093 - val_loss: 224.4584
Epoch 63/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 216.1503 - val_loss: 219.4933
Epoch 64/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 215.5568 - val_loss: 220.2888
Epoch 65/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 215.1149 - val_loss: 226.2891

 ###### inititial_accuracy = 229.40698381775906



 QUEUE SIZE BEFORE GET = 1


 NODE SELECTED <<<------ Epochs = 65 -------- BatchSize = 30000 --------- Accuracy = 229.40698381775906 -------->>>


 CHILD 1 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 24000

         EPOCHS = 60
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/60
2018-07-19 10:52:03.097389: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 10:52:03.103208: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 18s 2us/step - loss: 321.5330 - val_loss: 307.9814
Epoch 2/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 301.6231 - val_loss: 285.3666
Epoch 3/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 286.0112 - val_loss: 279.2086
Epoch 4/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 281.2314 - val_loss: 276.3646
Epoch 5/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 278.2334 - val_loss: 275.1251
Epoch 6/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 276.2782 - val_loss: 277.1754
Epoch 7/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 274.7756 - val_loss: 273.3032
Epoch 8/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 273.6398 - val_loss: 274.3422
Epoch 9/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.8037 - val_loss: 272.2492
Epoch 10/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.0751 - val_loss: 269.7162                   Epoch 11/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 271.3556 - val_loss: 269.7914
Epoch 12/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 270.9398 - val_loss: 269.2309
Epoch 13/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 270.4244 - val_loss: 276.7873
Epoch 14/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 270.1711 - val_loss: 268.0416
Epoch 15/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 269.7781 - val_loss: 267.7381
Epoch 16/60                                                                                                             9445953/9445953 [==============================] - 16s 2us/step - loss: 269.3974 - val_loss: 268.7347
Epoch 17/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 269.1146 - val_loss: 268.8592
Epoch 18/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 268.8552 - val_loss: 268.3138
Epoch 19/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 268.7094 - val_loss: 267.0957
Epoch 20/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 268.4747 - val_loss: 267.7618
Epoch 21/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 268.2880 - val_loss: 268.6788
Epoch 22/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 268.0524 - val_loss: 266.7550
Epoch 23/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 267.8566 - val_loss: 266.7798
Epoch 24/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 267.6667 - val_loss: 268.4090
Epoch 25/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 267.5045 - val_loss: 266.6572
Epoch 26/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 267.3230 - val_loss: 266.6974
Epoch 27/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 267.1709 - val_loss: 266.7986
Epoch 28/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 267.0165 - val_loss: 266.5115
Epoch 29/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 266.8717 - val_loss: 266.6751
Epoch 30/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 266.6804 - val_loss: 266.2955
Epoch 31/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 266.5860 - val_loss: 266.3121
Epoch 32/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 266.4019 - val_loss: 266.3104
Epoch 33/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 266.2690 - val_loss: 266.1148
Epoch 34/60                                                                                                             9445953/9445953 [==============================] - 16s 2us/step - loss: 266.0290 - val_loss: 267.2787
Epoch 35/60                                                                                                             9445953/9445953 [==============================] - 16s 2us/step - loss: 266.0272 - val_loss: 266.9225
Epoch 36/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 265.7888 - val_loss: 266.5298
Epoch 37/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 265.6461 - val_loss: 266.6845
Epoch 38/60
9445953/9445953 [==============================] - 18s 2us/step - loss: 265.5190 - val_loss: 266.1272
Epoch 39/60                                                                                                             9445953/9445953 [==============================] - 17s 2us/step - loss: 265.2965 - val_loss: 265.3205
Epoch 40/60
9445953/9445953 [==============================] - 18s 2us/step - loss: 265.0372 - val_loss: 264.9802                   Epoch 41/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 264.6837 - val_loss: 265.0759
Epoch 42/60                                                                                                             9445953/9445953 [==============================] - 19s 2us/step - loss: 263.6421 - val_loss: 263.5779
Epoch 43/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 261.1199 - val_loss: 256.8696                   Epoch 44/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 256.7301 - val_loss: 251.4169
Epoch 45/60                                                                                                             9445953/9445953 [==============================] - 17s 2us/step - loss: 251.8123 - val_loss: 254.6920                   Epoch 46/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 248.0091 - val_loss: 248.8974                   Epoch 47/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 244.5995 - val_loss: 241.7310
Epoch 48/60                                                                                                             9445953/9445953 [==============================] - 16s 2us/step - loss: 242.3445 - val_loss: 238.8136
Epoch 49/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 239.9711 - val_loss: 242.0294                   Epoch 50/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 238.1373 - val_loss: 249.5819
Epoch 51/60
9445953/9445953 [==============================] - 21s 2us/step - loss: 236.4401 - val_loss: 238.7622
Epoch 52/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 235.0265 - val_loss: 236.2686
Epoch 53/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 233.6406 - val_loss: 234.2809
Epoch 54/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 232.3151 - val_loss: 238.8838
Epoch 55/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 231.2794 - val_loss: 236.4401
Epoch 56/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 230.4398 - val_loss: 234.0058
Epoch 57/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 229.3184 - val_loss: 231.2606
Epoch 58/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 228.6280 - val_loss: 231.3692
Epoch 59/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 227.7764 - val_loss: 234.2988
Epoch 60/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 227.2421 - val_loss: 226.7058

         CHILD ACCURACY = 233.57594531332393


         PARENT ACCURACY = 229.40698381775906


 CHILD 2 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 30000

         EPOCHS = 60
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/60
2018-07-19 11:08:37.065166: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 11:08:37.070620: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 17s 2us/step - loss: 325.0258 - val_loss: 314.6269
Epoch 2/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 314.2119 - val_loss: 306.4262
Epoch 3/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 307.0778 - val_loss: 294.6507
Epoch 4/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 294.0627 - val_loss: 298.9790
Epoch 5/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 283.9075 - val_loss: 283.8569
Epoch 6/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 280.5498 - val_loss: 278.0651
Epoch 7/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 278.6632 - val_loss: 274.9734
Epoch 8/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 277.0297 - val_loss: 277.8013
Epoch 9/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 275.8897 - val_loss: 274.5048
Epoch 10/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 274.9218 - val_loss: 270.9416
Epoch 11/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 273.6739 - val_loss: 276.1423
Epoch 12/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.9357 - val_loss: 270.0105
Epoch 13/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.1163 - val_loss: 269.5502
Epoch 14/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 271.3289 - val_loss: 269.1760
Epoch 15/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 270.3968 - val_loss: 268.7095
Epoch 16/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 269.1656 - val_loss: 267.1650
Epoch 17/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 267.3179 - val_loss: 263.9995
Epoch 18/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 265.2021 - val_loss: 261.9697
Epoch 19/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 262.5920 - val_loss: 260.6521
Epoch 20/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 260.0563 - val_loss: 261.5118
Epoch 21/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 257.8414 - val_loss: 256.1793
Epoch 22/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 255.7515 - val_loss: 251.7764
Epoch 23/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 253.7817 - val_loss: 249.6343
Epoch 24/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 251.9339 - val_loss: 258.2606
Epoch 25/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 250.1966 - val_loss: 251.4744
Epoch 26/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 248.7598 - val_loss: 248.5083
Epoch 27/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 247.0148 - val_loss: 248.2315
Epoch 28/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 245.7019 - val_loss: 245.4851
Epoch 29/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 244.0828 - val_loss: 246.9723
Epoch 30/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 242.9422 - val_loss: 243.5904
Epoch 31/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 241.5278 - val_loss: 237.8107
Epoch 32/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 240.4565 - val_loss: 239.8460
Epoch 33/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 239.2240 - val_loss: 238.1547
Epoch 34/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 238.2339 - val_loss: 235.7866
Epoch 35/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 236.9803 - val_loss: 238.8207
Epoch 36/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 236.0087 - val_loss: 234.0783
Epoch 37/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 235.1438 - val_loss: 233.2543
Epoch 38/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 234.1834 - val_loss: 232.3773
Epoch 39/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 233.2558 - val_loss: 229.6839
Epoch 40/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 232.5102 - val_loss: 238.0764
Epoch 41/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 231.4316 - val_loss: 236.9629
Epoch 42/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 231.0399 - val_loss: 234.6307
Epoch 43/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 230.1099 - val_loss: 234.7025
Epoch 44/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 229.2638 - val_loss: 231.2886
Epoch 45/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 228.6846 - val_loss: 230.4526
Epoch 46/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 228.0267 - val_loss: 229.0129
Epoch 47/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 227.1388 - val_loss: 231.2964
Epoch 48/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 226.8774 - val_loss: 231.2106
Epoch 49/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 226.2157 - val_loss: 230.6353
Epoch 50/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 225.3218 - val_loss: 237.4949
Epoch 51/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 224.8575 - val_loss: 226.2776
Epoch 52/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 224.4535 - val_loss: 230.6842
Epoch 53/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 223.9271 - val_loss: 226.1570
Epoch 54/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 223.5114 - val_loss: 224.6924
Epoch 55/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 222.7545 - val_loss: 227.4344
Epoch 56/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 222.6053 - val_loss: 224.8843
Epoch 57/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 221.9537 - val_loss: 230.0076
Epoch 58/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 221.4999 - val_loss: 222.8382
Epoch 59/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 220.9445 - val_loss: 221.9688
Epoch 60/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 220.6051 - val_loss: 219.8382

         CHILD ACCURACY = 226.07561254111823


         PARENT ACCURACY = 229.40698381775906


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 1 <<<<<<<<<<<<<<<<<<<<<<<<<<<


                         ********** BEST MODEL SAVED | EPOCHS = 60 | BATCH_SIZE = 30000 | ACCURACY = 226.07561254111823 ********




 CHILD 3 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 24000

         EPOCHS = 70
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/70
2018-07-19 11:24:31.313157: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 11:24:31.320959: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 17s 2us/step - loss: 319.1439 - val_loss: 313.1551
Epoch 2/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 306.4503 - val_loss: 291.4861
Epoch 3/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 292.4062 - val_loss: 287.1826
Epoch 4/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 285.5296 - val_loss: 280.0980
Epoch 5/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 280.7716 - val_loss: 275.0544
Epoch 6/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 276.5836 - val_loss: 271.8213
Epoch 7/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 273.3323 - val_loss: 270.9926
Epoch 8/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 270.1225 - val_loss: 265.6198
Epoch 9/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 267.0153 - val_loss: 266.2737
Epoch 10/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 264.2588 - val_loss: 263.9398
Epoch 11/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 261.8441 - val_loss: 259.1153
Epoch 12/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 259.5212 - val_loss: 256.2693
Epoch 13/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 257.2247 - val_loss: 255.7567
Epoch 14/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 255.1866 - val_loss: 255.1399
Epoch 15/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 253.2481 - val_loss: 248.8091
Epoch 16/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 251.3555 - val_loss: 249.4277
Epoch 17/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 249.4914 - val_loss: 252.7840
Epoch 18/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 247.7348 - val_loss: 248.6845
Epoch 19/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 246.0346 - val_loss: 245.9530
Epoch 20/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 244.6533 - val_loss: 243.2907
Epoch 21/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 242.9659 - val_loss: 248.7452
Epoch 22/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 241.5375 - val_loss: 240.7193
Epoch 23/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 240.2743 - val_loss: 237.7903
Epoch 24/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 238.9752 - val_loss: 242.5522
Epoch 25/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 237.7568 - val_loss: 238.1707
Epoch 26/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 236.7133 - val_loss: 231.8122
Epoch 27/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 235.5116 - val_loss: 235.8584
Epoch 28/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 234.7846 - val_loss: 236.0184
Epoch 29/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 233.5763 - val_loss: 232.6950
Epoch 30/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 232.5179 - val_loss: 238.9176
Epoch 31/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 232.0070 - val_loss: 239.0979
Epoch 32/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 231.0255 - val_loss: 231.9162
Epoch 33/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 230.3665 - val_loss: 232.1826
Epoch 34/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 229.5505 - val_loss: 232.4529
Epoch 35/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 228.8567 - val_loss: 233.2475
Epoch 36/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 228.1224 - val_loss: 231.8389
Epoch 37/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 227.5129 - val_loss: 235.2095
Epoch 38/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 226.6853 - val_loss: 232.6748
Epoch 39/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 226.3679 - val_loss: 233.2637
Epoch 40/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 225.5536 - val_loss: 243.6594
Epoch 41/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 225.0571 - val_loss: 229.4875
Epoch 42/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 224.7803 - val_loss: 224.9097
Epoch 43/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 223.8909 - val_loss: 226.8618
Epoch 44/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 223.4554 - val_loss: 222.1504
Epoch 45/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 223.1991 - val_loss: 222.0345
Epoch 46/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 222.7195 - val_loss: 223.4495
Epoch 47/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 222.1739 - val_loss: 227.4364
Epoch 48/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 221.7604 - val_loss: 230.5662
Epoch 49/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 221.1770 - val_loss: 225.9380
Epoch 50/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 221.0506 - val_loss: 222.3350
Epoch 51/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 220.6397 - val_loss: 224.8398
Epoch 52/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 220.1980 - val_loss: 224.9527
Epoch 53/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 219.6929 - val_loss: 222.1401
Epoch 54/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 219.3792 - val_loss: 223.4299
Epoch 55/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 219.0400 - val_loss: 223.2328
Epoch 56/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 218.9807 - val_loss: 224.0168
Epoch 57/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 218.4029 - val_loss: 227.8925
Epoch 58/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 218.4327 - val_loss: 220.7904
Epoch 59/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 217.6170 - val_loss: 237.0100
Epoch 60/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 217.7006 - val_loss: 222.6103
Epoch 61/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 217.4980 - val_loss: 226.9927
Epoch 62/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 217.1965 - val_loss: 223.2816
Epoch 63/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 216.7274 - val_loss: 221.8196
Epoch 64/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 216.3534 - val_loss: 223.5352
Epoch 65/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 216.5234 - val_loss: 227.8675
Epoch 66/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 216.1941 - val_loss: 222.3915
Epoch 67/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 215.9498 - val_loss: 227.7698
Epoch 68/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 215.3981 - val_loss: 233.5174
Epoch 69/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 215.5811 - val_loss: 222.8470
Epoch 70/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 214.8141 - val_loss: 217.5742

         CHILD ACCURACY = 235.4184345576338


         PARENT ACCURACY = 229.40698381775906


 CHILD 4 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 36000

         EPOCHS = 70
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/70
2018-07-19 11:43:30.380690: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 11:43:30.386809: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 16s 2us/step - loss: 322.3504 - val_loss: 312.0437
Epoch 2/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 312.7769 - val_loss: 306.1550
Epoch 3/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 306.9152 - val_loss: 293.5637
Epoch 4/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 294.3707 - val_loss: 289.0029
Epoch 5/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 285.2710 - val_loss: 283.3581
Epoch 6/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 280.4976 - val_loss: 278.2086
Epoch 7/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 277.6600 - val_loss: 273.6119
Epoch 8/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 275.8907 - val_loss: 275.8793
Epoch 9/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 274.2836 - val_loss: 271.1745
Epoch 10/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 273.2055 - val_loss: 273.9283
Epoch 11/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.1493 - val_loss: 270.6976
Epoch 12/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 270.6514 - val_loss: 271.7158
Epoch 13/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 269.6855 - val_loss: 265.9652
Epoch 14/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 268.1803 - val_loss: 267.8945
Epoch 15/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 266.5213 - val_loss: 269.7652
Epoch 16/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 264.3773 - val_loss: 264.5228
Epoch 17/70
9445953/9445953 [==============================] - 17s 2us/step - loss: 262.5038 - val_loss: 260.4516
Epoch 18/70
9445953/9445953 [==============================] - 17s 2us/step - loss: 260.6293 - val_loss: 259.9514
Epoch 19/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 258.9480 - val_loss: 254.1254
Epoch 20/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 257.1242 - val_loss: 257.3324
Epoch 21/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 255.5736 - val_loss: 257.7058
Epoch 22/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 254.1045 - val_loss: 257.4248
Epoch 23/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 252.4699 - val_loss: 251.2856
Epoch 24/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 250.9706 - val_loss: 249.7273
Epoch 25/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 249.7732 - val_loss: 251.0107
Epoch 26/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 248.3329 - val_loss: 249.2429
Epoch 27/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 247.0097 - val_loss: 248.0702
Epoch 28/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 245.9962 - val_loss: 246.9061
Epoch 29/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 244.5559 - val_loss: 242.4486
Epoch 30/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 243.4526 - val_loss: 245.1496
Epoch 31/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 242.3434 - val_loss: 245.3813
Epoch 32/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 241.2860 - val_loss: 240.7175
Epoch 33/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 240.1887 - val_loss: 239.6650
Epoch 34/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 239.3478 - val_loss: 241.0423
Epoch 35/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 238.3119 - val_loss: 246.0247
Epoch 36/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 237.4208 - val_loss: 238.9010
Epoch 37/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 236.5840 - val_loss: 239.0432
Epoch 38/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 235.5422 - val_loss: 242.0523
Epoch 39/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 234.8610 - val_loss: 233.4492
Epoch 40/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 234.0059 - val_loss: 240.0953
Epoch 41/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 232.9952 - val_loss: 239.6631
Epoch 42/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 232.4867 - val_loss: 238.2900
Epoch 43/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 231.5102 - val_loss: 238.6303
Epoch 44/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 230.7041 - val_loss: 235.9876
Epoch 45/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 230.3100 - val_loss: 233.6026
Epoch 46/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 229.3310 - val_loss: 228.8035
Epoch 47/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 228.5019 - val_loss: 226.1058
Epoch 48/70
9445953/9445953 [==============================] - 17s 2us/step - loss: 228.1012 - val_loss: 237.0162
Epoch 49/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 227.7792 - val_loss: 232.2852
Epoch 50/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 227.0545 - val_loss: 226.0305
Epoch 51/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 225.9948 - val_loss: 228.7889
Epoch 52/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 225.5350 - val_loss: 225.3314
Epoch 53/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 224.7926 - val_loss: 230.8826
Epoch 54/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 224.5993 - val_loss: 225.3446
Epoch 55/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 224.0236 - val_loss: 224.4116
Epoch 56/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 223.4891 - val_loss: 223.4462
Epoch 57/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 222.6882 - val_loss: 226.6960
Epoch 58/70
9445953/9445953 [==============================] - 17s 2us/step - loss: 222.4817 - val_loss: 226.4250
Epoch 59/70
9445953/9445953 [==============================] - 17s 2us/step - loss: 221.7864 - val_loss: 224.7877
Epoch 60/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 221.3925 - val_loss: 232.7556
Epoch 61/70
9445953/9445953 [==============================] - 17s 2us/step - loss: 220.9646 - val_loss: 226.2215
Epoch 62/70
9445953/9445953 [==============================] - 17s 2us/step - loss: 220.3696 - val_loss: 228.6751
Epoch 63/70
9445953/9445953 [==============================] - 17s 2us/step - loss: 219.9262 - val_loss: 226.7135
Epoch 64/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 219.6187 - val_loss: 229.3729
Epoch 65/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 219.0179 - val_loss: 228.2405
Epoch 66/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 218.6423 - val_loss: 223.7696
Epoch 67/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 217.9160 - val_loss: 229.0903
Epoch 68/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 218.1359 - val_loss: 225.2688
Epoch 69/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 217.7584 - val_loss: 223.1364
Epoch 70/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 216.9564 - val_loss: 221.3138

         CHILD ACCURACY = 231.7129993855752


         PARENT ACCURACY = 229.40698381775906


 CHILD 5 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 24000

         EPOCHS = 65
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/65
2018-07-19 12:02:22.594187: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 12:02:22.601061: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 17s 2us/step - loss: 321.2316 - val_loss: 315.3539
Epoch 2/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 314.0598 - val_loss: 307.9909
Epoch 3/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 307.3026 - val_loss: 305.4490
Epoch 4/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 290.7848 - val_loss: 280.5159
Epoch 5/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 282.5135 - val_loss: 280.6242
Epoch 6/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 280.2644 - val_loss: 279.7199
Epoch 7/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 278.6909 - val_loss: 277.1282
Epoch 8/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 277.6138 - val_loss: 275.6720
Epoch 9/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 276.6278 - val_loss: 273.6762
Epoch 10/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 275.7801 - val_loss: 272.6722
Epoch 11/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 275.2308 - val_loss: 273.9174
Epoch 12/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 274.9027 - val_loss: 272.1019
Epoch 13/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 274.4829 - val_loss: 273.0670
Epoch 14/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 274.0482 - val_loss: 273.3007
Epoch 15/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 273.8624 - val_loss: 271.8044
Epoch 16/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 273.5378 - val_loss: 272.6385
Epoch 17/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 273.3443 - val_loss: 271.0533
Epoch 18/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 273.0612 - val_loss: 271.6726
Epoch 19/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.9450 - val_loss: 271.3514
Epoch 20/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.7207 - val_loss: 270.9685
Epoch 21/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.5009 - val_loss: 271.0499
Epoch 22/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.4068 - val_loss: 270.7110
Epoch 23/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.2792 - val_loss: 271.2559
Epoch 24/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.1367 - val_loss: 271.3879
Epoch 25/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 271.9533 - val_loss: 271.0318
Epoch 26/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 271.8158 - val_loss: 270.6003
Epoch 27/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 271.6871 - val_loss: 270.5648
Epoch 28/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 271.6069 - val_loss: 270.7901
Epoch 29/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 271.4512 - val_loss: 270.6923
Epoch 30/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 271.3272 - val_loss: 270.7273
Epoch 31/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 271.2090 - val_loss: 271.4769
Epoch 32/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 271.0282 - val_loss: 270.8206
Epoch 33/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 270.9761 - val_loss: 270.7631
Epoch 34/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 270.7749 - val_loss: 271.6788
Epoch 35/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 270.6848 - val_loss: 270.5541
Epoch 36/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 270.4856 - val_loss: 269.9016
Epoch 37/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 270.3791 - val_loss: 270.5239
Epoch 38/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 270.1665 - val_loss: 269.7578
Epoch 39/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 269.9402 - val_loss: 269.8249
Epoch 40/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 269.7189 - val_loss: 268.5616
Epoch 41/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 269.4490 - val_loss: 268.1793
Epoch 42/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 268.8802 - val_loss: 269.1417
Epoch 43/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 266.6732 - val_loss: 265.9540
Epoch 44/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 263.1511 - val_loss: 262.4279
Epoch 45/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 261.1977 - val_loss: 258.7591
Epoch 46/65
9445953/9445953 [==============================] - 18s 2us/step - loss: 259.6714 - val_loss: 261.0679
Epoch 47/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 258.3073 - val_loss: 255.7221
Epoch 48/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 257.3794 - val_loss: 256.7037
Epoch 49/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 256.3586 - val_loss: 254.5649
Epoch 50/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 255.7269 - val_loss: 254.9497
Epoch 51/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 254.9759 - val_loss: 253.5556
Epoch 52/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 254.5474 - val_loss: 252.7484
Epoch 53/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 254.0221 - val_loss: 254.7552
Epoch 54/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 253.5491 - val_loss: 253.6362
Epoch 55/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 253.0201 - val_loss: 252.6972
Epoch 56/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 252.6921 - val_loss: 251.4684
Epoch 57/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 252.1896 - val_loss: 251.9545
Epoch 58/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 251.9893 - val_loss: 250.9421
Epoch 59/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 251.5617 - val_loss: 251.3057
Epoch 60/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 251.2745 - val_loss: 250.0453
Epoch 61/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 251.0058 - val_loss: 253.1981
Epoch 62/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 250.6437 - val_loss: 254.3200
Epoch 63/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 250.3588 - val_loss: 254.2902
Epoch 64/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 250.1513 - val_loss: 250.2717
Epoch 65/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 249.7771 - val_loss: 249.4338

         CHILD ACCURACY = 253.9251773483759


         PARENT ACCURACY = 229.40698381775906


 CHILD 6 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 36000

         EPOCHS = 60
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/60
2018-07-19 12:20:23.822255: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 12:20:23.828723: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 17s 2us/step - loss: 319.6426 - val_loss: 315.6023
Epoch 2/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 312.0981 - val_loss: 325.7069
Epoch 3/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 303.2296 - val_loss: 293.0065
Epoch 4/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 290.4141 - val_loss: 285.0487
Epoch 5/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 285.5479 - val_loss: 285.8163
Epoch 6/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 282.7370 - val_loss: 279.6728
Epoch 7/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 281.1496 - val_loss: 280.3990
Epoch 8/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 279.9805 - val_loss: 278.4824
Epoch 9/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 278.9037 - val_loss: 278.7704
Epoch 10/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 278.7165 - val_loss: 274.6850
Epoch 11/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 277.8121 - val_loss: 274.0683
Epoch 12/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 276.7104 - val_loss: 278.7893
Epoch 13/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 275.9000 - val_loss: 272.7790
Epoch 14/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 275.0995 - val_loss: 273.9630
Epoch 15/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 273.6782 - val_loss: 269.9233
Epoch 16/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.5407 - val_loss: 271.4710
Epoch 17/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 271.3851 - val_loss: 272.0755
Epoch 18/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 270.0755 - val_loss: 272.7145
Epoch 19/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 268.9122 - val_loss: 266.2727
Epoch 20/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 267.7981 - val_loss: 268.6012
Epoch 21/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 266.5443 - val_loss: 264.5733
Epoch 22/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 265.3030 - val_loss: 263.2097
Epoch 23/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 264.1527 - val_loss: 260.6422
Epoch 24/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 263.2144 - val_loss: 259.2045
Epoch 25/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 261.9755 - val_loss: 264.2438
Epoch 26/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 261.1799 - val_loss: 258.3416
Epoch 27/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 260.1690 - val_loss: 259.9004
Epoch 28/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 259.2912 - val_loss: 257.6084
Epoch 29/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 258.3831 - val_loss: 260.0188
Epoch 30/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 257.6824 - val_loss: 264.3264
Epoch 31/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 256.7836 - val_loss: 255.0072
Epoch 32/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 256.1401 - val_loss: 254.7802
Epoch 33/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 255.4532 - val_loss: 253.8078
Epoch 34/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 254.8651 - val_loss: 260.0094
Epoch 35/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 254.0564 - val_loss: 253.1970
Epoch 36/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 253.6264 - val_loss: 255.1272
Epoch 37/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 253.0470 - val_loss: 253.0515
Epoch 38/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 252.5777 - val_loss: 252.5693
Epoch 39/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 251.9705 - val_loss: 256.3086
Epoch 40/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 251.4999 - val_loss: 251.1560
Epoch 41/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 251.0527 - val_loss: 251.1388
Epoch 42/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 250.6883 - val_loss: 252.5889
Epoch 43/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 250.4120 - val_loss: 252.0827
Epoch 44/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 249.6197 - val_loss: 253.6168
Epoch 45/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 249.3916 - val_loss: 248.8769
Epoch 46/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 248.8730 - val_loss: 253.5708
Epoch 47/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 248.5339 - val_loss: 254.1501
Epoch 48/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 248.3596 - val_loss: 249.5530
Epoch 49/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 247.7444 - val_loss: 249.7967
Epoch 50/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 247.5213 - val_loss: 247.7651
Epoch 51/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 247.2407 - val_loss: 251.2444
Epoch 52/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 246.7324 - val_loss: 249.8743
Epoch 53/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 246.5960 - val_loss: 248.3609
Epoch 54/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 246.1765 - val_loss: 247.7419
Epoch 55/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 246.0569 - val_loss: 247.8654
Epoch 56/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 245.4547 - val_loss: 247.8668
Epoch 57/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 245.3892 - val_loss: 248.7452
Epoch 58/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 245.0015 - val_loss: 246.5812
Epoch 59/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 244.6478 - val_loss: 248.7426
Epoch 60/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 244.5595 - val_loss: 246.5029

         CHILD ACCURACY = 250.38642176654616


         PARENT ACCURACY = 229.40698381775906


 CHILD 7 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 36000

         EPOCHS = 65
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/65
2018-07-19 12:36:30.795793: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 12:36:30.799997: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 17s 2us/step - loss: 321.7171 - val_loss: 313.7950
Epoch 2/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 312.1290 - val_loss: 300.9115
Epoch 3/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 303.7436 - val_loss: 294.6497
Epoch 4/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 292.5579 - val_loss: 286.3913
Epoch 5/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 287.1209 - val_loss: 282.4042
Epoch 6/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 283.5469 - val_loss: 281.7743
Epoch 7/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 281.3260 - val_loss: 277.9080
Epoch 8/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 279.4295 - val_loss: 279.1953
Epoch 9/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 278.1593 - val_loss: 276.3803
Epoch 10/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 277.2751 - val_loss: 275.6359
Epoch 11/65
9445953/9445953 [==============================] - 17s 2us/step - loss: 276.3668 - val_loss: 274.3265
Epoch 12/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 275.9191 - val_loss: 272.8476
Epoch 13/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 275.0099 - val_loss: 273.2403
Epoch 14/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 274.7211 - val_loss: 274.3155
Epoch 15/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 274.1103 - val_loss: 273.1315
Epoch 16/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 273.4501 - val_loss: 276.3866
Epoch 17/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.9676 - val_loss: 272.2479
Epoch 18/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.2454 - val_loss: 270.5496
Epoch 19/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 271.4117 - val_loss: 274.6252
Epoch 20/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 270.8655 - val_loss: 268.2618
Epoch 21/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 270.0234 - val_loss: 272.9118
Epoch 22/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 269.2732 - val_loss: 267.9758
Epoch 23/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 268.2509 - val_loss: 265.6349
Epoch 24/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 267.6564 - val_loss: 270.4778
Epoch 25/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 266.9168 - val_loss: 266.7484
Epoch 26/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 266.1196 - val_loss: 264.0533
Epoch 27/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 265.2914 - val_loss: 269.5637
Epoch 28/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 264.6951 - val_loss: 261.7432
Epoch 29/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 263.6955 - val_loss: 263.0023
Epoch 30/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 262.8618 - val_loss: 259.5113
Epoch 31/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 262.1537 - val_loss: 261.4032
Epoch 32/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 261.4366 - val_loss: 264.9801
Epoch 33/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 260.6607 - val_loss: 260.7095
Epoch 34/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 260.0416 - val_loss: 264.1358
Epoch 35/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 259.3802 - val_loss: 261.4480
Epoch 36/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 258.6022 - val_loss: 257.8819
Epoch 37/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 258.0390 - val_loss: 258.9127
Epoch 38/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 257.4190 - val_loss: 256.7965
Epoch 39/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 256.8010 - val_loss: 256.7757
Epoch 40/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 256.3858 - val_loss: 259.1822
Epoch 41/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 255.8931 - val_loss: 256.3802
Epoch 42/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 255.3505 - val_loss: 255.8775
Epoch 43/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 254.9269 - val_loss: 254.2774
Epoch 44/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 254.4962 - val_loss: 254.7083
Epoch 45/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 254.0223 - val_loss: 253.9661
Epoch 46/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 253.9129 - val_loss: 254.1823
Epoch 47/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 253.3852 - val_loss: 251.4067
Epoch 48/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 253.0023 - val_loss: 252.0298
Epoch 49/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 252.5341 - val_loss: 252.8338
Epoch 50/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 252.4732 - val_loss: 253.8970
Epoch 51/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 251.9766 - val_loss: 254.8306
Epoch 52/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 251.6743 - val_loss: 255.1975
Epoch 53/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 251.4915 - val_loss: 253.1878
Epoch 54/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 251.1143 - val_loss: 258.1470
Epoch 55/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 250.9722 - val_loss: 259.8337
Epoch 56/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 250.5592 - val_loss: 252.3434
Epoch 57/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 250.4094 - val_loss: 250.8517
Epoch 58/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 249.8280 - val_loss: 258.1701
Epoch 59/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 249.9822 - val_loss: 251.7702
Epoch 60/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 249.5979 - val_loss: 250.3273
Epoch 61/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 249.4827 - val_loss: 253.4104
Epoch 62/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 249.1055 - val_loss: 254.5334
Epoch 63/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 248.9789 - val_loss: 249.4432
Epoch 64/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 248.5556 - val_loss: 254.5076
Epoch 65/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 248.7365 - val_loss: 252.0552

         CHILD ACCURACY = 256.4255919237946


         PARENT ACCURACY = 229.40698381775906


 CHILD 8 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 30000

         EPOCHS = 70
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/70
2018-07-19 12:53:51.512618: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 12:53:51.518925: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 17s 2us/step - loss: 323.4871 - val_loss: 325.5135
Epoch 2/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 315.5429 - val_loss: 305.4578
Epoch 3/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 300.1610 - val_loss: 293.9963
Epoch 4/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 291.9332 - val_loss: 286.0839
Epoch 5/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 286.6838 - val_loss: 279.9031
Epoch 6/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 282.7983 - val_loss: 278.1303
Epoch 7/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 280.5778 - val_loss: 276.8022
Epoch 8/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 278.8820 - val_loss: 276.2264
Epoch 9/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 277.2664 - val_loss: 278.0345
Epoch 10/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 276.6064 - val_loss: 272.6704
Epoch 11/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 275.3456 - val_loss: 272.6927
Epoch 12/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 274.4353 - val_loss: 271.0975
Epoch 13/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 273.5027 - val_loss: 270.8611
Epoch 14/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.9020 - val_loss: 270.7383
Epoch 15/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.4587 - val_loss: 269.8578
Epoch 16/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 271.8486 - val_loss: 269.2342
Epoch 17/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 271.3151 - val_loss: 270.0374
Epoch 18/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 270.8131 - val_loss: 268.9781
Epoch 19/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 270.2859 - val_loss: 267.6029
Epoch 20/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 269.8896 - val_loss: 266.9675
Epoch 21/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 269.3469 - val_loss: 267.5252
Epoch 22/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 268.9149 - val_loss: 268.6627
Epoch 23/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 268.5836 - val_loss: 274.4344
Epoch 24/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 268.0303 - val_loss: 266.4141
Epoch 25/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 267.3556 - val_loss: 267.2927
Epoch 26/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 267.1251 - val_loss: 266.0463
Epoch 27/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 266.7470 - val_loss: 266.0377
Epoch 28/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 266.1491 - val_loss: 264.4014
Epoch 29/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 265.4556 - val_loss: 265.3381
Epoch 30/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 264.7263 - val_loss: 264.4418
Epoch 31/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 264.1167 - val_loss: 261.2234
Epoch 32/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 262.0714 - val_loss: 267.6999
Epoch 33/70
9445953/9445953 [==============================] - 22s 2us/step - loss: 258.5629 - val_loss: 256.6854
Epoch 34/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 255.4034 - val_loss: 255.5770
Epoch 35/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 252.6874 - val_loss: 252.7211
Epoch 36/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 250.2655 - val_loss: 245.9936
Epoch 37/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 248.1743 - val_loss: 245.8145
Epoch 38/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 245.9687 - val_loss: 243.0835
Epoch 39/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 244.2180 - val_loss: 239.8088
Epoch 40/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 242.8558 - val_loss: 243.0873
Epoch 41/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 241.1622 - val_loss: 235.9977
Epoch 42/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 239.9973 - val_loss: 238.0124
Epoch 43/70
9445953/9445953 [==============================] - 17s 2us/step - loss: 238.7166 - val_loss: 233.2712
Epoch 44/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 237.4013 - val_loss: 232.6829
Epoch 45/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 236.3594 - val_loss: 239.2135
Epoch 46/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 235.5546 - val_loss: 236.6581
Epoch 47/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 234.5030 - val_loss: 232.6664
Epoch 48/70
9445953/9445953 [==============================] - 17s 2us/step - loss: 233.6165 - val_loss: 233.9343
Epoch 49/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 232.8851 - val_loss: 229.9184
Epoch 50/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 232.0322 - val_loss: 233.7578
Epoch 51/70
9445953/9445953 [==============================] - 17s 2us/step - loss: 231.3163 - val_loss: 236.1828
Epoch 52/70
9445953/9445953 [==============================] - 17s 2us/step - loss: 230.5136 - val_loss: 227.8577
Epoch 53/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 229.8846 - val_loss: 227.3919
Epoch 54/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 229.1169 - val_loss: 229.6455
Epoch 55/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 228.5565 - val_loss: 231.1971
Epoch 56/70
9445953/9445953 [==============================] - 17s 2us/step - loss: 228.0590 - val_loss: 229.3369
Epoch 57/70
9445953/9445953 [==============================] - 17s 2us/step - loss: 227.3097 - val_loss: 232.4450
Epoch 58/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 226.8097 - val_loss: 228.5966
Epoch 59/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 226.3343 - val_loss: 231.0781
Epoch 60/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 225.8089 - val_loss: 230.2278
Epoch 61/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 225.4070 - val_loss: 228.9684
Epoch 62/70
9445953/9445953 [==============================] - 17s 2us/step - loss: 225.0227 - val_loss: 228.2412
Epoch 63/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 224.2773 - val_loss: 222.9595
Epoch 64/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 224.1154 - val_loss: 230.0694
Epoch 65/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 223.5407 - val_loss: 225.3010
Epoch 66/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 223.3157 - val_loss: 231.8912
Epoch 67/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 222.9202 - val_loss: 224.7064
Epoch 68/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 222.4150 - val_loss: 220.7804
Epoch 69/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 222.2535 - val_loss: 223.6452
Epoch 70/70
9445953/9445953 [==============================] - 17s 2us/step - loss: 221.7095 - val_loss: 229.2807

         CHILD ACCURACY = 226.88173448261745


         PARENT ACCURACY = 229.40698381775906


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 2 <<<<<<<<<<<<<<<<<<<<<<<<<<<



 QUEUE SIZE BEFORE GET = 2


 NODE SELECTED <<<------ Epochs = 60 -------- BatchSize = 30000 --------- Accuracy = 226.07561254111823 -------->>>


 CHILD 1 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 30000

         EPOCHS = 55
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/55
2018-07-19 13:12:52.284813: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 13:12:52.296077: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 18s 2us/step - loss: 326.9624 - val_loss: 316.4079
Epoch 2/55
9445953/9445953 [==============================] - 17s 2us/step - loss: 314.6539 - val_loss: 306.3741
Epoch 3/55
9445953/9445953 [==============================] - 17s 2us/step - loss: 303.7598 - val_loss: 291.3138
Epoch 4/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 291.6685 - val_loss: 283.6540
Epoch 5/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 285.2755 - val_loss: 281.5837
Epoch 6/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 282.3884 - val_loss: 279.6386
Epoch 7/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 280.7546 - val_loss: 276.8982
Epoch 8/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 279.6002 - val_loss: 277.6667
Epoch 9/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 278.6407 - val_loss: 277.5325
Epoch 10/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 278.0260 - val_loss: 275.6889
Epoch 11/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 277.3491 - val_loss: 275.0833
Epoch 12/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 277.0010 - val_loss: 273.8406
Epoch 13/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 276.4329 - val_loss: 275.2647
Epoch 14/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 276.0258 - val_loss: 274.8307
Epoch 15/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 275.3719 - val_loss: 274.5623
Epoch 16/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 274.5729 - val_loss: 271.9243
Epoch 17/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 273.2801 - val_loss: 269.4585
Epoch 18/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 271.8097 - val_loss: 269.2694
Epoch 19/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 270.1809 - val_loss: 267.3875
Epoch 20/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 268.4019 - val_loss: 266.0687
Epoch 21/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 266.6525 - val_loss: 267.5028
Epoch 22/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 265.0451 - val_loss: 261.7998
Epoch 23/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 263.6656 - val_loss: 264.5362
Epoch 24/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 262.4977 - val_loss: 259.7102
Epoch 25/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 261.1519 - val_loss: 259.5988
Epoch 26/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 260.0694 - val_loss: 260.1442
Epoch 27/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 259.0594 - val_loss: 258.9374
Epoch 28/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 258.2398 - val_loss: 259.1308
Epoch 29/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 257.1134 - val_loss: 257.9063
Epoch 30/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 256.3854 - val_loss: 254.7274
Epoch 31/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 255.4654 - val_loss: 254.4345
Epoch 32/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 254.8781 - val_loss: 254.6982
Epoch 33/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 254.0858 - val_loss: 251.4703
Epoch 34/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 253.5384 - val_loss: 253.9099
Epoch 35/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 252.8705 - val_loss: 252.4928
Epoch 36/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 252.4874 - val_loss: 252.1166
Epoch 37/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 251.8249 - val_loss: 249.9144
Epoch 38/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 251.3080 - val_loss: 252.3177
Epoch 39/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 250.8863 - val_loss: 250.0890
Epoch 40/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 250.2625 - val_loss: 250.5066
Epoch 41/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 250.1219 - val_loss: 248.2801
Epoch 42/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 249.3246 - val_loss: 248.9535
Epoch 43/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 249.3148 - val_loss: 251.2052
Epoch 44/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 248.7388 - val_loss: 248.8492
Epoch 45/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 248.4908 - val_loss: 248.9034
Epoch 46/55
9445953/9445953 [==============================] - 17s 2us/step - loss: 247.8698 - val_loss: 248.9810
Epoch 47/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 247.7671 - val_loss: 248.7394
Epoch 48/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 247.4559 - val_loss: 248.4199
Epoch 49/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 247.0752 - val_loss: 248.9376
Epoch 50/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 246.8225 - val_loss: 246.9076
Epoch 51/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 246.5434 - val_loss: 246.4359
Epoch 52/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 246.1775 - val_loss: 252.4428
Epoch 53/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 245.8704 - val_loss: 251.3381
Epoch 54/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 245.7712 - val_loss: 247.8541
Epoch 55/55
9445953/9445953 [==============================] - 17s 2us/step - loss: 245.3840 - val_loss: 249.9143

         CHILD ACCURACY = 254.97388171995985


         PARENT ACCURACY = 226.07561254111823


 CHILD 2 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 30000

         EPOCHS = 65
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/65
2018-07-19 13:27:37.504696: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 13:27:37.511106: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 16s 2us/step - loss: 382.8505 - val_loss: 373.9005
Epoch 2/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 372.1545 - val_loss: 365.3173
Epoch 3/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 364.0184 - val_loss: 357.6871
Epoch 4/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 356.8056 - val_loss: 350.9450
Epoch 5/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 350.4472 - val_loss: 345.0211
Epoch 6/65
9445953/9445953 [==============================] - 16s 2us/step - loss: 344.8747 - val_loss: 339.8493
Epoch 7/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 340.0261 - val_loss: 335.3721
Epoch 8/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 335.8441 - val_loss: 331.5323
Epoch 9/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 332.2758 - val_loss: 328.2800
Epoch 10/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 329.2698 - val_loss: 325.5636
Epoch 11/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 326.7777 - val_loss: 323.3358
Epoch 12/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 324.7516 - val_loss: 321.5486
Epoch 13/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 323.1434 - val_loss: 320.1540
Epoch 14/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 321.9037 - val_loss: 319.1007
Epoch 15/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 320.9821 - val_loss: 318.3382
Epoch 16/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 320.3269 - val_loss: 317.8130
Epoch 17/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.8859 - val_loss: 317.4750
Epoch 18/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.6086 - val_loss: 317.2742
Epoch 19/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.4479 - val_loss: 317.1662
Epoch 20/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3639 - val_loss: 317.1159
Epoch 21/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3253 - val_loss: 317.0961
Epoch 22/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3098 - val_loss: 317.0901
Epoch 23/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3046 - val_loss: 317.0893
Epoch 24/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3032 - val_loss: 317.0896
Epoch 25/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0899
Epoch 26/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0901
Epoch 27/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0900
Epoch 28/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0901
Epoch 29/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0902
Epoch 30/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0899
Epoch 31/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0904
Epoch 32/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0900
Epoch 33/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0898
Epoch 34/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0901
Epoch 35/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0902
Epoch 36/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0897
Epoch 37/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3029 - val_loss: 317.0906
Epoch 38/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3031 - val_loss: 317.0898
Epoch 39/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0903
Epoch 40/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3031 - val_loss: 317.0898
Epoch 41/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0898
Epoch 42/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3029 - val_loss: 317.0911
Epoch 43/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3031 - val_loss: 317.0902
Epoch 44/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0910
Epoch 45/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3031 - val_loss: 317.0906
Epoch 46/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0899
Epoch 47/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0900
Epoch 48/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0901
Epoch 49/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3031 - val_loss: 317.0901
Epoch 50/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3031 - val_loss: 317.0900
Epoch 51/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0908
Epoch 52/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3031 - val_loss: 317.0895
Epoch 53/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3031 - val_loss: 317.0904
Epoch 54/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3031 - val_loss: 317.0904
Epoch 55/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3031 - val_loss: 317.0905
Epoch 56/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3031 - val_loss: 317.0900
Epoch 57/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0907
Epoch 58/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3031 - val_loss: 317.0899
Epoch 59/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0910
Epoch 60/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3032 - val_loss: 317.0895
Epoch 61/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0901
Epoch 62/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3031 - val_loss: 317.0899
Epoch 63/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3031 - val_loss: 317.0899
Epoch 64/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3031 - val_loss: 317.0906
Epoch 65/65
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3029 - val_loss: 317.0893

         CHILD ACCURACY = 314.87675892760785


         PARENT ACCURACY = 226.07561254111823


 CHILD 3 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 36000

         EPOCHS = 55
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/55
2018-07-19 13:44:13.456925: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 13:44:13.465314: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 16s 2us/step - loss: 320.1163 - val_loss: 313.4215
Epoch 2/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 309.0824 - val_loss: 294.7608
Epoch 3/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 295.5080 - val_loss: 286.0619
Epoch 4/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 287.9500 - val_loss: 287.4805
Epoch 5/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 282.8975 - val_loss: 282.4589
Epoch 6/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 279.9120 - val_loss: 277.5760
Epoch 7/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 277.5875 - val_loss: 275.1403
Epoch 8/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 276.2462 - val_loss: 274.1483
Epoch 9/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 274.9727 - val_loss: 274.7031
Epoch 10/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 273.6504 - val_loss: 274.3678
Epoch 11/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.5633 - val_loss: 273.3699
Epoch 12/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 271.0181 - val_loss: 272.8055
Epoch 13/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 269.7365 - val_loss: 266.9413
Epoch 14/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 267.8263 - val_loss: 266.1159
Epoch 15/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 265.7145 - val_loss: 261.1773
Epoch 16/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 263.4267 - val_loss: 259.0447
Epoch 17/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 261.1926 - val_loss: 256.2066
Epoch 18/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 259.2133 - val_loss: 259.9202
Epoch 19/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 257.2479 - val_loss: 254.2886
Epoch 20/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 255.6231 - val_loss: 254.5148
Epoch 21/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 254.1132 - val_loss: 256.0280
Epoch 22/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 252.5784 - val_loss: 259.4612
Epoch 23/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 251.1070 - val_loss: 256.6682
Epoch 24/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 249.6328 - val_loss: 258.4690
Epoch 25/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 248.4479 - val_loss: 248.7719
Epoch 26/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 247.4102 - val_loss: 246.4973
Epoch 27/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 245.8150 - val_loss: 247.9462
Epoch 28/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 244.9458 - val_loss: 246.9231
Epoch 29/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 243.7149 - val_loss: 242.3139
Epoch 30/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 242.9536 - val_loss: 247.3426
Epoch 31/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 241.9313 - val_loss: 244.0785
Epoch 32/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 240.9738 - val_loss: 242.7825
Epoch 33/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 239.6455 - val_loss: 240.6334
Epoch 34/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 239.0505 - val_loss: 241.7690
Epoch 35/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 238.1280 - val_loss: 236.9021
Epoch 36/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 236.8618 - val_loss: 244.6935
Epoch 37/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 236.6050 - val_loss: 237.0189
Epoch 38/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 235.6549 - val_loss: 249.7188
Epoch 39/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 234.9845 - val_loss: 239.3218
Epoch 40/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 234.1297 - val_loss: 237.4849
Epoch 41/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 233.2498 - val_loss: 234.2201
Epoch 42/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 232.7211 - val_loss: 242.2625
Epoch 43/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 232.0653 - val_loss: 236.9398
Epoch 44/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 231.3633 - val_loss: 236.2987
Epoch 45/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 230.7837 - val_loss: 241.6879
Epoch 46/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 230.3466 - val_loss: 231.3723
Epoch 47/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 229.8258 - val_loss: 234.4447
Epoch 48/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 228.9000 - val_loss: 233.7662
Epoch 49/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 228.4651 - val_loss: 233.1068
Epoch 50/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 228.0109 - val_loss: 229.4185
Epoch 51/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 227.1694 - val_loss: 230.5872
Epoch 52/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 226.9948 - val_loss: 233.9652
Epoch 53/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 226.1930 - val_loss: 233.0280
Epoch 54/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 226.0002 - val_loss: 231.8392
Epoch 55/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 225.4186 - val_loss: 230.6550

         CHILD ACCURACY = 238.5919916611547


         PARENT ACCURACY = 226.07561254111823


 CHILD 4 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 24000

         EPOCHS = 55
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/55
2018-07-19 13:58:37.903835: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 13:58:37.909653: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 17s 2us/step - loss: 318.9413 - val_loss: 311.6546
Epoch 2/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 309.7116 - val_loss: 300.1098
Epoch 3/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 289.7151 - val_loss: 286.3548
Epoch 4/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 283.1617 - val_loss: 286.5444
Epoch 5/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 280.7362 - val_loss: 276.1990
Epoch 6/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 278.8289 - val_loss: 274.7895
Epoch 7/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 277.3146 - val_loss: 274.3486
Epoch 8/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 276.0440 - val_loss: 274.1271
Epoch 9/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 274.4113 - val_loss: 270.3910
Epoch 10/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 273.0721 - val_loss: 271.8978
Epoch 11/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 271.1542 - val_loss: 271.6174
Epoch 12/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 269.1635 - val_loss: 266.8571
Epoch 13/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 266.9462 - val_loss: 264.6396
Epoch 14/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 264.3594 - val_loss: 263.9514
Epoch 15/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 261.6122 - val_loss: 256.3480
Epoch 16/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 258.5990 - val_loss: 255.0910
Epoch 17/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 256.1070 - val_loss: 258.3809
Epoch 18/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 253.6762 - val_loss: 249.8445
Epoch 19/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 251.4484 - val_loss: 249.7466
Epoch 20/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 249.3045 - val_loss: 254.0085
Epoch 21/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 247.5697 - val_loss: 249.3591
Epoch 22/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 245.7735 - val_loss: 240.6450
Epoch 23/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 244.2596 - val_loss: 249.7822
Epoch 24/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 242.8218 - val_loss: 243.6825
Epoch 25/55
9445953/9445953 [==============================] - 17s 2us/step - loss: 241.4261 - val_loss: 241.5374
Epoch 26/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 240.0498 - val_loss: 241.9398
Epoch 27/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 238.9188 - val_loss: 240.9285
Epoch 28/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 237.7122 - val_loss: 242.9718
Epoch 29/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 236.6861 - val_loss: 236.6765
Epoch 30/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 235.5677 - val_loss: 246.5498
Epoch 31/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 234.5826 - val_loss: 239.8087
Epoch 32/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 233.6366 - val_loss: 238.1385
Epoch 33/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 232.7537 - val_loss: 235.1212
Epoch 34/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 231.8108 - val_loss: 230.7957
Epoch 35/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 231.1337 - val_loss: 230.6459
Epoch 36/55
9445953/9445953 [==============================] - 17s 2us/step - loss: 230.1155 - val_loss: 228.8152
Epoch 37/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 229.5786 - val_loss: 227.0527
Epoch 38/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 228.7039 - val_loss: 231.6277
Epoch 39/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 228.3388 - val_loss: 234.5923
Epoch 40/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 227.6228 - val_loss: 231.6046
Epoch 41/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 226.8001 - val_loss: 230.1010
Epoch 42/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 226.2547 - val_loss: 231.4013
Epoch 43/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 225.8022 - val_loss: 229.6719
Epoch 44/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 225.0821 - val_loss: 232.2038
Epoch 45/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 224.6821 - val_loss: 233.4141
Epoch 46/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 224.2354 - val_loss: 223.0494
Epoch 47/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 223.6503 - val_loss: 232.6718
Epoch 48/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 223.4964 - val_loss: 226.5440
Epoch 49/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 222.7031 - val_loss: 228.4170
Epoch 50/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 222.4157 - val_loss: 227.2545
Epoch 51/55
9445953/9445953 [==============================] - 17s 2us/step - loss: 221.8381 - val_loss: 225.2232
Epoch 52/55
9445953/9445953 [==============================] - 17s 2us/step - loss: 221.6822 - val_loss: 225.4757
Epoch 53/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 221.3491 - val_loss: 234.8571
Epoch 54/55
9445953/9445953 [==============================] - 16s 2us/step - loss: 221.1325 - val_loss: 225.8718
Epoch 55/55
9445953/9445953 [==============================] - 17s 2us/step - loss: 220.3187 - val_loss: 223.5244

         CHILD ACCURACY = 233.74383463887153


         PARENT ACCURACY = 226.07561254111823


 CHILD 5 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 24000

         EPOCHS = 60
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/60
2018-07-19 14:13:37.497095: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 14:13:37.500655: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 17s 2us/step - loss: 320.3848 - val_loss: 314.2053
Epoch 2/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 307.8293 - val_loss: 302.5668
Epoch 3/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 292.1869 - val_loss: 284.7175
Epoch 4/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 284.9288 - val_loss: 284.0188
Epoch 5/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 281.1145 - val_loss: 280.8198
Epoch 6/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 278.0825 - val_loss: 273.6710
Epoch 7/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 275.2691 - val_loss: 271.9323
Epoch 8/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 272.4375 - val_loss: 266.1331
Epoch 9/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 269.4687 - val_loss: 263.7925
Epoch 10/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 266.5037 - val_loss: 263.6975
Epoch 11/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 264.1172 - val_loss: 262.3695
Epoch 12/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 261.9257 - val_loss: 256.5136
Epoch 13/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 259.7203 - val_loss: 256.8730
Epoch 14/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 257.7157 - val_loss: 253.3535
Epoch 15/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 255.9465 - val_loss: 252.4164
Epoch 16/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 253.9726 - val_loss: 254.2513
Epoch 17/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 252.1566 - val_loss: 249.5960
Epoch 18/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 250.3097 - val_loss: 247.9858
Epoch 19/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 248.8763 - val_loss: 247.4650
Epoch 20/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 247.2512 - val_loss: 243.2795
Epoch 21/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 245.8392 - val_loss: 240.5860
Epoch 22/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 244.3096 - val_loss: 242.0663
Epoch 23/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 242.9701 - val_loss: 244.2550
Epoch 24/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 241.7198 - val_loss: 242.6443
Epoch 25/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 240.4503 - val_loss: 246.9210
Epoch 26/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 239.3708 - val_loss: 237.4673
Epoch 27/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 238.0810 - val_loss: 240.9526
Epoch 28/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 237.1427 - val_loss: 245.3824
Epoch 29/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 236.2479 - val_loss: 239.6649
Epoch 30/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 235.2228 - val_loss: 237.2676
Epoch 31/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 234.1150 - val_loss: 232.6129
Epoch 32/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 233.5084 - val_loss: 237.7192
Epoch 33/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 232.5647 - val_loss: 239.6164
Epoch 34/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 231.6680 - val_loss: 233.3809
Epoch 35/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 230.9797 - val_loss: 234.9062
Epoch 36/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 230.2865 - val_loss: 230.3204
Epoch 37/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 229.6280 - val_loss: 228.7116
Epoch 38/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 228.8693 - val_loss: 236.2680
Epoch 39/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 228.3529 - val_loss: 233.5118
Epoch 40/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 227.8405 - val_loss: 230.7945
Epoch 41/60
9445953/9445953 [==============================] - 16s 2us/step - loss: 227.0660 - val_loss: 230.3025
Epoch 42/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 226.4968 - val_loss: 235.1118
Epoch 43/60
9445953/9445953 [==============================] - 18s 2us/step - loss: 225.8907 - val_loss: 232.1400
Epoch 44/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 225.5033 - val_loss: 232.3940
Epoch 45/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 225.0509 - val_loss: 235.3086
Epoch 46/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 224.4348 - val_loss: 227.5606
Epoch 47/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 223.9659 - val_loss: 229.4826
Epoch 48/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 223.6170 - val_loss: 228.9598
Epoch 49/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 223.1051 - val_loss: 225.6806
Epoch 50/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 222.9471 - val_loss: 223.1753
Epoch 51/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 222.1435 - val_loss: 231.9271
Epoch 52/60
9445953/9445953 [==============================] - 18s 2us/step - loss: 221.7637 - val_loss: 223.4143
Epoch 53/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 221.4688 - val_loss: 231.1006
Epoch 54/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 221.3623 - val_loss: 222.6707
Epoch 55/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 220.7386 - val_loss: 225.0226
Epoch 56/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 220.4641 - val_loss: 229.3007
Epoch 57/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 220.0023 - val_loss: 222.6989
Epoch 58/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 219.6686 - val_loss: 235.4807
Epoch 59/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 219.3354 - val_loss: 226.8401
Epoch 60/60
9445953/9445953 [==============================] - 17s 2us/step - loss: 219.0042 - val_loss: 225.2069

         CHILD ACCURACY = 235.61068475108516


         PARENT ACCURACY = 226.07561254111823



 QUEUE SIZE BEFORE GET = 1


 NODE SELECTED <<<------ Epochs = 70 -------- BatchSize = 30000 --------- Accuracy = 226.88173448261745 -------->>>


 CHILD 1 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 36000

         EPOCHS = 75
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/75
2018-07-19 14:30:25.716121: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 14:30:25.721363: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 17s 2us/step - loss: 321.3903 - val_loss: 314.4311
Epoch 2/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 311.9571 - val_loss: 302.4111
Epoch 3/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 301.7967 - val_loss: 292.9409
Epoch 4/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 290.5109 - val_loss: 284.8676
Epoch 5/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 284.1757 - val_loss: 281.1493
Epoch 6/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 281.1900 - val_loss: 275.7006
Epoch 7/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 279.2396 - val_loss: 279.9295
Epoch 8/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 277.8596 - val_loss: 277.5480
Epoch 9/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 276.5599 - val_loss: 273.4732
Epoch 10/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 275.1736 - val_loss: 272.5997
Epoch 11/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 274.3725 - val_loss: 270.4625
Epoch 12/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 273.3893 - val_loss: 273.0342
Epoch 13/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.4811 - val_loss: 271.0471
Epoch 14/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 271.8740 - val_loss: 268.6688
Epoch 15/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 270.9611 - val_loss: 269.3735
Epoch 16/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 270.3925 - val_loss: 268.0073
Epoch 17/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 269.7269 - val_loss: 269.3536
Epoch 18/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 269.0719 - val_loss: 267.0160
Epoch 19/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 268.4470 - val_loss: 266.9505
Epoch 20/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 267.7452 - val_loss: 272.9896
Epoch 21/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 267.0199 - val_loss: 267.2961
Epoch 22/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 266.3635 - val_loss: 268.5535
Epoch 23/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 265.4579 - val_loss: 265.7448
Epoch 24/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 264.2676 - val_loss: 263.1856
Epoch 25/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 262.1599 - val_loss: 258.1306
Epoch 26/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 259.6275 - val_loss: 261.6093
Epoch 27/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 257.4413 - val_loss: 255.6570
Epoch 28/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 255.4979 - val_loss: 250.4621
Epoch 29/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 253.6340 - val_loss: 250.2204
Epoch 30/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 251.9729 - val_loss: 250.7439
Epoch 31/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 250.2031 - val_loss: 250.8660
Epoch 32/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 248.8550 - val_loss: 255.6475
Epoch 33/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 247.4171 - val_loss: 246.5360
Epoch 34/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 246.1239 - val_loss: 246.9104
Epoch 35/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 244.9494 - val_loss: 245.0636
Epoch 36/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 243.6303 - val_loss: 245.6954
Epoch 37/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 242.6187 - val_loss: 242.8157
Epoch 38/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 241.4060 - val_loss: 244.1348
Epoch 39/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 240.4798 - val_loss: 247.6381
Epoch 40/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 239.5352 - val_loss: 237.1688
Epoch 41/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 238.5100 - val_loss: 239.4149
Epoch 42/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 237.8242 - val_loss: 244.3110
Epoch 43/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 236.8433 - val_loss: 235.6999
Epoch 44/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 235.9683 - val_loss: 237.3008
Epoch 45/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 235.1012 - val_loss: 239.8726
Epoch 46/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 234.5328 - val_loss: 241.0100
Epoch 47/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 233.6010 - val_loss: 234.9705
Epoch 48/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 233.0453 - val_loss: 231.4971
Epoch 49/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 232.4776 - val_loss: 234.2899
Epoch 50/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 231.9524 - val_loss: 235.8907
Epoch 51/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 230.9960 - val_loss: 237.5688
Epoch 52/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 230.8508 - val_loss: 228.5788
Epoch 53/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 229.8632 - val_loss: 231.4258
Epoch 54/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 229.4422 - val_loss: 234.3759
Epoch 55/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 228.9049 - val_loss: 234.3996
Epoch 56/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 228.1648 - val_loss: 230.8163
Epoch 57/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 227.9637 - val_loss: 235.0223
Epoch 58/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 227.3651 - val_loss: 225.9366
Epoch 59/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 226.7023 - val_loss: 231.2398
Epoch 60/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 226.3342 - val_loss: 226.1267
Epoch 61/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 225.8835 - val_loss: 232.7781
Epoch 62/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 225.4980 - val_loss: 231.9569
Epoch 63/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 225.1784 - val_loss: 230.3066
Epoch 64/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 224.0675 - val_loss: 226.3700
Epoch 65/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 224.2558 - val_loss: 226.2605
Epoch 66/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 223.6626 - val_loss: 228.0462
Epoch 67/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 223.1453 - val_loss: 234.9524
Epoch 68/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 223.2608 - val_loss: 229.5711
Epoch 69/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 222.6112 - val_loss: 229.6778
Epoch 70/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 222.0568 - val_loss: 233.0876
Epoch 71/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 222.1222 - val_loss: 230.4631
Epoch 72/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 221.5997 - val_loss: 229.2111
Epoch 73/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 221.2201 - val_loss: 230.0905
Epoch 74/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 220.8991 - val_loss: 223.0567
Epoch 75/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 220.5402 - val_loss: 227.8703

         CHILD ACCURACY = 234.04953680466588


         PARENT ACCURACY = 226.88173448261745


 CHILD 2 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 30000

         EPOCHS = 75
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/75
2018-07-19 14:50:34.504081: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 14:50:34.510724: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 17s 2us/step - loss: 324.5956 - val_loss: 314.8693
Epoch 2/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 313.3614 - val_loss: 299.5320
Epoch 3/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 297.7857 - val_loss: 282.9087
Epoch 4/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 287.2410 - val_loss: 284.4721
Epoch 5/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 282.4030 - val_loss: 277.4419
Epoch 6/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 279.7415 - val_loss: 277.4421
Epoch 7/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 278.1501 - val_loss: 278.5388
Epoch 8/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 276.7507 - val_loss: 274.5328
Epoch 9/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 275.8039 - val_loss: 280.0815
Epoch 10/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 274.9006 - val_loss: 272.9445
Epoch 11/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 273.9318 - val_loss: 272.8834
Epoch 12/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 272.9853 - val_loss: 270.8772
Epoch 13/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 271.9057 - val_loss: 270.9653
Epoch 14/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 270.6962 - val_loss: 273.1837
Epoch 15/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 269.2489 - val_loss: 267.8629
Epoch 16/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 267.4790 - val_loss: 262.3338
Epoch 17/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 265.7726 - val_loss: 263.1421
Epoch 18/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 263.5346 - val_loss: 266.6261
Epoch 19/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 261.6986 - val_loss: 257.1887
Epoch 20/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 259.5572 - val_loss: 256.9006
Epoch 21/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 257.5055 - val_loss: 253.5498
Epoch 22/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 255.6532 - val_loss: 256.1638
Epoch 23/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 253.5209 - val_loss: 253.3909
Epoch 24/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 251.6929 - val_loss: 247.2063
Epoch 25/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 250.2618 - val_loss: 246.5340
Epoch 26/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 248.4732 - val_loss: 245.0351
Epoch 27/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 246.8940 - val_loss: 247.6043
Epoch 28/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 245.6633 - val_loss: 241.5694
Epoch 29/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 244.2163 - val_loss: 240.9106
Epoch 30/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 243.1893 - val_loss: 242.1559
Epoch 31/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 241.7895 - val_loss: 239.0981
Epoch 32/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 240.9069 - val_loss: 237.0525
Epoch 33/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 239.4901 - val_loss: 238.4861
Epoch 34/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 238.5005 - val_loss: 239.0810
Epoch 35/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 237.6192 - val_loss: 238.0749
Epoch 36/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 236.5851 - val_loss: 241.5914
Epoch 37/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 235.6708 - val_loss: 237.4402
Epoch 38/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 234.7416 - val_loss: 235.6395
Epoch 39/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 233.7783 - val_loss: 232.0791
Epoch 40/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 232.8981 - val_loss: 231.2809
Epoch 41/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 232.2306 - val_loss: 230.7584
Epoch 42/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 231.4520 - val_loss: 238.6241
Epoch 43/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 230.7494 - val_loss: 232.6154
Epoch 44/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 230.0018 - val_loss: 237.2313
Epoch 45/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 229.3066 - val_loss: 228.0163
Epoch 46/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 228.6261 - val_loss: 227.1841
Epoch 47/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 227.8541 - val_loss: 224.7378
Epoch 48/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 227.3238 - val_loss: 232.7019
Epoch 49/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 226.7809 - val_loss: 230.8698
Epoch 50/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 225.9064 - val_loss: 228.3321
Epoch 51/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 225.8762 - val_loss: 226.4138
Epoch 52/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 225.0660 - val_loss: 226.2308
Epoch 53/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 224.6289 - val_loss: 230.4290
Epoch 54/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 224.1149 - val_loss: 227.0301
Epoch 55/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 223.6672 - val_loss: 220.8781
Epoch 56/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 223.1577 - val_loss: 228.3172
Epoch 57/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 222.6563 - val_loss: 227.1283
Epoch 58/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 222.1246 - val_loss: 222.1351
Epoch 59/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 221.8638 - val_loss: 232.3111
Epoch 60/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 221.4893 - val_loss: 222.9953
Epoch 61/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 221.1753 - val_loss: 233.1026
Epoch 62/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 220.7822 - val_loss: 222.7823
Epoch 63/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 220.2765 - val_loss: 224.9080
Epoch 64/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 219.5071 - val_loss: 228.9161
Epoch 65/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 219.5792 - val_loss: 223.4836
Epoch 66/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 219.1758 - val_loss: 223.9961
Epoch 67/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 218.9794 - val_loss: 218.7587
Epoch 68/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 218.6072 - val_loss: 229.0264
Epoch 69/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 217.9688 - val_loss: 218.0900
Epoch 70/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 217.7595 - val_loss: 224.4324
Epoch 71/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 217.5179 - val_loss: 227.8288
Epoch 72/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 217.0626 - val_loss: 229.1249
Epoch 73/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 216.9940 - val_loss: 220.0127
Epoch 74/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 216.6484 - val_loss: 220.7239
Epoch 75/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 216.4061 - val_loss: 221.7564

         CHILD ACCURACY = 229.0311792290867


         PARENT ACCURACY = 226.88173448261745


 CHILD 3 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 36000

         EPOCHS = 70
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/70
2018-07-19 15:10:49.976811: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 15:10:49.981757: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 16s 2us/step - loss: 381.9295 - val_loss: 375.0964
Epoch 2/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 373.9761 - val_loss: 367.6976
Epoch 3/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 366.9061 - val_loss: 361.0064
Epoch 4/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 360.5194 - val_loss: 354.9720
Epoch 5/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 354.7653 - val_loss: 349.5442
Epoch 6/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 349.5963 - val_loss: 344.6808
Epoch 7/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 344.9736 - val_loss: 340.3437
Epoch 8/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 340.8601 - val_loss: 336.4971
Epoch 9/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 337.2196 - val_loss: 333.1062
Epoch 10/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 334.0216 - val_loss: 330.1418
Epoch 11/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 331.2358 - val_loss: 327.5734
Epoch 12/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 328.8324 - val_loss: 325.3728
Epoch 13/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 326.7825 - val_loss: 323.5101
Epoch 14/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 325.0575 - val_loss: 321.9575
Epoch 15/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 323.6313 - val_loss: 320.6886
Epoch 16/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 322.4745 - val_loss: 319.6727
Epoch 17/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 321.5568 - val_loss: 318.8802
Epoch 18/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 320.8487 - val_loss: 318.2815
Epoch 19/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 320.3202 - val_loss: 317.8449
Epoch 20/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.9409 - val_loss: 317.5415
Epoch 21/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.6811 - val_loss: 317.3415
Epoch 22/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.5128 - val_loss: 317.2184
Epoch 23/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.4106 - val_loss: 317.1483
Epoch 24/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3535 - val_loss: 317.1125
Epoch 25/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 319.3243 - val_loss: 317.0966
Epoch 26/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 319.3110 - val_loss: 317.0908
Epoch 27/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3056 - val_loss: 317.0893
Epoch 28/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3037 - val_loss: 317.0894
Epoch 29/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 319.3031 - val_loss: 317.0896
Epoch 30/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0898
Epoch 31/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0900
Epoch 32/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 319.3030 - val_loss: 317.0899
Epoch 33/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3029 - val_loss: 317.0897
Epoch 34/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0900
Epoch 35/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0900
Epoch 36/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0902
Epoch 37/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3029 - val_loss: 317.0898
Epoch 38/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 319.3030 - val_loss: 317.0899
Epoch 39/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 319.3030 - val_loss: 317.0898
Epoch 40/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0902
Epoch 41/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0900
Epoch 42/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0896
Epoch 43/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0900
Epoch 44/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0902
Epoch 45/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0907
Epoch 46/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 319.3031 - val_loss: 317.0901
Epoch 47/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 319.3031 - val_loss: 317.0899
Epoch 48/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3031 - val_loss: 317.0897
Epoch 49/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 319.3031 - val_loss: 317.0898
Epoch 50/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3031 - val_loss: 317.0896
Epoch 51/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3031 - val_loss: 317.0898
Epoch 52/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 319.3030 - val_loss: 317.0899
Epoch 53/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 319.3030 - val_loss: 317.0908
Epoch 54/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 319.3030 - val_loss: 317.0901
Epoch 55/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 319.3030 - val_loss: 317.0897
Epoch 56/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3031 - val_loss: 317.0902
Epoch 57/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 319.3030 - val_loss: 317.0907
Epoch 58/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 319.3030 - val_loss: 317.0910
Epoch 59/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3031 - val_loss: 317.0901
Epoch 60/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 319.3031 - val_loss: 317.0905
Epoch 61/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3031 - val_loss: 317.0899
Epoch 62/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0902
Epoch 63/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0907
Epoch 64/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 319.3031 - val_loss: 317.0900
Epoch 65/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0894
Epoch 66/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0901
Epoch 67/70
9445953/9445953 [==============================] - 15s 2us/step - loss: 319.3030 - val_loss: 317.0900
Epoch 68/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 319.3030 - val_loss: 317.0901
Epoch 69/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 319.3030 - val_loss: 317.0896
Epoch 70/70
9445953/9445953 [==============================] - 16s 2us/step - loss: 319.3031 - val_loss: 317.0895

         CHILD ACCURACY = 314.876532006503


         PARENT ACCURACY = 226.88173448261745


 CHILD 4 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 24000

         EPOCHS = 75
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/75
2018-07-19 15:28:54.289610: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-19 15:28:54.295681: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 17s 2us/step - loss: 319.9601 - val_loss: 311.9760
Epoch 2/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 310.3957 - val_loss: 303.5076
Epoch 3/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 294.3764 - val_loss: 288.8144
Epoch 4/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 285.2594 - val_loss: 279.5240
Epoch 5/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 282.0901 - val_loss: 280.8381
Epoch 6/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 280.4270 - val_loss: 279.5162
Epoch 7/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 278.9561 - val_loss: 276.3505
Epoch 8/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 277.9685 - val_loss: 276.0408
Epoch 9/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 277.0380 - val_loss: 274.3852
Epoch 10/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 276.6295 - val_loss: 273.9180
Epoch 11/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 275.9614 - val_loss: 276.2968
Epoch 12/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 275.6637 - val_loss: 273.0359
Epoch 13/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 275.1958 - val_loss: 273.0642
Epoch 14/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 274.9827 - val_loss: 272.9967
Epoch 15/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 274.6522 - val_loss: 273.2989
Epoch 16/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 274.3115 - val_loss: 273.7996
Epoch 17/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 274.1447 - val_loss: 274.2037
Epoch 18/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 273.9000 - val_loss: 274.0156
Epoch 19/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 273.7335 - val_loss: 272.4723
Epoch 20/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 273.5340 - val_loss: 272.9857
Epoch 21/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 273.3602 - val_loss: 271.8190
Epoch 22/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 273.1001 - val_loss: 271.5481
Epoch 23/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.9433 - val_loss: 273.4507
Epoch 24/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.7178 - val_loss: 271.4255
Epoch 25/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.5198 - val_loss: 271.6463
Epoch 26/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.3927 - val_loss: 270.8753
Epoch 27/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.1961 - val_loss: 272.3055
Epoch 28/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 272.0008 - val_loss: 271.0486
Epoch 29/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 271.7274 - val_loss: 271.3020
Epoch 30/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 271.5481 - val_loss: 270.9870
Epoch 31/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 271.3424 - val_loss: 269.8336
Epoch 32/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 271.1180 - val_loss: 270.1529
Epoch 33/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 270.8829 - val_loss: 270.8835
Epoch 34/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 270.4855 - val_loss: 269.3890
Epoch 35/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 270.0780 - val_loss: 268.1661
Epoch 36/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 268.9779 - val_loss: 267.9373
Epoch 37/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 265.5904 - val_loss: 262.4558
Epoch 38/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 262.7457 - val_loss: 259.9356
Epoch 39/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 260.7509 - val_loss: 258.2115
Epoch 40/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 259.4037 - val_loss: 259.8173
Epoch 41/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 258.1893 - val_loss: 256.9545
Epoch 42/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 257.3303 - val_loss: 255.4168
Epoch 43/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 256.4725 - val_loss: 255.5607
Epoch 44/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 255.7814 - val_loss: 253.2850
Epoch 45/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 255.2796 - val_loss: 253.1322
Epoch 46/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 254.6753 - val_loss: 252.8337
Epoch 47/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 254.1287 - val_loss: 254.9807
Epoch 48/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 253.9002 - val_loss: 252.0839
Epoch 49/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 253.2380 - val_loss: 256.0754
Epoch 50/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 253.0435 - val_loss: 255.0198
Epoch 51/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 252.5550 - val_loss: 252.5480
Epoch 52/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 252.4797 - val_loss: 252.3563
Epoch 53/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 251.8753 - val_loss: 251.2468
Epoch 54/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 251.5227 - val_loss: 251.2272
Epoch 55/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 251.3671 - val_loss: 250.9760
Epoch 56/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 251.0140 - val_loss: 253.2967
Epoch 57/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 250.6662 - val_loss: 256.3153
Epoch 58/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 250.5493 - val_loss: 251.7344
Epoch 59/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 250.2954 - val_loss: 250.8995
Epoch 60/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 249.9710 - val_loss: 250.2086
Epoch 61/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 249.6638 - val_loss: 250.6254
Epoch 62/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 249.4998 - val_loss: 251.7283
Epoch 63/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 249.2498 - val_loss: 249.6311
Epoch 64/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 248.9443 - val_loss: 252.8170
Epoch 65/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 248.9138 - val_loss: 252.0883
Epoch 66/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 248.6449 - val_loss: 252.0077
Epoch 67/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 248.4801 - val_loss: 249.3161
Epoch 68/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 248.3698 - val_loss: 250.3257
Epoch 69/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 248.0050 - val_loss: 251.9961
Epoch 70/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 248.0390 - val_loss: 249.1554
Epoch 71/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 247.6779 - val_loss: 250.8254
Epoch 72/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 247.7526 - val_loss: 250.9367
Epoch 73/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 247.3339 - val_loss: 248.9494
Epoch 74/75
9445953/9445953 [==============================] - 17s 2us/step - loss: 247.3470 - val_loss: 252.2501
Epoch 75/75
9445953/9445953 [==============================] - 16s 2us/step - loss: 247.0809 - val_loss: 249.9673

         CHILD ACCURACY = 253.67318703585929


         PARENT ACCURACY = 226.88173448261745


 NODES EXPLORED:
(70, 36000)
(60, 24000)
(70, 24000)
(60, 36000)
(65, 36000)
(65, 24000)
(70, 30000)
(60, 30000)
(65, 30000)
(55, 30000)
(75, 36000)



 #########################  TRAINING COMPLETED  ###############################



C:\Users\mrinal\Documents\code_stuff\Carom Billiards Source>
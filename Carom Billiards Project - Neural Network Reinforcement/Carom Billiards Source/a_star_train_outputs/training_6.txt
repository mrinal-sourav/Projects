

Using TensorFlow backend.
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/50

pciBusID: 0000:01:00.0
totalMemory: 4.00GiB freeMemory: 3.30GiB
2018-07-17 22:08:47.423582: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 22:08:48.157523: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3032 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 38s 4us/step - loss: 308.0135 - val_loss: 286.1996
Epoch 2/50
9445953/9445953 [==============================] - 36s 4us/step - loss: 282.3080 - val_loss: 277.4312
Epoch 3/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 277.9857 - val_loss: 275.6733
Epoch 4/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 275.9936 - val_loss: 275.8578
Epoch 5/50
9445953/9445953 [==============================] - 36s 4us/step - loss: 274.2102 - val_loss: 271.4312
Epoch 6/50
9445953/9445953 [==============================] - 36s 4us/step - loss: 272.5489 - val_loss: 268.6946
Epoch 7/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 268.6455 - val_loss: 261.9172
Epoch 8/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 263.2063 - val_loss: 256.4948
Epoch 9/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 259.1146 - val_loss: 252.7189
Epoch 10/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 255.9987 - val_loss: 249.0365
Epoch 11/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 253.3114 - val_loss: 246.2095
Epoch 12/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 251.1041 - val_loss: 245.2188
Epoch 13/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 249.0773 - val_loss: 245.8489
Epoch 14/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 247.3531 - val_loss: 243.2547
Epoch 15/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 245.7233 - val_loss: 240.1835
Epoch 16/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 244.0609 - val_loss: 243.9599
Epoch 17/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 242.7431 - val_loss: 242.7226
Epoch 18/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 241.5518 - val_loss: 243.0844
Epoch 19/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 240.4085 - val_loss: 234.0897
Epoch 20/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 239.2988 - val_loss: 238.0288
Epoch 21/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 238.3604 - val_loss: 250.2306
Epoch 22/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 237.5649 - val_loss: 229.9565
Epoch 23/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 236.6700 - val_loss: 234.8704
Epoch 24/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 235.9540 - val_loss: 233.2108
Epoch 25/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 235.2027 - val_loss: 227.6673
Epoch 26/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 234.6494 - val_loss: 229.4165
Epoch 27/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 234.0488 - val_loss: 226.9172
Epoch 28/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 233.4551 - val_loss: 229.7259
Epoch 29/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 233.0878 - val_loss: 227.6031
Epoch 30/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 232.5184 - val_loss: 225.4982
Epoch 31/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 232.0483 - val_loss: 228.2349
Epoch 32/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 231.5260 - val_loss: 227.9222
Epoch 33/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 231.1396 - val_loss: 226.2446
Epoch 34/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.7641 - val_loss: 224.7139
Epoch 35/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.4719 - val_loss: 224.1410
Epoch 36/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.0443 - val_loss: 227.4444
Epoch 37/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 229.6079 - val_loss: 225.3604
Epoch 38/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 229.2715 - val_loss: 236.8148
Epoch 39/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.9398 - val_loss: 223.4522
Epoch 40/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.6737 - val_loss: 226.3073
Epoch 41/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.3299 - val_loss: 226.2945
Epoch 42/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.0110 - val_loss: 227.0598
Epoch 43/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.8491 - val_loss: 219.9829
Epoch 44/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.4624 - val_loss: 223.2889
Epoch 45/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.3041 - val_loss: 222.8178
Epoch 46/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.0573 - val_loss: 220.9345
Epoch 47/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.8360 - val_loss: 221.8947
Epoch 48/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.4431 - val_loss: 219.3477
Epoch 49/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.2480 - val_loss: 220.0864
Epoch 50/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.9272 - val_loss: 221.7896

 ###### inititial_accuracy = 215.19562747550978
                                                                                                                        

 QUEUE SIZE BEFORE GET = 1


 NODE SELECTED <<<------ Epochs = 50 -------- BatchSize = 9000--------- Accuracy = 215.19562747550978 -------->>>


 CHILD 1 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 10500

         EPOCHS = 55
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/55
2018-07-17 22:38:00.928584: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 22:38:00.933976: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 319.1282 - val_loss: 309.9455
Epoch 2/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 298.2320 - val_loss: 279.6668
Epoch 3/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 280.2852 - val_loss: 275.9127
Epoch 4/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 276.8120 - val_loss: 274.1469
Epoch 5/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 274.7527 - val_loss: 270.5838
Epoch 6/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 272.4721 - val_loss: 268.8124
Epoch 7/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 269.0044 - val_loss: 263.5132
Epoch 8/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 264.7996 - val_loss: 262.1229
Epoch 9/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 260.6545 - val_loss: 254.0561
Epoch 10/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 257.1850 - val_loss: 256.1902
Epoch 11/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 254.2723 - val_loss: 248.3592
Epoch 12/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 251.9291 - val_loss: 244.8480
Epoch 13/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 249.7152 - val_loss: 243.4460
Epoch 14/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 247.7988 - val_loss: 241.5526
Epoch 15/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 245.7764 - val_loss: 238.8942
Epoch 16/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 244.0866 - val_loss: 238.9338
Epoch 17/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 242.3058 - val_loss: 237.8513
Epoch 18/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 240.6655 - val_loss: 237.9461
Epoch 19/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 239.1445 - val_loss: 233.1407
Epoch 20/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 237.6852 - val_loss: 230.6968
Epoch 21/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 236.6561 - val_loss: 231.8644
Epoch 22/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 235.4441 - val_loss: 226.6714
Epoch 23/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 234.3020 - val_loss: 226.8733
Epoch 24/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 233.3237 - val_loss: 227.9012
Epoch 25/55                                                                                                                                                                                                        9445953/9445953 [==============================] - 33s 3us/step - loss: 232.4419 - val_loss: 226.3016
Epoch 26/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 231.8767 - val_loss: 225.6100
Epoch 27/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 230.9375 - val_loss: 227.0299                                                                                                              Epoch 28/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 230.3445 - val_loss: 223.0013
Epoch 29/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 229.6385 - val_loss: 223.6060
Epoch 30/55                                                                                                                                                                                                        9445953/9445953 [==============================] - 33s 3us/step - loss: 228.8803 - val_loss: 228.7482
Epoch 31/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 228.5141 - val_loss: 226.6145
Epoch 32/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 227.7113 - val_loss: 218.5889                                                                                                              Epoch 33/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 227.4510 - val_loss: 221.9273
Epoch 34/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 226.8317 - val_loss: 227.9396
Epoch 35/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 226.3684 - val_loss: 226.7416
Epoch 36/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 225.8542 - val_loss: 222.0142
Epoch 37/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 225.5358 - val_loss: 218.8907
Epoch 38/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 225.0642 - val_loss: 216.3934
Epoch 39/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 224.7008 - val_loss: 217.7001
Epoch 40/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 224.3033 - val_loss: 216.9015
Epoch 41/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 223.8442 - val_loss: 224.6997
Epoch 42/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 223.5044 - val_loss: 217.1486
Epoch 43/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 222.9928 - val_loss: 217.8032
Epoch 44/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 222.8896 - val_loss: 214.5661
Epoch 45/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 222.4697 - val_loss: 214.6410                                                                                                              Epoch 46/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 222.2502 - val_loss: 216.8164
Epoch 47/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 221.7524 - val_loss: 221.3989
Epoch 48/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 221.5901 - val_loss: 210.8225
Epoch 49/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 221.2117 - val_loss: 229.5201
Epoch 50/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 221.0121 - val_loss: 216.9100
Epoch 51/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 220.6257 - val_loss: 214.6444
Epoch 52/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 220.4634 - val_loss: 215.8467
Epoch 53/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 220.5620 - val_loss: 210.6120
Epoch 54/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 220.0187 - val_loss: 221.5908
Epoch 55/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 219.7849 - val_loss: 212.2498

         CHILD ACCURACY = 209.94244174160647


         PARENT ACCURACY = 215.19562747550978


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 1 <<<<<<<<<<<<<<<<<<<<<<<<<<<


                         ********** BEST MODEL SAVED | EPOCHS = 55 | BATCH_SIZE = 10500 | ACCURACY = 209.94244174160647 ********




 CHILD 2 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7500

         EPOCHS = 45
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-07-17 23:08:27.944899: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 23:08:27.949862: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 36s 4us/step - loss: 326.4726 - val_loss: 300.9872
Epoch 2/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 289.2003 - val_loss: 285.5444
Epoch 3/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 281.8715 - val_loss: 280.5830
Epoch 4/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 279.1933 - val_loss: 308.5834
Epoch 5/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 277.3228 - val_loss: 275.8023
Epoch 6/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 275.5708 - val_loss: 271.8955
Epoch 7/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 273.1256 - val_loss: 271.8894
Epoch 8/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 268.1946 - val_loss: 272.2707
Epoch 9/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 262.4508 - val_loss: 255.6777
Epoch 10/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 257.6661 - val_loss: 260.7795
Epoch 11/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 253.9833 - val_loss: 248.3556
Epoch 12/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 251.2040 - val_loss: 249.7355
Epoch 13/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 248.5020 - val_loss: 245.5359
Epoch 14/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 246.2331 - val_loss: 239.5391
Epoch 15/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 244.0833 - val_loss: 238.6004
Epoch 16/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 242.1481 - val_loss: 234.5426
Epoch 17/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 240.6181 - val_loss: 242.1136
Epoch 18/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 238.9791 - val_loss: 235.7926
Epoch 19/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 237.7803 - val_loss: 229.7401
Epoch 20/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 236.7471 - val_loss: 236.1878
Epoch 21/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 235.6955 - val_loss: 236.3116
Epoch 22/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 234.9333 - val_loss: 228.8098
Epoch 23/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 234.1906 - val_loss: 242.6605
Epoch 24/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 233.3139 - val_loss: 227.0897
Epoch 25/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 232.5284 - val_loss: 228.6603
Epoch 26/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 231.9051 - val_loss: 226.6222
Epoch 27/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 231.4657 - val_loss: 238.5014
Epoch 28/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.8346 - val_loss: 225.4395
Epoch 29/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.5202 - val_loss: 252.5667
Epoch 30/45                                                                                                                                                                                                        9445953/9445953 [==============================] - 35s 4us/step - loss: 230.0674 - val_loss: 222.6990
Epoch 31/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 229.4032 - val_loss: 224.6605
Epoch 32/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 229.1746 - val_loss: 220.4340
Epoch 33/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.6719 - val_loss: 229.6524
Epoch 34/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.0752 - val_loss: 227.4524
Epoch 35/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.9344 - val_loss: 220.3333
Epoch 36/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.3981 - val_loss: 218.4516
Epoch 37/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.2524 - val_loss: 229.5952
Epoch 38/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.9520 - val_loss: 218.9365
Epoch 39/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.8297 - val_loss: 220.8869
Epoch 40/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.3458 - val_loss: 221.3114
Epoch 41/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.0184 - val_loss: 218.8227
Epoch 42/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.8595 - val_loss: 225.4671
Epoch 43/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.5042 - val_loss: 218.0348
Epoch 44/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.3034 - val_loss: 224.8143
Epoch 45/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.2468 - val_loss: 229.1061

         CHILD ACCURACY = 223.23272916496774


         PARENT ACCURACY = 215.19562747550978


 CHILD 3 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7500

         EPOCHS = 50
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/50
2018-07-17 23:34:56.338169: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 23:34:56.344264: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 36s 4us/step - loss: 307.3194 - val_loss: 285.9379
Epoch 2/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 279.6182 - val_loss: 278.2557
Epoch 3/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 274.6329 - val_loss: 269.0982
Epoch 4/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 270.7940 - val_loss: 264.5816
Epoch 5/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 266.4143 - val_loss: 259.3266
Epoch 6/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 262.4433 - val_loss: 259.8333
Epoch 7/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 259.2896 - val_loss: 261.2943
Epoch 8/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 256.2571 - val_loss: 250.6835
Epoch 9/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 253.8223 - val_loss: 250.7641
Epoch 10/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 251.5586 - val_loss: 245.7559
Epoch 11/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 249.7627 - val_loss: 243.9188
Epoch 12/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 247.8779 - val_loss: 242.9742
Epoch 13/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 246.3395 - val_loss: 243.5548
Epoch 14/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 244.8178 - val_loss: 254.9581
Epoch 15/50
9445953/9445953 [==============================] - 36s 4us/step - loss: 243.2808 - val_loss: 237.7150
Epoch 16/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 241.9790 - val_loss: 238.5764
Epoch 17/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 240.7114 - val_loss: 234.7562
Epoch 18/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 239.4365 - val_loss: 236.5175
Epoch 19/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 238.2974 - val_loss: 233.7724
Epoch 20/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 237.4093 - val_loss: 232.9903
Epoch 21/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 236.3900 - val_loss: 235.2955
Epoch 22/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 235.3818 - val_loss: 228.7298
Epoch 23/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 234.7492 - val_loss: 232.2594
Epoch 24/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 233.8232 - val_loss: 226.3051                                                                                                              Epoch 25/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 233.1681 - val_loss: 229.5662
Epoch 26/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 232.5217 - val_loss: 235.5492
Epoch 27/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 231.9671 - val_loss: 227.7273
Epoch 28/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 231.3236 - val_loss: 223.2868
Epoch 29/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.6848 - val_loss: 225.1441
Epoch 30/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.1555 - val_loss: 236.1820
Epoch 31/50
9445953/9445953 [==============================] - 36s 4us/step - loss: 229.6907 - val_loss: 227.8955
Epoch 32/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 229.2461 - val_loss: 222.2627
Epoch 33/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.7121 - val_loss: 227.6163
Epoch 34/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.3055 - val_loss: 220.5386
Epoch 35/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.7849 - val_loss: 221.6899
Epoch 36/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.6297 - val_loss: 220.8583
Epoch 37/50
9445953/9445953 [==============================] - 36s 4us/step - loss: 227.1254 - val_loss: 227.1962
Epoch 38/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.7070 - val_loss: 221.2310
Epoch 39/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.4970 - val_loss: 223.8076
Epoch 40/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.0494 - val_loss: 228.3698
Epoch 41/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.8686 - val_loss: 218.1279
Epoch 42/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.5476 - val_loss: 217.7709
Epoch 43/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.1999 - val_loss: 218.6295
Epoch 44/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.8434 - val_loss: 217.9716
Epoch 45/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.6188 - val_loss: 233.2781
Epoch 46/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.5101 - val_loss: 215.6140
Epoch 47/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.0177 - val_loss: 218.1183
Epoch 48/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 223.6832 - val_loss: 227.3991
Epoch 49/50
9445953/9445953 [==============================] - 36s 4us/step - loss: 223.4336 - val_loss: 219.2470
Epoch 50/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 223.2061 - val_loss: 227.5205

         CHILD ACCURACY = 222.55724770842738


         PARENT ACCURACY = 215.19562747550978


 CHILD 4 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 10500

         EPOCHS = 45
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-07-18 00:04:28.177593: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 00:04:28.182581: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 33s 4us/step - loss: 323.6220 - val_loss: 309.2396
Epoch 2/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 299.3572 - val_loss: 286.4549
Epoch 3/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 279.0635 - val_loss: 276.2011
Epoch 4/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 276.2934 - val_loss: 272.5272
Epoch 5/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 274.5047 - val_loss: 272.0396
Epoch 6/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 272.8344 - val_loss: 268.4041
Epoch 7/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 269.4258 - val_loss: 264.0574
Epoch 8/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 264.5476 - val_loss: 258.1023
Epoch 9/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 260.0845 - val_loss: 253.1785
Epoch 10/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 256.5875 - val_loss: 252.6576
Epoch 11/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 254.1620 - val_loss: 246.5009
Epoch 12/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 251.8580 - val_loss: 245.2014
Epoch 13/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 250.1429 - val_loss: 244.2456
Epoch 14/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 248.4886 - val_loss: 240.4953
Epoch 15/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 246.7879 - val_loss: 241.3597
Epoch 16/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 245.3220 - val_loss: 240.7178
Epoch 17/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 244.1035 - val_loss: 239.6805
Epoch 18/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 242.7147 - val_loss: 239.0798
Epoch 19/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 241.5358 - val_loss: 234.5726
Epoch 20/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 240.1421 - val_loss: 232.7862
Epoch 21/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 239.0423 - val_loss: 231.7686
Epoch 22/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 237.8905 - val_loss: 229.3320
Epoch 23/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 237.0781 - val_loss: 229.0684
Epoch 24/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 236.0530 - val_loss: 227.5915
Epoch 25/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 235.2275 - val_loss: 229.7096
Epoch 26/45                                                                                                                                                                                                        9445953/9445953 [==============================] - 33s 3us/step - loss: 234.2458 - val_loss: 227.2793
Epoch 27/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 233.4097 - val_loss: 224.6681
Epoch 28/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 232.8030 - val_loss: 230.6882
Epoch 29/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 231.9188 - val_loss: 224.3419
Epoch 30/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 231.5418 - val_loss: 225.1028
Epoch 31/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 230.8040 - val_loss: 224.8653
Epoch 32/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 230.1436 - val_loss: 231.5367
Epoch 33/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 229.7665 - val_loss: 222.3239
Epoch 34/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 229.2161 - val_loss: 220.7894
Epoch 35/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 228.6696 - val_loss: 220.3877
Epoch 36/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 228.1103 - val_loss: 231.4606
Epoch 37/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 227.8412 - val_loss: 218.9709
Epoch 38/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 227.2045 - val_loss: 221.9578
Epoch 39/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 226.8776 - val_loss: 221.9150
Epoch 40/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 226.6728 - val_loss: 223.5268
Epoch 41/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 226.2063 - val_loss: 218.2873
Epoch 42/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 225.8535 - val_loss: 217.6824
Epoch 43/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 225.5124 - val_loss: 221.1601
Epoch 44/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 225.1164 - val_loss: 216.5896
Epoch 45/45
9445953/9445953 [==============================] - 33s 3us/step - loss: 225.0635 - val_loss: 218.8234

         CHILD ACCURACY = 211.74131495095924


         PARENT ACCURACY = 215.19562747550978


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 2 <<<<<<<<<<<<<<<<<<<<<<<<<<<


 CHILD 5 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 9000

         EPOCHS = 55
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/55
2018-07-18 00:29:07.033936: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 00:29:07.039018: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 313.8529 - val_loss: 305.5934
Epoch 2/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 286.6212 - val_loss: 279.1603
Epoch 3/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 278.4899 - val_loss: 271.8399
Epoch 4/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 273.3064 - val_loss: 267.4983
Epoch 5/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 267.5869 - val_loss: 265.8718
Epoch 6/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 262.7609 - val_loss: 256.7155
Epoch 7/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 258.7890 - val_loss: 252.1760
Epoch 8/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 255.6297 - val_loss: 249.2692
Epoch 9/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 253.1128 - val_loss: 248.1485
Epoch 10/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 250.8766 - val_loss: 256.4120
Epoch 11/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 248.9802 - val_loss: 241.7958
Epoch 12/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 247.3071 - val_loss: 239.3326
Epoch 13/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 245.7493 - val_loss: 239.7745
Epoch 14/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 244.1151 - val_loss: 241.0991
Epoch 15/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 242.6268 - val_loss: 240.4676
Epoch 16/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 241.2943 - val_loss: 238.2350
Epoch 17/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 239.9014 - val_loss: 232.9380
Epoch 18/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 238.7059 - val_loss: 232.6417
Epoch 19/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 237.6066 - val_loss: 230.3696
Epoch 20/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 236.4689 - val_loss: 229.5534                                                                                                              Epoch 21/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 235.4730 - val_loss: 233.9171
Epoch 22/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 234.6518 - val_loss: 228.8450
Epoch 23/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 233.7188 - val_loss: 234.2246
Epoch 24/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 232.9716 - val_loss: 236.2554
Epoch 25/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 232.1108 - val_loss: 227.9728
Epoch 26/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 231.4856 - val_loss: 233.7312
Epoch 27/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 230.9507 - val_loss: 224.0783
Epoch 28/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 230.2292 - val_loss: 238.3746
Epoch 29/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 229.7783 - val_loss: 226.5774
Epoch 30/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 229.4979 - val_loss: 222.1411
Epoch 31/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 228.6825 - val_loss: 226.4679
Epoch 32/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 228.0830 - val_loss: 231.5891
Epoch 33/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.7906 - val_loss: 222.4361
Epoch 34/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.4256 - val_loss: 222.8094
Epoch 35/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.8680 - val_loss: 219.8341
Epoch 36/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.4307 - val_loss: 222.6468
Epoch 37/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.1619 - val_loss: 226.5139
Epoch 38/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 225.8463 - val_loss: 224.1449
Epoch 39/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 225.3876 - val_loss: 216.0820
Epoch 40/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 225.1311 - val_loss: 220.1298
Epoch 41/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.8012 - val_loss: 223.9527
Epoch 42/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.5834 - val_loss: 219.6716
Epoch 43/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.2492 - val_loss: 228.2823
Epoch 44/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.0216 - val_loss: 218.7800
Epoch 45/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 223.4966 - val_loss: 216.4371
Epoch 46/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 223.1006 - val_loss: 224.5903
Epoch 47/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 223.0672 - val_loss: 226.7824
Epoch 48/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 222.6882 - val_loss: 219.3869
Epoch 49/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 222.5525 - val_loss: 212.4838
Epoch 50/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 222.0150 - val_loss: 219.3501
Epoch 51/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 222.2067 - val_loss: 218.3873
Epoch 52/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 221.9192 - val_loss: 214.4101
Epoch 53/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 221.6157 - val_loss: 212.5902
Epoch 54/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 221.4547 - val_loss: 212.3545
Epoch 55/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 221.1295 - val_loss: 222.3409

         CHILD ACCURACY = 209.31806106245202


         PARENT ACCURACY = 215.19562747550978


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 3 <<<<<<<<<<<<<<<<<<<<<<<<<<<


                         ********** BEST MODEL SAVED | EPOCHS = 55 | BATCH_SIZE = 9000 | ACCURACY = 209.31806106245202 ********




 CHILD 6 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 10500

         EPOCHS = 50
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/50
2018-07-18 01:00:14.978254: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 01:00:14.982781: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 33s 4us/step - loss: 327.3844 - val_loss: 329.7076
Epoch 2/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 296.0324 - val_loss: 286.6480
Epoch 3/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 283.0359 - val_loss: 275.9691
Epoch 4/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 277.3975 - val_loss: 279.0131
Epoch 5/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 275.3695 - val_loss: 275.2407
Epoch 6/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 273.8899 - val_loss: 272.7143
Epoch 7/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 273.0162 - val_loss: 274.5145
Epoch 8/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 272.1075 - val_loss: 269.9900
Epoch 9/50                                                                                                                                                                                                         9445953/9445953 [==============================] - 33s 3us/step - loss: 271.0985 - val_loss: 268.1628
Epoch 10/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 269.4970 - val_loss: 265.0680
Epoch 11/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 264.2171 - val_loss: 257.3953
Epoch 12/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 259.0887 - val_loss: 252.5172
Epoch 13/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 255.2159 - val_loss: 253.2616
Epoch 14/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 252.3991 - val_loss: 245.3353
Epoch 15/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 249.7145 - val_loss: 243.6714
Epoch 16/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 247.6598 - val_loss: 248.8800
Epoch 17/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 245.4242 - val_loss: 237.0465
Epoch 18/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 243.6627 - val_loss: 239.8731
Epoch 19/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 241.9405 - val_loss: 235.3815
Epoch 20/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 240.2050 - val_loss: 231.9913
Epoch 21/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 238.9939 - val_loss: 235.4928
Epoch 22/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 237.7375 - val_loss: 232.3667
Epoch 23/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 236.5925 - val_loss: 230.4242
Epoch 24/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 235.4147 - val_loss: 232.2720
Epoch 25/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 234.5280 - val_loss: 227.2674
Epoch 26/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 233.6864 - val_loss: 226.1926
Epoch 27/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 232.8323 - val_loss: 230.1379
Epoch 28/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 232.3160 - val_loss: 234.6040
Epoch 29/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 231.6339 - val_loss: 227.8270
Epoch 30/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 231.0844 - val_loss: 236.5406
Epoch 31/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.5954 - val_loss: 221.5374
Epoch 32/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.1026 - val_loss: 233.6940
Epoch 33/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 229.5893 - val_loss: 225.8601
Epoch 34/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 229.1129 - val_loss: 237.4793
Epoch 35/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 228.6964 - val_loss: 221.8064
Epoch 36/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 228.2718 - val_loss: 220.1739
Epoch 37/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 228.0374 - val_loss: 220.1194
Epoch 38/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.5835 - val_loss: 220.5570
Epoch 39/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.2252 - val_loss: 227.8013
Epoch 40/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.0741 - val_loss: 218.6485
Epoch 41/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.4004 - val_loss: 220.7796
Epoch 42/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.3362 - val_loss: 217.8864
Epoch 43/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.1009 - val_loss: 221.2380
Epoch 44/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.7731 - val_loss: 224.6309
Epoch 45/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 225.4177 - val_loss: 221.1072
Epoch 46/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 225.1101 - val_loss: 224.8600
Epoch 47/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.9763 - val_loss: 220.7886
Epoch 48/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.9342 - val_loss: 217.9893
Epoch 49/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.5550 - val_loss: 214.8402
Epoch 50/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.4507 - val_loss: 220.1635

         CHILD ACCURACY = 212.1617828397996


         PARENT ACCURACY = 215.19562747550978


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 4 <<<<<<<<<<<<<<<<<<<<<<<<<<<


 CHILD 7 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 9000

         EPOCHS = 45
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-07-18 01:28:02.666912: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 01:28:02.671834: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 36s 4us/step - loss: 321.4197 - val_loss: 304.3917
Epoch 2/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 301.8105 - val_loss: 282.2604
Epoch 3/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 282.4912 - val_loss: 279.9661
Epoch 4/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 278.0036 - val_loss: 279.5055
Epoch 5/45                                                                                                                                                                                                         9445953/9445953 [==============================] - 36s 4us/step - loss: 276.4839 - val_loss: 275.3094
Epoch 6/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 274.8153 - val_loss: 272.2587
Epoch 7/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 272.3848 - val_loss: 269.3738
Epoch 8/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 267.7129 - val_loss: 264.7636
Epoch 9/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 262.4422 - val_loss: 258.8075
Epoch 10/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 258.3171 - val_loss: 252.3080
Epoch 11/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 255.0202 - val_loss: 256.6570
Epoch 12/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 252.1560 - val_loss: 247.1904
Epoch 13/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 249.7833 - val_loss: 245.0448
Epoch 14/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 247.2627 - val_loss: 271.1352
Epoch 15/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 245.3194 - val_loss: 241.0612
Epoch 16/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 243.2670 - val_loss: 236.1195
Epoch 17/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 241.2256 - val_loss: 233.5642
Epoch 18/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 239.5090 - val_loss: 232.6473
Epoch 19/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 238.0554 - val_loss: 233.2121
Epoch 20/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 236.6250 - val_loss: 238.5553
Epoch 21/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 235.4412 - val_loss: 226.4776
Epoch 22/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 234.5548 - val_loss: 225.2240
Epoch 23/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 233.6624 - val_loss: 228.6520
Epoch 24/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 232.5409 - val_loss: 232.4571
Epoch 25/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 231.8803 - val_loss: 225.0820
Epoch 26/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.9524 - val_loss: 228.7970
Epoch 27/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.2869 - val_loss: 223.8536
Epoch 28/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 229.7314 - val_loss: 224.3315
Epoch 29/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 229.0510 - val_loss: 218.8436
Epoch 30/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 228.4720 - val_loss: 222.5576
Epoch 31/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.9022 - val_loss: 229.0956
Epoch 32/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.4792 - val_loss: 218.2838
Epoch 33/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.9111 - val_loss: 237.3709
Epoch 34/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.4411 - val_loss: 225.3834
Epoch 35/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.2360 - val_loss: 228.0648
Epoch 36/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 225.5313 - val_loss: 218.5626
Epoch 37/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 225.4992 - val_loss: 233.9610
Epoch 38/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.8405 - val_loss: 216.8589
Epoch 39/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 224.3525 - val_loss: 217.8409
Epoch 40/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.2229 - val_loss: 224.7578
Epoch 41/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 223.8236 - val_loss: 220.5686
Epoch 42/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 223.6378 - val_loss: 217.1624
Epoch 43/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 223.1610 - val_loss: 219.3526
Epoch 44/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 223.0616 - val_loss: 212.3723
Epoch 45/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 222.7836 - val_loss: 215.0198

         CHILD ACCURACY = 208.79254974375507


         PARENT ACCURACY = 215.19562747550978


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 5 <<<<<<<<<<<<<<<<<<<<<<<<<<<


                         ********** BEST MODEL SAVED | EPOCHS = 45 | BATCH_SIZE = 9000 | ACCURACY = 208.79254974375507 ********




 CHILD 8 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7500

         EPOCHS = 55
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/55
2018-07-18 01:54:39.604870: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 01:54:39.617912: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 38s 4us/step - loss: 308.5805 - val_loss: 282.2959
Epoch 2/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 282.6615 - val_loss: 281.1798
Epoch 3/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 279.1141 - val_loss: 275.5047
Epoch 4/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 278.0081 - val_loss: 279.1324
Epoch 5/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 277.2556 - val_loss: 274.5858
Epoch 6/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 276.8069 - val_loss: 275.6230
Epoch 7/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 276.4100 - val_loss: 277.7957
Epoch 8/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 276.0344 - val_loss: 273.7645
Epoch 9/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 275.6807 - val_loss: 273.8300
Epoch 10/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 275.4059 - val_loss: 274.0722
Epoch 11/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 275.0993 - val_loss: 276.2895
Epoch 12/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 274.7829 - val_loss: 273.0480
Epoch 13/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 274.3485 - val_loss: 272.2007
Epoch 14/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 273.7669 - val_loss: 272.1572
Epoch 15/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 271.5636 - val_loss: 266.1032
Epoch 16/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 266.8467 - val_loss: 261.3181
Epoch 17/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 264.1551 - val_loss: 264.0342
Epoch 18/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 262.3640 - val_loss: 258.2946
Epoch 19/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 261.1583 - val_loss: 257.8474
Epoch 20/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 260.1987 - val_loss: 257.0366
Epoch 21/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 259.3945 - val_loss: 256.4229
Epoch 22/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 258.7070 - val_loss: 255.1661
Epoch 23/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 257.9977 - val_loss: 255.4440
Epoch 24/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 257.5579 - val_loss: 253.4723
Epoch 25/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 257.0769 - val_loss: 253.3474
Epoch 26/55
9445953/9445953 [==============================] - 39s 4us/step - loss: 256.6316 - val_loss: 258.0098
Epoch 27/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 256.2553 - val_loss: 256.8244
Epoch 28/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 255.8659 - val_loss: 253.3402
Epoch 29/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 255.5647 - val_loss: 255.1553
Epoch 30/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 255.2021 - val_loss: 254.0953
Epoch 31/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 255.0303 - val_loss: 253.3099
Epoch 32/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 254.6851 - val_loss: 253.0328
Epoch 33/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 254.5189 - val_loss: 251.0810
Epoch 34/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 254.3169 - val_loss: 253.0562
Epoch 35/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 254.0478 - val_loss: 250.7241
Epoch 36/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 253.9514 - val_loss: 250.8177
Epoch 37/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 253.7044 - val_loss: 251.4908
Epoch 38/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 253.6227 - val_loss: 251.3669
Epoch 39/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 253.3909 - val_loss: 250.6412
Epoch 40/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 253.1954 - val_loss: 250.4258
Epoch 41/55
9445953/9445953 [==============================] - 36s 4us/step - loss: 253.1773 - val_loss: 255.8775
Epoch 42/55
9445953/9445953 [==============================] - 36s 4us/step - loss: 252.9792 - val_loss: 251.8682
Epoch 43/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 252.8356 - val_loss: 253.3959
Epoch 44/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 252.6879 - val_loss: 250.3468
Epoch 45/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 252.6267 - val_loss: 251.5993
Epoch 46/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 252.4765 - val_loss: 250.7662
Epoch 47/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 252.3501 - val_loss: 249.8270
Epoch 48/55                                                                                                                                                                                                        9445953/9445953 [==============================] - 38s 4us/step - loss: 252.2528 - val_loss: 249.0689
Epoch 49/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 252.1525 - val_loss: 251.5324
Epoch 50/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 252.0707 - val_loss: 249.7317
Epoch 51/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 251.7802 - val_loss: 248.2292
Epoch 52/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 251.8021 - val_loss: 249.4761
Epoch 53/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 251.7128 - val_loss: 248.3765
Epoch 54/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 251.5763 - val_loss: 248.6326
Epoch 55/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 251.5068 - val_loss: 248.3190

         CHILD ACCURACY = 245.7525714399829


         PARENT ACCURACY = 215.19562747550978



 QUEUE SIZE BEFORE GET = 5


 NODE SELECTED <<<------ Epochs = 45 -------- BatchSize = 9000--------- Accuracy = 208.79254974375507 -------->>>


 CHILD 1 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7500

         EPOCHS = 45
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-07-18 02:29:00.588865: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 02:29:00.597888: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 38s 4us/step - loss: 321.5009 - val_loss: 303.8518
Epoch 2/45
9445953/9445953 [==============================] - 38s 4us/step - loss: 292.6651 - val_loss: 277.8337
Epoch 3/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 279.2669 - val_loss: 274.2543
Epoch 4/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 276.1175 - val_loss: 272.1615
Epoch 5/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 274.5442 - val_loss: 272.4739
Epoch 6/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 273.5059 - val_loss: 271.8558
Epoch 7/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 272.6268 - val_loss: 270.3985
Epoch 8/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 271.1538 - val_loss: 269.9931
Epoch 9/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 266.2534 - val_loss: 259.6183
Epoch 10/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 260.3221 - val_loss: 254.1928
Epoch 11/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 255.8159 - val_loss: 266.9448
Epoch 12/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 252.4722 - val_loss: 247.4831
Epoch 13/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 249.7002 - val_loss: 243.8445
Epoch 14/45
9445953/9445953 [==============================] - 39s 4us/step - loss: 247.3698 - val_loss: 244.4994
Epoch 15/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 245.2777 - val_loss: 246.4244
Epoch 16/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 243.2248 - val_loss: 238.6355
Epoch 17/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 241.4620 - val_loss: 244.8399
Epoch 18/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 239.9542 - val_loss: 241.1872
Epoch 19/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 238.5467 - val_loss: 229.7713
Epoch 20/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 237.3442 - val_loss: 236.1769
Epoch 21/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 236.2473 - val_loss: 229.3444
Epoch 22/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 235.2352 - val_loss: 231.3468
Epoch 23/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 234.3162 - val_loss: 231.3655
Epoch 24/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 233.5174 - val_loss: 228.4935
Epoch 25/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 232.6827 - val_loss: 225.6734
Epoch 26/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 231.9423 - val_loss: 223.4027
Epoch 27/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 231.4902 - val_loss: 225.1124
Epoch 28/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 230.6045 - val_loss: 222.3174
Epoch 29/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 230.2316 - val_loss: 222.3423
Epoch 30/45
9445953/9445953 [==============================] - 38s 4us/step - loss: 229.6366 - val_loss: 226.5770
Epoch 31/45
9445953/9445953 [==============================] - 38s 4us/step - loss: 229.1465 - val_loss: 221.3761
Epoch 32/45
9445953/9445953 [==============================] - 38s 4us/step - loss: 228.6361 - val_loss: 235.4318
Epoch 33/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 227.9725 - val_loss: 219.1517
Epoch 34/45
9445953/9445953 [==============================] - 38s 4us/step - loss: 227.5565 - val_loss: 225.4741
Epoch 35/45
9445953/9445953 [==============================] - 43s 5us/step - loss: 227.2727 - val_loss: 220.7085
Epoch 36/45
9445953/9445953 [==============================] - 41s 4us/step - loss: 226.6694 - val_loss: 227.1931
Epoch 37/45
9445953/9445953 [==============================] - 41s 4us/step - loss: 226.3704 - val_loss: 219.3556
Epoch 38/45
9445953/9445953 [==============================] - 41s 4us/step - loss: 225.9026 - val_loss: 221.0758
Epoch 39/45
9445953/9445953 [==============================] - 40s 4us/step - loss: 225.4547 - val_loss: 214.8120
Epoch 40/45
9445953/9445953 [==============================] - 41s 4us/step - loss: 225.0929 - val_loss: 218.2873
Epoch 41/45                                                                                                                                                                                                        9445953/9445953 [==============================] - 43s 5us/step - loss: 224.8856 - val_loss: 227.5269
Epoch 42/45
9445953/9445953 [==============================] - 38s 4us/step - loss: 224.5261 - val_loss: 215.7184
Epoch 43/45
9445953/9445953 [==============================] - 40s 4us/step - loss: 224.0874 - val_loss: 231.2098
Epoch 44/45
9445953/9445953 [==============================] - 38s 4us/step - loss: 223.9288 - val_loss: 220.0746
Epoch 45/45
9445953/9445953 [==============================] - 39s 4us/step - loss: 223.4294 - val_loss: 216.8614

         CHILD ACCURACY = 217.93912671737897


         PARENT ACCURACY = 208.79254974375507


 CHILD 2 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7500

         EPOCHS = 40
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/40
2018-07-18 02:57:30.718269: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 02:57:30.723257: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 39s 4us/step - loss: 327.9627 - val_loss: 335.6223
Epoch 2/40
9445953/9445953 [==============================] - 38s 4us/step - loss: 293.5954 - val_loss: 280.4080
Epoch 3/40
9445953/9445953 [==============================] - 42s 4us/step - loss: 281.8969 - val_loss: 276.9187
Epoch 4/40
9445953/9445953 [==============================] - 39s 4us/step - loss: 278.7894 - val_loss: 276.1317
Epoch 5/40
9445953/9445953 [==============================] - 41s 4us/step - loss: 275.7686 - val_loss: 275.5045
Epoch 6/40
9445953/9445953 [==============================] - 40s 4us/step - loss: 271.3826 - val_loss: 266.9592
Epoch 7/40
9445953/9445953 [==============================] - 39s 4us/step - loss: 268.0728 - val_loss: 263.5044
Epoch 8/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 265.8709 - val_loss: 262.2194
Epoch 9/40
9445953/9445953 [==============================] - 39s 4us/step - loss: 264.2533 - val_loss: 261.6763
Epoch 10/40
9445953/9445953 [==============================] - 38s 4us/step - loss: 262.7930 - val_loss: 258.4075
Epoch 11/40
9445953/9445953 [==============================] - 40s 4us/step - loss: 261.5509 - val_loss: 257.4165
Epoch 12/40
9445953/9445953 [==============================] - 38s 4us/step - loss: 260.4745 - val_loss: 259.0912
Epoch 13/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 259.6063 - val_loss: 259.8030
Epoch 14/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 258.5627 - val_loss: 256.5446
Epoch 15/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 257.7153 - val_loss: 254.2932
Epoch 16/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 256.7169 - val_loss: 259.9000
Epoch 17/40
9445953/9445953 [==============================] - 38s 4us/step - loss: 255.7145 - val_loss: 260.9122
Epoch 18/40
9445953/9445953 [==============================] - 39s 4us/step - loss: 254.9321 - val_loss: 257.1162
Epoch 19/40
9445953/9445953 [==============================] - 39s 4us/step - loss: 254.1495 - val_loss: 254.3789
Epoch 20/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 253.5104 - val_loss: 252.0694
Epoch 21/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 252.9103 - val_loss: 251.6881
Epoch 22/40
9445953/9445953 [==============================] - 44s 5us/step - loss: 252.4449 - val_loss: 251.0557
Epoch 23/40
9445953/9445953 [==============================] - 40s 4us/step - loss: 251.9641 - val_loss: 249.5874
Epoch 24/40
9445953/9445953 [==============================] - 45s 5us/step - loss: 251.6913 - val_loss: 248.3692
Epoch 25/40
9445953/9445953 [==============================] - 43s 5us/step - loss: 251.1625 - val_loss: 248.7909
Epoch 26/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 250.9011 - val_loss: 251.4600
Epoch 27/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 250.5535 - val_loss: 247.6566
Epoch 28/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 250.1854 - val_loss: 248.9929
Epoch 29/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 249.9489 - val_loss: 246.6958
Epoch 30/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 249.6343 - val_loss: 251.8514
Epoch 31/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 249.4080 - val_loss: 246.6322
Epoch 32/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 249.1874 - val_loss: 250.5916
Epoch 33/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 248.9301 - val_loss: 249.0741
Epoch 34/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 248.7793 - val_loss: 250.4476
Epoch 35/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 248.5682 - val_loss: 250.1542                                                                                                              Epoch 36/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 248.4304 - val_loss: 249.7412
Epoch 37/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 248.2598 - val_loss: 246.7692
Epoch 38/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 248.0779 - val_loss: 244.1992
Epoch 39/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 247.8558 - val_loss: 246.1380
Epoch 40/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 247.6807 - val_loss: 245.9663

         CHILD ACCURACY = 243.56781443245706


         PARENT ACCURACY = 208.79254974375507


 CHILD 3 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 9000

         EPOCHS = 40
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/40
2018-07-18 03:23:02.447096: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 03:23:02.452818: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 36s 4us/step - loss: 319.5830 - val_loss: 289.3853
Epoch 2/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 287.9627 - val_loss: 284.8050
Epoch 3/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 280.6785 - val_loss: 274.8023
Epoch 4/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 277.4111 - val_loss: 274.6220
Epoch 5/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 275.4756 - val_loss: 290.2992
Epoch 6/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 273.6491 - val_loss: 273.3377
Epoch 7/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 270.1214 - val_loss: 274.6967
Epoch 8/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 264.4315 - val_loss: 257.8417
Epoch 9/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 259.1819 - val_loss: 254.4232
Epoch 10/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 255.1532 - val_loss: 254.7740
Epoch 11/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 251.9625 - val_loss: 245.7093
Epoch 12/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 249.4046 - val_loss: 246.6075
Epoch 13/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 247.2022 - val_loss: 241.7190
Epoch 14/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 245.3405 - val_loss: 243.3531
Epoch 15/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 243.2515 - val_loss: 240.8577
Epoch 16/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 241.2895 - val_loss: 236.5390
Epoch 17/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 239.3634 - val_loss: 234.6739
Epoch 18/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 237.7299 - val_loss: 239.9633
Epoch 19/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 235.9842 - val_loss: 228.4017
Epoch 20/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 234.7247 - val_loss: 227.5874
Epoch 21/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 233.4439 - val_loss: 227.4314
Epoch 22/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 232.2803 - val_loss: 226.0993
Epoch 23/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 231.3176 - val_loss: 225.8242
Epoch 24/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.2135 - val_loss: 223.2710
Epoch 25/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 229.5486 - val_loss: 221.0744
Epoch 26/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.7145 - val_loss: 224.1475
Epoch 27/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.1660 - val_loss: 219.8206
Epoch 28/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.4232 - val_loss: 222.2139
Epoch 29/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.7333 - val_loss: 219.8113
Epoch 30/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.1944 - val_loss: 218.6978
Epoch 31/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.5891 - val_loss: 220.9242
Epoch 32/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.1365 - val_loss: 219.8547
Epoch 33/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.6803 - val_loss: 217.9769
Epoch 34/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.3084 - val_loss: 224.2218
Epoch 35/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 223.6155 - val_loss: 218.1906
Epoch 36/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 223.3456 - val_loss: 218.0306
Epoch 37/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 223.1660 - val_loss: 215.3920
Epoch 38/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 222.6531 - val_loss: 218.5516
Epoch 39/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 222.3787 - val_loss: 215.0391
Epoch 40/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 221.8794 - val_loss: 223.7021                   
         CHILD ACCURACY = 213.82317416089455


         PARENT ACCURACY = 208.79254974375507


 CHILD 4 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 9000

         EPOCHS = 50
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/50
2018-07-18 03:46:24.803025: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 03:46:24.808191: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 35s 4us/step - loss: 317.2584 - val_loss: 296.0379
Epoch 2/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 287.9659 - val_loss: 279.7807
Epoch 3/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 280.5752 - val_loss: 276.1786
Epoch 4/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 277.5644 - val_loss: 276.9821
Epoch 5/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 275.9473 - val_loss: 273.1380
Epoch 6/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 274.7295 - val_loss: 271.6149
Epoch 7/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 273.7868 - val_loss: 271.1574
Epoch 8/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 273.1407 - val_loss: 271.5931
Epoch 9/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 272.6152 - val_loss: 270.1972
Epoch 10/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 272.1718 - val_loss: 271.4636
Epoch 11/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 271.6989 - val_loss: 269.5256
Epoch 12/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 271.2808 - val_loss: 269.9931
Epoch 13/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 270.8734 - val_loss: 268.2519
Epoch 14/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 268.5878 - val_loss: 261.6194
Epoch 15/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 261.2012 - val_loss: 252.5840
Epoch 16/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 255.9910 - val_loss: 250.4977
Epoch 17/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 252.6359 - val_loss: 248.8437
Epoch 18/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 249.8190 - val_loss: 244.2885
Epoch 19/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 247.6451 - val_loss: 244.1969
Epoch 20/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 245.5240 - val_loss: 248.0299
Epoch 21/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 244.1225 - val_loss: 237.7031
Epoch 22/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 242.4365 - val_loss: 249.4130
Epoch 23/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 241.3695 - val_loss: 232.6340
Epoch 24/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 240.2009 - val_loss: 240.5798
Epoch 25/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 239.0258 - val_loss: 234.1212
Epoch 26/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 238.1380 - val_loss: 234.1716
Epoch 27/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 237.2041 - val_loss: 231.9174
Epoch 28/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 236.7297 - val_loss: 233.5010
Epoch 29/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 235.8598 - val_loss: 230.8636
Epoch 30/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 235.2794 - val_loss: 229.6364
Epoch 31/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 234.8420 - val_loss: 229.8204
Epoch 32/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 234.1756 - val_loss: 226.8273
Epoch 33/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 233.7365 - val_loss: 242.8081
Epoch 34/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 233.1955 - val_loss: 224.7783
Epoch 35/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 232.6628 - val_loss: 234.4769
Epoch 36/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 232.2538 - val_loss: 225.8104
Epoch 37/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 231.7542 - val_loss: 224.5120
Epoch 38/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 231.5501 - val_loss: 226.9931
Epoch 39/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.9647 - val_loss: 224.4812
Epoch 40/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.6524 - val_loss: 222.3579
Epoch 41/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.3567 - val_loss: 221.9826
Epoch 42/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 229.9730 - val_loss: 223.7567
Epoch 43/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 229.6737 - val_loss: 220.4705
Epoch 44/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 229.4428 - val_loss: 227.6975
Epoch 45/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 229.0791 - val_loss: 223.1540
Epoch 46/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.7399 - val_loss: 238.8310
Epoch 47/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.4366 - val_loss: 228.7364                                                                                                              Epoch 48/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.2475 - val_loss: 231.7790
Epoch 49/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.7600 - val_loss: 226.2975
Epoch 50/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.6234 - val_loss: 225.5287

         CHILD ACCURACY = 228.15394538550947


         PARENT ACCURACY = 208.79254974375507


 CHILD 5 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 10500

         EPOCHS = 40
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/40
2018-07-18 04:15:27.204429: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 04:15:27.209257: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 312.4256 - val_loss: 292.8662
Epoch 2/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 285.4224 - val_loss: 276.9899
Epoch 3/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 276.8069 - val_loss: 269.9238
Epoch 4/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 272.1931 - val_loss: 266.3416
Epoch 5/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 267.9006 - val_loss: 269.5403
Epoch 6/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 263.6305 - val_loss: 256.7876
Epoch 7/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 260.2104 - val_loss: 255.2767
Epoch 8/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 257.1477 - val_loss: 251.9458
Epoch 9/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 254.7870 - val_loss: 252.9208
Epoch 10/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 252.5308 - val_loss: 247.5738
Epoch 11/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 250.6041 - val_loss: 247.1729
Epoch 12/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 248.5168 - val_loss: 242.5630
Epoch 13/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 246.8053 - val_loss: 243.3148
Epoch 14/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 245.1998 - val_loss: 241.9993
Epoch 15/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 243.5731 - val_loss: 240.9806
Epoch 16/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 242.4834 - val_loss: 236.8302
Epoch 17/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 241.1282 - val_loss: 241.6534
Epoch 18/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 239.9411 - val_loss: 236.5782
Epoch 19/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 238.9874 - val_loss: 232.8700
Epoch 20/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 238.0563 - val_loss: 231.8475
Epoch 21/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 237.0848 - val_loss: 231.6224
Epoch 22/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 236.3586 - val_loss: 230.9009
Epoch 23/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 235.6292 - val_loss: 230.3072
Epoch 24/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 234.9280 - val_loss: 241.2467
Epoch 25/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 234.3313 - val_loss: 229.4206
Epoch 26/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 233.6825 - val_loss: 229.1747
Epoch 27/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 233.1049 - val_loss: 225.5043
Epoch 28/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 232.4970 - val_loss: 229.6597
Epoch 29/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 232.2519 - val_loss: 232.1390
Epoch 30/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 231.6507 - val_loss: 227.9642
Epoch 31/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 231.1843 - val_loss: 225.0960
Epoch 32/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 230.6036 - val_loss: 224.4403
Epoch 33/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 230.4811 - val_loss: 222.3421
Epoch 34/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 229.9396 - val_loss: 222.4105
Epoch 35/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 229.6341 - val_loss: 222.9312
Epoch 36/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 229.3984 - val_loss: 223.4482
Epoch 37/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 229.0736 - val_loss: 224.5289
Epoch 38/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 228.5459 - val_loss: 231.7409
Epoch 39/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 228.3106 - val_loss: 221.4198
Epoch 40/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 228.1312 - val_loss: 222.7637

         CHILD ACCURACY = 221.71134976193366


         PARENT ACCURACY = 208.79254974375507



 QUEUE SIZE BEFORE GET = 4                                                                                              

 NODE SELECTED <<<------ Epochs = 55 -------- BatchSize = 9000--------- Accuracy = 209.31806106245202 -------->>>


 CHILD 1 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 10500

         EPOCHS = 55
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/55
2018-07-18 04:37:53.173050: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 04:37:53.177236: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 325.1619 - val_loss: 314.2146
Epoch 2/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 295.5029 - val_loss: 301.6184
Epoch 3/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 283.9563 - val_loss: 277.0355
Epoch 4/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 279.6754 - val_loss: 282.8310
Epoch 5/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 277.2540 - val_loss: 273.1965
Epoch 6/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 275.7661 - val_loss: 272.9154
Epoch 7/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 274.6065 - val_loss: 272.0469
Epoch 8/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 273.7931 - val_loss: 270.9666
Epoch 9/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 273.1134 - val_loss: 272.4386
Epoch 10/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 272.5363 - val_loss: 270.6365
Epoch 11/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 272.0428 - val_loss: 269.9771
Epoch 12/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 271.6320 - val_loss: 271.1425
Epoch 13/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 271.2798 - val_loss: 269.0505
Epoch 14/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 270.8711 - val_loss: 270.5944
Epoch 15/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 270.5287 - val_loss: 270.0028
Epoch 16/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 270.0315 - val_loss: 268.7117
Epoch 17/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 269.3236 - val_loss: 266.5110
Epoch 18/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 266.4525 - val_loss: 265.2496
Epoch 19/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 259.2856 - val_loss: 253.0557
Epoch 20/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 253.8109 - val_loss: 248.4358
Epoch 21/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 249.8701 - val_loss: 242.7290
Epoch 22/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 246.7489 - val_loss: 237.6688
Epoch 23/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 244.1038 - val_loss: 237.1706
Epoch 24/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 242.0255 - val_loss: 236.6246
Epoch 25/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 239.8609 - val_loss: 233.3854
Epoch 26/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 238.2934 - val_loss: 238.0020
Epoch 27/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 236.8473 - val_loss: 229.0820
Epoch 28/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 235.3370 - val_loss: 227.1269
Epoch 29/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 234.2237 - val_loss: 228.9019
Epoch 30/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 233.1536 - val_loss: 225.3546
Epoch 31/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 232.2157 - val_loss: 227.8277
Epoch 32/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 231.2505 - val_loss: 230.0169
Epoch 33/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 230.5170 - val_loss: 230.5612
Epoch 34/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 229.5908 - val_loss: 223.0529
Epoch 35/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 228.7615 - val_loss: 222.6264
Epoch 36/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 228.1438 - val_loss: 224.9205
Epoch 37/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 227.4070 - val_loss: 220.4772
Epoch 38/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 226.8232 - val_loss: 222.2852
Epoch 39/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 226.4728 - val_loss: 228.1354
Epoch 40/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 225.5998 - val_loss: 226.3845
Epoch 41/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 225.3709 - val_loss: 222.4302
Epoch 42/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 224.8398 - val_loss: 218.5242
Epoch 43/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 224.3240 - val_loss: 217.5802
Epoch 44/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 223.8403 - val_loss: 226.3472
Epoch 45/55                                                                                                                                                                                                        9445953/9445953 [==============================] - 33s 4us/step - loss: 223.5986 - val_loss: 221.4293
Epoch 46/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 223.0339 - val_loss: 225.4889
Epoch 47/55
9445953/9445953 [==============================] - 34s 4us/step - loss: 222.5331 - val_loss: 216.1787
Epoch 48/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 222.4426 - val_loss: 212.9536
Epoch 49/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 222.0083 - val_loss: 225.7562
Epoch 50/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 221.5600 - val_loss: 219.5252
Epoch 51/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 221.2340 - val_loss: 216.4550
Epoch 52/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 221.0106 - val_loss: 212.7399
Epoch 53/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 220.7182 - val_loss: 219.1194
Epoch 54/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 220.1159 - val_loss: 214.6560
Epoch 55/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 219.9306 - val_loss: 230.8430

         CHILD ACCURACY = 218.23538663171811


         PARENT ACCURACY = 209.31806106245202


 CHILD 2 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 10500

         EPOCHS = 60
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/60
2018-07-18 05:08:34.908330: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 05:08:34.914230: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 321.2935 - val_loss: 310.0860
Epoch 2/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 291.8853 - val_loss: 284.4078
Epoch 3/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 285.2706 - val_loss: 280.4107
Epoch 4/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 281.9692 - val_loss: 278.8474
Epoch 5/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 279.9691 - val_loss: 277.6225
Epoch 6/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 278.6389 - val_loss: 276.7495
Epoch 7/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 277.6288 - val_loss: 275.3570
Epoch 8/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 276.5966 - val_loss: 273.7855
Epoch 9/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 275.3413 - val_loss: 273.1321
Epoch 10/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 274.0990 - val_loss: 271.7903
Epoch 11/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 272.7209 - val_loss: 276.7706
Epoch 12/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 269.7903 - val_loss: 265.5221
Epoch 13/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 266.0360 - val_loss: 261.6243
Epoch 14/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 262.7207 - val_loss: 259.4489
Epoch 15/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 260.0036 - val_loss: 254.5329
Epoch 16/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 257.4574 - val_loss: 256.4264
Epoch 17/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 255.0553 - val_loss: 252.0202
Epoch 18/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 253.0186 - val_loss: 249.9853
Epoch 19/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 250.9819 - val_loss: 246.2645
Epoch 20/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 249.2435 - val_loss: 250.2115
Epoch 21/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 247.6000 - val_loss: 241.9674
Epoch 22/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 245.9793 - val_loss: 239.8613
Epoch 23/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 244.5407 - val_loss: 243.3003
Epoch 24/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 243.4168 - val_loss: 238.6016
Epoch 25/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 242.2160 - val_loss: 236.4262
Epoch 26/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 241.1155 - val_loss: 236.2604
Epoch 27/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 240.3295 - val_loss: 234.8675
Epoch 28/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 239.1291 - val_loss: 236.1627
Epoch 29/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 238.6369 - val_loss: 237.8409
Epoch 30/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 237.8591 - val_loss: 230.3290
Epoch 31/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 237.0560 - val_loss: 228.4692
Epoch 32/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 236.4482 - val_loss: 229.3991
Epoch 33/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 236.0681 - val_loss: 231.9392
Epoch 34/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 235.3341 - val_loss: 233.4101
Epoch 35/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 234.8563 - val_loss: 229.1246
Epoch 36/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 234.4312 - val_loss: 226.5525
Epoch 37/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 233.8779 - val_loss: 231.1757
Epoch 38/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 233.6462 - val_loss: 233.5568
Epoch 39/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 233.2425 - val_loss: 234.0676
Epoch 40/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 232.9896 - val_loss: 229.9112
Epoch 41/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 232.4467 - val_loss: 229.0250                                                                                                              Epoch 42/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 232.1522 - val_loss: 226.0311
Epoch 43/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 231.7082 - val_loss: 223.9319
Epoch 44/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 231.5365 - val_loss: 224.6194
Epoch 45/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 231.2737 - val_loss: 226.9004
Epoch 46/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 230.7716 - val_loss: 226.7834
Epoch 47/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 230.5212 - val_loss: 223.5702
Epoch 48/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 230.2014 - val_loss: 223.0547
Epoch 49/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 229.9322 - val_loss: 224.7801
Epoch 50/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 229.7382 - val_loss: 225.2431
Epoch 51/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 229.4253 - val_loss: 223.4733
Epoch 52/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 229.1435 - val_loss: 226.3420
Epoch 53/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 229.0562 - val_loss: 221.6338
Epoch 54/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 228.7062 - val_loss: 223.2126
Epoch 55/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 228.5431 - val_loss: 221.3963
Epoch 56/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 228.3628 - val_loss: 234.6866
Epoch 57/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 228.1861 - val_loss: 219.5155
Epoch 58/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.8602 - val_loss: 221.4860
Epoch 59/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.6570 - val_loss: 224.4981
Epoch 60/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.4792 - val_loss: 228.0384

         CHILD ACCURACY = 218.97336359167895


         PARENT ACCURACY = 209.31806106245202


 CHILD 3 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7500

         EPOCHS = 60
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/60
2018-07-18 05:42:10.634595: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 05:42:10.639479: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 37s 4us/step - loss: 317.3332 - val_loss: 292.3483
Epoch 2/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 287.0834 - val_loss: 276.2361
Epoch 3/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 277.8996 - val_loss: 273.3025
Epoch 4/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 274.4488 - val_loss: 268.7222
Epoch 5/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 269.8998 - val_loss: 268.7474
Epoch 6/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 264.3270 - val_loss: 257.4404
Epoch 7/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 260.0584 - val_loss: 254.3232
Epoch 8/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 256.6767 - val_loss: 250.8485
Epoch 9/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 253.7940 - val_loss: 252.0670
Epoch 10/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 251.4955 - val_loss: 247.2569
Epoch 11/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 249.4827 - val_loss: 246.2850
Epoch 12/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 247.6635 - val_loss: 243.3496
Epoch 13/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 245.9570 - val_loss: 244.1513
Epoch 14/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 244.1883 - val_loss: 242.7223
Epoch 15/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 242.7733 - val_loss: 242.1440
Epoch 16/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 241.5225 - val_loss: 240.0400
Epoch 17/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 240.2046 - val_loss: 239.4859
Epoch 18/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 238.9216 - val_loss: 239.9763
Epoch 19/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 237.8140 - val_loss: 235.3459
Epoch 20/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 236.8061 - val_loss: 233.0909
Epoch 21/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 235.9101 - val_loss: 249.0327
Epoch 22/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 234.8794 - val_loss: 237.3351
Epoch 23/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 234.1716 - val_loss: 245.9961
Epoch 24/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 233.5259 - val_loss: 228.6222
Epoch 25/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 232.7208 - val_loss: 223.6992
Epoch 26/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 232.2258 - val_loss: 230.2504
Epoch 27/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 231.5394 - val_loss: 223.5128
Epoch 28/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 231.2095 - val_loss: 231.5595
Epoch 29/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 230.4917 - val_loss: 228.2050
Epoch 30/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 230.1559 - val_loss: 232.1783
Epoch 31/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 229.5612 - val_loss: 229.0983
Epoch 32/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 229.0648 - val_loss: 220.7900
Epoch 33/60                                                                                                                                                                                                        9445953/9445953 [==============================] - 36s 4us/step - loss: 228.8472 - val_loss: 221.7680
Epoch 34/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 228.3631 - val_loss: 226.8002
Epoch 35/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 228.0286 - val_loss: 238.1494
Epoch 36/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 227.6359 - val_loss: 221.3269
Epoch 37/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 227.2443 - val_loss: 222.3600
Epoch 38/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 227.0723 - val_loss: 221.9103
Epoch 39/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 226.6795 - val_loss: 231.5686
Epoch 40/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 226.2794 - val_loss: 218.5585
Epoch 41/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 225.9917 - val_loss: 223.3913
Epoch 42/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 225.6884 - val_loss: 225.7503
Epoch 43/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 225.4794 - val_loss: 218.8752
Epoch 44/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 225.0765 - val_loss: 229.8435
Epoch 45/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 224.9427 - val_loss: 218.5559
Epoch 46/60
9445953/9445953 [==============================] - 37s 4us/step - loss: 224.7357 - val_loss: 219.2101
Epoch 47/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 224.3476 - val_loss: 224.0243
Epoch 48/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 224.0889 - val_loss: 224.1747
Epoch 49/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 223.8465 - val_loss: 220.2698
Epoch 50/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 223.5128 - val_loss: 223.0561
Epoch 51/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 223.4432 - val_loss: 222.3233
Epoch 52/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 223.1873 - val_loss: 229.1244
Epoch 53/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 223.1701 - val_loss: 224.8931
Epoch 54/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 222.8703 - val_loss: 225.4886
Epoch 55/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 222.5951 - val_loss: 213.0198
Epoch 56/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 222.4777 - val_loss: 218.8183
Epoch 57/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 222.4249 - val_loss: 223.3633
Epoch 58/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 221.9046 - val_loss: 225.1810
Epoch 59/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 222.1956 - val_loss: 219.5377
Epoch 60/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 221.8633 - val_loss: 217.0727

         CHILD ACCURACY = 220.48023008754507


         PARENT ACCURACY = 209.31806106245202


 CHILD 4 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 9000

         EPOCHS = 60
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/60
2018-07-18 06:18:29.278438: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 06:18:29.284025: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 35s 4us/step - loss: 318.0828 - val_loss: 305.7675
Epoch 2/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 288.2642 - val_loss: 281.2664
Epoch 3/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 282.1001 - val_loss: 278.1460
Epoch 4/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 279.0292 - val_loss: 277.4683
Epoch 5/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 277.7051 - val_loss: 275.1149
Epoch 6/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 276.6138 - val_loss: 275.2222
Epoch 7/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 274.8860 - val_loss: 276.6376
Epoch 8/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 272.2339 - val_loss: 270.2956
Epoch 9/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 269.6932 - val_loss: 268.7068
Epoch 10/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 267.1277 - val_loss: 266.7572
Epoch 11/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 264.9183 - val_loss: 260.7813
Epoch 12/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 262.8664 - val_loss: 257.8657
Epoch 13/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 260.9302 - val_loss: 259.2599
Epoch 14/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 259.3180 - val_loss: 257.1898
Epoch 15/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 258.0223 - val_loss: 252.8877
Epoch 16/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 256.7775 - val_loss: 254.2316
Epoch 17/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 255.9526 - val_loss: 254.3388
Epoch 18/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 254.1712 - val_loss: 249.6717
Epoch 19/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 251.8644 - val_loss: 245.7096
Epoch 20/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 248.4011 - val_loss: 242.6355                                                                                                              Epoch 21/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 245.5123 - val_loss: 244.2888
Epoch 22/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 243.0019 - val_loss: 237.6993
Epoch 23/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 240.9255 - val_loss: 240.4536
Epoch 24/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 239.3138 - val_loss: 234.6559
Epoch 25/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 238.0736 - val_loss: 233.5089
Epoch 26/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 236.8900 - val_loss: 234.7387
Epoch 27/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 235.7056 - val_loss: 228.2499
Epoch 28/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 234.6948 - val_loss: 230.5297
Epoch 29/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 233.6198 - val_loss: 224.5258
Epoch 30/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 232.9149 - val_loss: 224.0813
Epoch 31/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 232.2933 - val_loss: 226.2255
Epoch 32/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 231.5102 - val_loss: 224.3966
Epoch 33/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.8797 - val_loss: 247.3694
Epoch 34/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.1308 - val_loss: 220.2920
Epoch 35/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 229.6847 - val_loss: 229.0365
Epoch 36/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 229.0153 - val_loss: 218.2327
Epoch 37/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.5969 - val_loss: 227.5542
Epoch 38/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.0295 - val_loss: 216.5695
Epoch 39/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.5036 - val_loss: 222.8022
Epoch 40/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.1560 - val_loss: 225.8469
Epoch 41/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.6768 - val_loss: 225.1659
Epoch 42/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.3493 - val_loss: 223.7100
Epoch 43/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.9054 - val_loss: 217.8042
Epoch 44/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.6169 - val_loss: 235.7579
Epoch 45/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.3209 - val_loss: 220.5526
Epoch 46/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.1059 - val_loss: 222.4682
Epoch 47/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.6125 - val_loss: 231.0049
Epoch 48/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.1737 - val_loss: 217.4404
Epoch 49/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 223.9760 - val_loss: 215.9222
Epoch 50/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 223.6122 - val_loss: 222.2017
Epoch 51/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 223.3641 - val_loss: 246.5581
Epoch 52/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 222.9846 - val_loss: 220.6412
Epoch 53/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 222.6851 - val_loss: 216.2758
Epoch 54/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 222.4747 - val_loss: 225.5492
Epoch 55/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 222.4516 - val_loss: 224.8549
Epoch 56/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 221.9907 - val_loss: 222.1794
Epoch 57/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 221.7853 - val_loss: 214.0074
Epoch 58/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 221.5432 - val_loss: 213.2982
Epoch 59/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 221.3893 - val_loss: 214.6303
Epoch 60/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 221.2366 - val_loss: 213.2181

         CHILD ACCURACY = 206.08845193106362


         PARENT ACCURACY = 209.31806106245202


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 4 <<<<<<<<<<<<<<<<<<<<<<<<<<<


                         ********** BEST MODEL SAVED | EPOCHS = 60 | BATCH_SIZE = 9000 | ACCURACY = 206.08845193106362 ********





 QUEUE SIZE BEFORE GET = 4


 NODE SELECTED <<<------ Epochs = 60 -------- BatchSize = 9000--------- Accuracy = 206.08845193106362 -------->>>


 CHILD 1 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 10500

         EPOCHS = 60
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/60
2018-07-18 06:53:22.190616: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 06:53:22.195591: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 320.9544 - val_loss: 301.0331
Epoch 2/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 292.7491 - val_loss: 280.4015
Epoch 3/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 280.9929 - val_loss: 276.2451
Epoch 4/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 277.0113 - val_loss: 279.2259
Epoch 5/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 275.2941 - val_loss: 271.2077
Epoch 6/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 273.9860 - val_loss: 272.2860
Epoch 7/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 272.7230 - val_loss: 269.9970
Epoch 8/60                                                                                                                                                                                                         9445953/9445953 [==============================] - 34s 4us/step - loss: 270.0308 - val_loss: 264.4563
Epoch 9/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 265.5446 - val_loss: 259.6387
Epoch 10/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 261.2249 - val_loss: 253.7396
Epoch 11/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 258.0699 - val_loss: 252.9946
Epoch 12/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 255.4379 - val_loss: 248.2502
Epoch 13/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 253.1126 - val_loss: 250.4655
Epoch 14/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 250.9450 - val_loss: 246.5209
Epoch 15/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 249.0832 - val_loss: 244.7738
Epoch 16/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 247.5979 - val_loss: 240.9384
Epoch 17/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 245.9137 - val_loss: 239.0661
Epoch 18/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 244.5815 - val_loss: 237.5097
Epoch 19/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 243.1217 - val_loss: 235.6232
Epoch 20/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 241.9683 - val_loss: 232.3132
Epoch 21/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 240.7374 - val_loss: 234.2148
Epoch 22/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 239.7364 - val_loss: 246.1286
Epoch 23/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 238.6895 - val_loss: 235.1670
Epoch 24/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 237.5726 - val_loss: 233.4658
Epoch 25/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 236.5758 - val_loss: 227.4390
Epoch 26/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 235.7225 - val_loss: 230.6878
Epoch 27/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 234.8644 - val_loss: 228.4800
Epoch 28/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 234.1324 - val_loss: 224.3226
Epoch 29/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 233.3065 - val_loss: 244.0025
Epoch 30/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 232.6977 - val_loss: 233.2407
Epoch 31/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 232.1128 - val_loss: 228.8581
Epoch 32/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 231.4649 - val_loss: 222.1845
Epoch 33/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 231.0827 - val_loss: 226.6879
Epoch 34/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 230.4178 - val_loss: 221.0235
Epoch 35/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 229.8119 - val_loss: 223.2443
Epoch 36/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 229.5040 - val_loss: 241.0379
Epoch 37/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 228.9713 - val_loss: 223.5415
Epoch 38/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 228.6012 - val_loss: 218.8161
Epoch 39/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 228.0541 - val_loss: 221.2104
Epoch 40/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.6587 - val_loss: 220.6825
Epoch 41/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.3025 - val_loss: 228.1310
Epoch 42/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.9914 - val_loss: 221.5319
Epoch 43/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.4736 - val_loss: 220.2765
Epoch 44/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.3165 - val_loss: 222.9537
Epoch 45/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 225.7862 - val_loss: 219.2581
Epoch 46/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 225.3383 - val_loss: 221.5770
Epoch 47/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.9439 - val_loss: 223.5563
Epoch 48/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.8303 - val_loss: 223.0884
Epoch 49/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.5784 - val_loss: 225.4215
Epoch 50/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.4391 - val_loss: 216.5006
Epoch 51/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.1446 - val_loss: 216.0984
Epoch 52/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 223.8206 - val_loss: 219.7674
Epoch 53/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 223.5087 - val_loss: 213.4402
Epoch 54/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 223.0892 - val_loss: 213.6102
Epoch 55/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 222.8393 - val_loss: 219.2618                                                                                                              Epoch 56/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 222.7726 - val_loss: 223.7922
Epoch 57/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 222.5297 - val_loss: 218.8734
Epoch 58/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 222.1859 - val_loss: 211.8941
Epoch 59/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 221.8317 - val_loss: 223.6534
Epoch 60/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 221.8333 - val_loss: 217.1883

         CHILD ACCURACY = 213.7094800554197


         PARENT ACCURACY = 206.08845193106362


 CHILD 2 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7500

         EPOCHS = 65
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/65
2018-07-18 07:26:56.974677: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 07:26:56.980323: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 37s 4us/step - loss: 311.7543 - val_loss: 285.4568
Epoch 2/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 285.4414 - val_loss: 297.3872
Epoch 3/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 281.1665 - val_loss: 285.1376
Epoch 4/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 279.4770 - val_loss: 277.1114
Epoch 5/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 278.2523 - val_loss: 275.9518
Epoch 6/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 277.3679 - val_loss: 278.5423
Epoch 7/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 276.4031 - val_loss: 273.4072
Epoch 8/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 273.1923 - val_loss: 267.8531
Epoch 9/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 269.8370 - val_loss: 265.6020
Epoch 10/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 267.5227 - val_loss: 263.5524
Epoch 11/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 265.5805 - val_loss: 264.8428
Epoch 12/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 264.1130 - val_loss: 261.5085
Epoch 13/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 262.9696 - val_loss: 257.9584
Epoch 14/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 262.1218 - val_loss: 261.0074
Epoch 15/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 261.4419 - val_loss: 257.9954
Epoch 16/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 260.8391 - val_loss: 257.3242
Epoch 17/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 260.3483 - val_loss: 258.0558
Epoch 18/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 259.9998 - val_loss: 260.9722
Epoch 19/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 259.5928 - val_loss: 256.9125
Epoch 20/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 259.2263 - val_loss: 255.6530
Epoch 21/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 258.9872 - val_loss: 257.9074
Epoch 22/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 258.6327 - val_loss: 261.3646
Epoch 23/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 258.4319 - val_loss: 255.5600
Epoch 24/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 258.2721 - val_loss: 254.7737
Epoch 25/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 257.9525 - val_loss: 255.7335
Epoch 26/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 257.7890 - val_loss: 254.5962
Epoch 27/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 257.5672 - val_loss: 254.8243
Epoch 28/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 257.3763 - val_loss: 262.5070
Epoch 29/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 257.1758 - val_loss: 255.9426
Epoch 30/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 256.9804 - val_loss: 253.7767
Epoch 31/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 256.8358 - val_loss: 253.9577
Epoch 32/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 256.7629 - val_loss: 254.4850
Epoch 33/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 256.5116 - val_loss: 255.1669
Epoch 34/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 256.3622 - val_loss: 252.6797
Epoch 35/65                                                                                                                                                                                                        9445953/9445953 [==============================] - 36s 4us/step - loss: 256.3191 - val_loss: 256.2165
Epoch 36/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 256.0823 - val_loss: 255.8201
Epoch 37/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 255.9348 - val_loss: 252.8641
Epoch 38/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 255.8325 - val_loss: 255.2059
Epoch 39/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 255.7056 - val_loss: 260.0285
Epoch 40/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 255.6160 - val_loss: 251.9976
Epoch 41/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 255.4919 - val_loss: 255.6205
Epoch 42/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 255.3157 - val_loss: 257.1952
Epoch 43/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 255.3637 - val_loss: 253.4882
Epoch 44/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 255.0827 - val_loss: 259.1254
Epoch 45/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 255.0459 - val_loss: 255.5309
Epoch 46/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 254.8463 - val_loss: 254.1299
Epoch 47/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 254.7822 - val_loss: 252.6053
Epoch 48/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 254.7456 - val_loss: 254.6899
Epoch 49/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 254.5797 - val_loss: 257.3434
Epoch 50/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 254.5403 - val_loss: 252.8863
Epoch 51/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 254.4220 - val_loss: 251.8494
Epoch 52/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 254.3270 - val_loss: 251.8572
Epoch 53/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 254.1993 - val_loss: 250.5735
Epoch 54/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 254.1167 - val_loss: 253.6723
Epoch 55/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 254.1161 - val_loss: 251.4174
Epoch 56/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 253.9603 - val_loss: 250.1300
Epoch 57/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 253.8236 - val_loss: 252.3139
Epoch 58/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 253.6755 - val_loss: 251.7604
Epoch 59/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 253.6805 - val_loss: 254.0800
Epoch 60/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 253.6670 - val_loss: 250.8284
Epoch 61/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 253.5635 - val_loss: 251.0445
Epoch 62/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 253.4657 - val_loss: 251.4733
Epoch 63/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 253.4437 - val_loss: 254.0125
Epoch 64/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 253.2935 - val_loss: 251.0623
Epoch 65/65
9445953/9445953 [==============================] - 36s 4us/step - loss: 253.2453 - val_loss: 250.4057

         CHILD ACCURACY = 250.11485410037307


         PARENT ACCURACY = 206.08845193106362


 CHILD 3 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 10500

         EPOCHS = 65
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/65
2018-07-18 08:06:15.751454: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 08:06:15.757182: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 320.3359 - val_loss: 300.6659
Epoch 2/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 295.1594 - val_loss: 287.2301
Epoch 3/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 285.8229 - val_loss: 290.0335
Epoch 4/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 281.5135 - val_loss: 280.4592
Epoch 5/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 279.0598 - val_loss: 274.2598
Epoch 6/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 275.9672 - val_loss: 272.2821
Epoch 7/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 272.5795 - val_loss: 268.0841
Epoch 8/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 269.9612 - val_loss: 271.0050
Epoch 9/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 268.2025 - val_loss: 264.3504
Epoch 10/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 266.5042 - val_loss: 262.0826
Epoch 11/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 265.3397 - val_loss: 272.0661
Epoch 12/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 264.0422 - val_loss: 261.3499
Epoch 13/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 262.9836 - val_loss: 259.8497                                                                                                              Epoch 14/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 261.9853 - val_loss: 262.0436
Epoch 15/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 261.0316 - val_loss: 258.3176
Epoch 16/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 260.1266 - val_loss: 257.9370
Epoch 17/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 259.3165 - val_loss: 257.7078
Epoch 18/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 258.4503 - val_loss: 255.7617
Epoch 19/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 257.6537 - val_loss: 254.8806
Epoch 20/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 256.8782 - val_loss: 260.0065
Epoch 21/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 256.1743 - val_loss: 254.8678
Epoch 22/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 255.3799 - val_loss: 252.5318
Epoch 23/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 254.6572 - val_loss: 251.8528
Epoch 24/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 254.0878 - val_loss: 253.0621
Epoch 25/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 253.2513 - val_loss: 249.3698
Epoch 26/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 252.6231 - val_loss: 248.1739
Epoch 27/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 251.8461 - val_loss: 252.7328
Epoch 28/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 251.3539 - val_loss: 246.1527
Epoch 29/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 250.7011 - val_loss: 250.6266
Epoch 30/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 249.5588 - val_loss: 243.6187
Epoch 31/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 245.5010 - val_loss: 242.3613
Epoch 32/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 242.6330 - val_loss: 235.5599
Epoch 33/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 240.6262 - val_loss: 239.7289
Epoch 34/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 239.1598 - val_loss: 232.9595
Epoch 35/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 237.9542 - val_loss: 231.1394
Epoch 36/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 236.8532 - val_loss: 229.4240
Epoch 37/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 235.8354 - val_loss: 227.7988
Epoch 38/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 235.0081 - val_loss: 228.4396
Epoch 39/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 234.2358 - val_loss: 229.0368
Epoch 40/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 233.5330 - val_loss: 227.4676
Epoch 41/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 232.9241 - val_loss: 231.4384
Epoch 42/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 232.3261 - val_loss: 240.7085
Epoch 43/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 231.9557 - val_loss: 226.2593
Epoch 44/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 231.2899 - val_loss: 226.0269
Epoch 45/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 230.7019 - val_loss: 228.9959
Epoch 46/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 230.3498 - val_loss: 229.8559
Epoch 47/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 229.9794 - val_loss: 221.0393
Epoch 48/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 229.5373 - val_loss: 221.8278
Epoch 49/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 228.9808 - val_loss: 221.4140
Epoch 50/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 228.8216 - val_loss: 221.9812
Epoch 51/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 228.4114 - val_loss: 222.8670
Epoch 52/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 228.0503 - val_loss: 224.8805
Epoch 53/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.7511 - val_loss: 222.6598
Epoch 54/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.5188 - val_loss: 220.8661
Epoch 55/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.0323 - val_loss: 222.4896
Epoch 56/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.9297 - val_loss: 226.1533
Epoch 57/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.5403 - val_loss: 233.2502
Epoch 58/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.3956 - val_loss: 219.5945
Epoch 59/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.1263 - val_loss: 220.8175
Epoch 60/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 225.9069 - val_loss: 219.0825
Epoch 61/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 225.6526 - val_loss: 235.3294
Epoch 62/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 225.4566 - val_loss: 225.3491
Epoch 63/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 225.1204 - val_loss: 219.4539
Epoch 64/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.8039 - val_loss: 216.1752                                                                                                              Epoch 65/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.7390 - val_loss: 224.3919

         CHILD ACCURACY = 217.655062756179


         PARENT ACCURACY = 206.08845193106362


 CHILD 4 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 9000

         EPOCHS = 65
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/65
2018-07-18 08:42:45.456076: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 08:42:45.460265: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 35s 4us/step - loss: 315.2870 - val_loss: 323.5105
Epoch 2/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 287.6668 - val_loss: 281.7690
Epoch 3/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 279.3517 - val_loss: 274.1803
Epoch 4/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 276.6748 - val_loss: 271.3629
Epoch 5/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 273.9269 - val_loss: 270.4253
Epoch 6/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 270.8350 - val_loss: 266.4577
Epoch 7/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 268.3097 - val_loss: 265.9727
Epoch 8/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 266.3139 - val_loss: 269.3187
Epoch 9/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 264.5756 - val_loss: 264.2655
Epoch 10/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 262.9428 - val_loss: 260.9839
Epoch 11/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 261.5913 - val_loss: 258.3160
Epoch 12/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 260.1936 - val_loss: 256.6266
Epoch 13/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 258.8263 - val_loss: 256.2149
Epoch 14/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 257.7279 - val_loss: 254.0408
Epoch 15/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 256.8002 - val_loss: 259.8289
Epoch 16/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 255.9741 - val_loss: 253.5613
Epoch 17/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 255.1196 - val_loss: 250.3026
Epoch 18/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 254.4065 - val_loss: 253.0523
Epoch 19/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 253.7470 - val_loss: 251.0352
Epoch 20/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 253.2690 - val_loss: 248.6160
Epoch 21/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 252.6769 - val_loss: 250.6726
Epoch 22/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 252.1862 - val_loss: 250.4393
Epoch 23/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 251.7835 - val_loss: 248.6441
Epoch 24/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 251.3369 - val_loss: 247.3806
Epoch 25/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 250.8956 - val_loss: 248.3673
Epoch 26/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 250.3936 - val_loss: 247.6427
Epoch 27/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 249.7817 - val_loss: 246.7414
Epoch 28/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 249.2200 - val_loss: 248.7107
Epoch 29/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 248.6852 - val_loss: 247.4192
Epoch 30/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 248.0853 - val_loss: 245.1908
Epoch 31/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 247.3860 - val_loss: 245.2535
Epoch 32/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 246.7011 - val_loss: 247.8284
Epoch 33/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 245.8931 - val_loss: 242.1651
Epoch 34/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 245.1529 - val_loss: 242.4738
Epoch 35/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 244.0646 - val_loss: 239.9308
Epoch 36/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 243.0213 - val_loss: 239.0013
Epoch 37/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 241.8407 - val_loss: 239.8279
Epoch 38/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 240.3896 - val_loss: 237.1370
Epoch 39/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 238.9262 - val_loss: 233.0837
Epoch 40/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 237.3195 - val_loss: 229.0281
Epoch 41/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 235.9223 - val_loss: 235.0207
Epoch 42/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 234.7002 - val_loss: 231.8027
Epoch 43/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 233.4399 - val_loss: 227.0614
Epoch 44/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 232.3631 - val_loss: 226.2877
Epoch 45/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 231.5138 - val_loss: 224.5772
Epoch 46/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.6965 - val_loss: 228.5738
Epoch 47/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 229.9893 - val_loss: 223.7751
Epoch 48/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 229.4077 - val_loss: 228.1810
Epoch 49/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.7406 - val_loss: 228.7248
Epoch 50/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.2136 - val_loss: 221.4103
Epoch 51/65                                                                                                                                                                                                        9445953/9445953 [==============================] - 35s 4us/step - loss: 227.5608 - val_loss: 219.9623
Epoch 52/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.2158 - val_loss: 225.0924
Epoch 53/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.5517 - val_loss: 217.3455
Epoch 54/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.2429 - val_loss: 219.5970
Epoch 55/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.8411 - val_loss: 222.2969
Epoch 56/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.4504 - val_loss: 218.6299
Epoch 57/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.2137 - val_loss: 218.9868
Epoch 58/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.5533 - val_loss: 215.9406
Epoch 59/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.3573 - val_loss: 217.8087
Epoch 60/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.0640 - val_loss: 217.5963
Epoch 61/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 223.4658 - val_loss: 227.7560
Epoch 62/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 223.3416 - val_loss: 221.1471
Epoch 63/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 223.1230 - val_loss: 216.2216
Epoch 64/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 222.9404 - val_loss: 233.7208
Epoch 65/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 222.5757 - val_loss: 233.2459

         CHILD ACCURACY = 229.1725132413961


         PARENT ACCURACY = 206.08845193106362


 CHILD 5 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7500

         EPOCHS = 60
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/60
2018-07-18 09:20:29.801869: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 09:20:29.806623: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 37s 4us/step - loss: 328.0794 - val_loss: 313.9510
Epoch 2/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 305.2887 - val_loss: 291.9103
Epoch 3/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 283.2708 - val_loss: 294.2675
Epoch 4/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 278.1890 - val_loss: 281.2498
Epoch 5/60
9445953/9445953 [==============================] - 37s 4us/step - loss: 275.8472 - val_loss: 273.9469
Epoch 6/60
9445953/9445953 [==============================] - 39s 4us/step - loss: 274.5206 - val_loss: 273.1165
Epoch 7/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 273.6636 - val_loss: 271.3192
Epoch 8/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 273.0068 - val_loss: 270.4541
Epoch 9/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 272.4173 - val_loss: 271.9671
Epoch 10/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 271.9511 - val_loss: 269.3553
Epoch 11/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 271.4940 - val_loss: 270.1258
Epoch 12/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 271.0804 - val_loss: 269.7873
Epoch 13/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 270.7278 - val_loss: 268.5846
Epoch 14/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 270.4043 - val_loss: 267.7896
Epoch 15/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 270.0439 - val_loss: 267.7396
Epoch 16/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 269.6938 - val_loss: 269.8118
Epoch 17/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 269.3149 - val_loss: 266.8424
Epoch 18/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 269.0354 - val_loss: 267.1595
Epoch 19/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 268.6695 - val_loss: 267.6142
Epoch 20/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 268.2667 - val_loss: 265.9652
Epoch 21/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 267.6482 - val_loss: 265.2747
Epoch 22/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 266.5082 - val_loss: 261.6965
Epoch 23/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 260.7395 - val_loss: 254.4683
Epoch 24/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 255.0676 - val_loss: 249.4335
Epoch 25/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 251.2380 - val_loss: 246.2079
Epoch 26/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 248.3925 - val_loss: 241.0417
Epoch 27/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 245.9276 - val_loss: 240.4425
Epoch 28/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 243.7895 - val_loss: 250.8428
Epoch 29/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 242.0702 - val_loss: 239.4572
Epoch 30/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 240.6657 - val_loss: 241.9164
Epoch 31/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 239.3187 - val_loss: 244.2372
Epoch 32/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 238.3397 - val_loss: 232.0369
Epoch 33/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 237.1724 - val_loss: 232.3732
Epoch 34/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 236.3953 - val_loss: 231.8851
Epoch 35/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 235.5302 - val_loss: 228.2934
Epoch 36/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 234.7492 - val_loss: 232.0409
Epoch 37/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 234.0437 - val_loss: 235.7156                                                                                                              Epoch 38/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 233.4788 - val_loss: 234.4943
Epoch 39/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 232.8406 - val_loss: 226.8272
Epoch 40/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 232.4242 - val_loss: 229.3527
Epoch 41/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 231.7377 - val_loss: 226.3326
Epoch 42/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 231.2637 - val_loss: 225.1986
Epoch 43/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 230.9214 - val_loss: 228.0520
Epoch 44/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 230.4636 - val_loss: 223.9223
Epoch 45/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 230.0841 - val_loss: 223.8443
Epoch 46/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 229.6389 - val_loss: 222.2247
Epoch 47/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 229.2316 - val_loss: 223.1234
Epoch 48/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 228.7682 - val_loss: 223.3040
Epoch 49/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 228.6331 - val_loss: 222.4274
Epoch 50/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 228.3114 - val_loss: 222.1491
Epoch 51/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 227.9953 - val_loss: 227.5563
Epoch 52/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 227.6298 - val_loss: 224.1674
Epoch 53/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 227.1747 - val_loss: 230.5752
Epoch 54/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 227.0158 - val_loss: 222.9442
Epoch 55/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 226.8760 - val_loss: 229.3869
Epoch 56/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 226.4707 - val_loss: 226.0598
Epoch 57/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 226.3681 - val_loss: 228.4131
Epoch 58/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 226.0521 - val_loss: 223.2754
Epoch 59/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 225.6550 - val_loss: 218.2575
Epoch 60/60
9445953/9445953 [==============================] - 36s 4us/step - loss: 225.5396 - val_loss: 228.3785

         CHILD ACCURACY = 223.25859156996967


         PARENT ACCURACY = 206.08845193106362



 QUEUE SIZE BEFORE GET = 3


 NODE SELECTED <<<------ Epochs = 55 -------- BatchSize = 10500--------- Accuracy = 209.94244174160647 -------->>>


 CHILD 1 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 12000

         EPOCHS = 50
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/50
2018-07-18 09:56:53.080590: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 09:56:53.085119: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 33s 4us/step - loss: 323.2919 - val_loss: 311.4898
Epoch 2/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 308.7706 - val_loss: 309.2247
Epoch 3/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 287.3581 - val_loss: 277.6092
Epoch 4/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 278.3670 - val_loss: 277.4986
Epoch 5/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 276.5629 - val_loss: 274.1894
Epoch 6/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 275.2833 - val_loss: 273.6741
Epoch 7/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 273.9205 - val_loss: 270.0306
Epoch 8/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 272.0097 - val_loss: 277.3087
Epoch 9/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 268.5725 - val_loss: 265.0702
Epoch 10/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 264.2914 - val_loss: 271.7161
Epoch 11/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 260.5160 - val_loss: 273.2195
Epoch 12/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 257.4003 - val_loss: 252.5475
Epoch 13/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 254.8684 - val_loss: 252.5954
Epoch 14/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 252.8073 - val_loss: 247.2536
Epoch 15/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 250.8872 - val_loss: 249.2944
Epoch 16/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 249.3560 - val_loss: 243.8915
Epoch 17/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 247.6382 - val_loss: 244.4551
Epoch 18/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 246.3976 - val_loss: 240.2705
Epoch 19/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 244.6032 - val_loss: 254.9070
Epoch 20/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 243.5377 - val_loss: 242.1307
Epoch 21/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 242.1653 - val_loss: 261.6642                                                                                                              Epoch 22/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 240.9853 - val_loss: 239.7581
Epoch 23/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 239.6854 - val_loss: 239.8144
Epoch 24/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 238.7362 - val_loss: 233.5238
Epoch 25/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 237.6445 - val_loss: 239.1990
Epoch 26/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 236.5662 - val_loss: 241.4572
Epoch 27/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 235.8457 - val_loss: 236.0610
Epoch 28/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 234.9651 - val_loss: 248.4432
Epoch 29/50
9445953/9445953 [==============================] - 36s 4us/step - loss: 234.1694 - val_loss: 238.5278
Epoch 30/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 233.4311 - val_loss: 227.3724
Epoch 31/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 232.5500 - val_loss: 257.3197
Epoch 32/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 231.9408 - val_loss: 239.4194
Epoch 33/50
9445953/9445953 [==============================] - 33s 3us/step - loss: 231.4838 - val_loss: 234.5268
Epoch 34/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 230.7069 - val_loss: 232.4172
Epoch 35/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 230.1442 - val_loss: 243.9560
Epoch 36/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 229.5216 - val_loss: 241.8684
Epoch 37/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 229.1162 - val_loss: 229.0598
Epoch 38/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 228.4054 - val_loss: 226.0171
Epoch 39/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 228.1096 - val_loss: 227.6321
Epoch 40/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.7776 - val_loss: 219.9490
Epoch 41/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.1577 - val_loss: 232.6300
Epoch 42/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.8114 - val_loss: 221.1148
Epoch 43/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.4329 - val_loss: 225.0277
Epoch 44/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.2064 - val_loss: 226.9436
Epoch 45/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 225.7400 - val_loss: 236.8127
Epoch 46/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 225.4698 - val_loss: 218.6912
Epoch 47/50
9445953/9445953 [==============================] - 33s 4us/step - loss: 225.0886 - val_loss: 215.4437
Epoch 48/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.7072 - val_loss: 249.3291
Epoch 49/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.4859 - val_loss: 241.1967
Epoch 50/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.2862 - val_loss: 235.6362

         CHILD ACCURACY = 246.160863818145


         PARENT ACCURACY = 209.94244174160647


 CHILD 2 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 10500

         EPOCHS = 60
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/60
2018-07-18 10:24:35.158874: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 10:24:35.164575: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 35s 4us/step - loss: 321.4020 - val_loss: 300.2475
Epoch 2/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 318.7341 - val_loss: 332.9429
Epoch 3/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 293.1035 - val_loss: 280.3576
Epoch 4/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 279.4504 - val_loss: 274.0534
Epoch 5/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 276.2169 - val_loss: 272.9036
Epoch 6/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 274.5805 - val_loss: 272.3745
Epoch 7/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 273.2788 - val_loss: 272.3110
Epoch 8/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 271.9132 - val_loss: 270.5050
Epoch 9/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 269.2062 - val_loss: 263.6398
Epoch 10/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 264.2321 - val_loss: 261.5585
Epoch 11/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 259.9247 - val_loss: 255.7709
Epoch 12/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 256.7944 - val_loss: 254.8603
Epoch 13/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 254.1353 - val_loss: 247.1007
Epoch 14/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 252.1813 - val_loss: 247.8699
Epoch 15/60                                                                                                                                                                                                        9445953/9445953 [==============================] - 35s 4us/step - loss: 250.0926 - val_loss: 241.7133
Epoch 16/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 248.3882 - val_loss: 245.2857
Epoch 17/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 246.6827 - val_loss: 242.8420
Epoch 18/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 245.2754 - val_loss: 238.7084
Epoch 19/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 243.9819 - val_loss: 245.2883
Epoch 20/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 242.8338 - val_loss: 240.4092
Epoch 21/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 241.6549 - val_loss: 241.5778
Epoch 22/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 240.5354 - val_loss: 235.6289
Epoch 23/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 239.4128 - val_loss: 233.4474
Epoch 24/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 238.7080 - val_loss: 235.1514
Epoch 25/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 237.7794 - val_loss: 230.6208
Epoch 26/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 236.9127 - val_loss: 232.1107
Epoch 27/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 236.2138 - val_loss: 228.2651
Epoch 28/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 235.4699 - val_loss: 228.8720
Epoch 29/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 234.7605 - val_loss: 227.6790
Epoch 30/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 234.1783 - val_loss: 231.2268
Epoch 31/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 233.7169 - val_loss: 226.6121
Epoch 32/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 233.0467 - val_loss: 225.5818
Epoch 33/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 232.5150 - val_loss: 236.3043
Epoch 34/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 232.1790 - val_loss: 226.3365
Epoch 35/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 231.4582 - val_loss: 226.3936
Epoch 36/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 231.0548 - val_loss: 222.0092
Epoch 37/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 230.5605 - val_loss: 221.2153
Epoch 38/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 230.3426 - val_loss: 225.4447
Epoch 39/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 229.8099 - val_loss: 230.4603
Epoch 40/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 229.3139 - val_loss: 227.5150
Epoch 41/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 229.1119 - val_loss: 224.3200
Epoch 42/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 228.6098 - val_loss: 226.0913
Epoch 43/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 228.3109 - val_loss: 227.8984
Epoch 44/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.7887 - val_loss: 225.0553
Epoch 45/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.5627 - val_loss: 219.8750
Epoch 46/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.1864 - val_loss: 220.2343
Epoch 47/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.0526 - val_loss: 216.9791
Epoch 48/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.6941 - val_loss: 228.4703
Epoch 49/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.3469 - val_loss: 217.4259
Epoch 50/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.1478 - val_loss: 217.4486
Epoch 51/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 225.7819 - val_loss: 216.1189
Epoch 52/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 225.2218 - val_loss: 220.8221
Epoch 53/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 225.4441 - val_loss: 218.3012
Epoch 54/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.8329 - val_loss: 217.2528
Epoch 55/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.5381 - val_loss: 216.7107
Epoch 56/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.4056 - val_loss: 221.8130
Epoch 57/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.1095 - val_loss: 215.8949
Epoch 58/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.0030 - val_loss: 216.6154
Epoch 59/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 223.5329 - val_loss: 224.3562
Epoch 60/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 223.4672 - val_loss: 226.7422

         CHILD ACCURACY = 218.02618911065693


         PARENT ACCURACY = 209.94244174160647


 CHILD 3 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 9000

         EPOCHS = 60
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/60
2018-07-18 10:58:48.450210: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 10:58:48.457287: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 36s 4us/step - loss: 320.0096 - val_loss: 302.2812
Epoch 2/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 290.7896 - val_loss: 276.2066
Epoch 3/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 278.0703 - val_loss: 272.5194
Epoch 4/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 274.8487 - val_loss: 270.7677
Epoch 5/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 271.4869 - val_loss: 265.3712
Epoch 6/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 266.0645 - val_loss: 258.6294                                                                                                              Epoch 7/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 261.1953 - val_loss: 254.1960
Epoch 8/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 257.2308 - val_loss: 253.5924
Epoch 9/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 254.0411 - val_loss: 249.8627
Epoch 10/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 251.6970 - val_loss: 248.0442
Epoch 11/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 249.5565 - val_loss: 247.5150
Epoch 12/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 247.6212 - val_loss: 241.7922
Epoch 13/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 245.5513 - val_loss: 243.0745
Epoch 14/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 243.8701 - val_loss: 238.4495
Epoch 15/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 242.0978 - val_loss: 238.2651
Epoch 16/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 240.3989 - val_loss: 234.7541
Epoch 17/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 238.7995 - val_loss: 231.7600
Epoch 18/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 237.3251 - val_loss: 230.4988
Epoch 19/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 235.9064 - val_loss: 229.8663
Epoch 20/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 234.6583 - val_loss: 230.2417
Epoch 21/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 233.5220 - val_loss: 237.0140
Epoch 22/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 232.5270 - val_loss: 225.3238
Epoch 23/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 231.3772 - val_loss: 222.2306
Epoch 24/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.5670 - val_loss: 235.4337
Epoch 25/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 229.8387 - val_loss: 223.9023
Epoch 26/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 229.1944 - val_loss: 226.9623
Epoch 27/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.2492 - val_loss: 227.4977
Epoch 28/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.5786 - val_loss: 222.0689
Epoch 29/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.1330 - val_loss: 220.0607
Epoch 30/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.6229 - val_loss: 225.0671
Epoch 31/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.9893 - val_loss: 217.2897
Epoch 32/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.6739 - val_loss: 228.3165
Epoch 33/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.0960 - val_loss: 234.5906
Epoch 34/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.5870 - val_loss: 218.9308
Epoch 35/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.0044 - val_loss: 216.4182
Epoch 36/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 223.6182 - val_loss: 217.9275
Epoch 37/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 223.3424 - val_loss: 223.8592
Epoch 38/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 222.9628 - val_loss: 218.6389
Epoch 39/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 222.4367 - val_loss: 218.9771
Epoch 40/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 222.3231 - val_loss: 218.7761
Epoch 41/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 221.9359 - val_loss: 216.4116
Epoch 42/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 221.5439 - val_loss: 216.8742
Epoch 43/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 221.3394 - val_loss: 225.0907
Epoch 44/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 221.0338 - val_loss: 213.5115
Epoch 45/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 220.3989 - val_loss: 213.7935
Epoch 46/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 220.5513 - val_loss: 213.5757
Epoch 47/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 219.9389 - val_loss: 221.5751
Epoch 48/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 219.9312 - val_loss: 218.2309
Epoch 49/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 219.4510 - val_loss: 223.5835
Epoch 50/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 219.2166 - val_loss: 215.0054
Epoch 51/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 219.1569 - val_loss: 212.0155
Epoch 52/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 218.6361 - val_loss: 210.9446
Epoch 53/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 218.4879 - val_loss: 221.9982
Epoch 54/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 218.3164 - val_loss: 232.2770
Epoch 55/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 218.1646 - val_loss: 225.4220
Epoch 56/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 217.9265 - val_loss: 210.8357
Epoch 57/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 217.6326 - val_loss: 211.3026
Epoch 58/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 217.3570 - val_loss: 214.5185
Epoch 59/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 217.2941 - val_loss: 213.1959
Epoch 60/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 216.9840 - val_loss: 208.7387

         CHILD ACCURACY = 206.56094494221642


         PARENT ACCURACY = 209.94244174160647


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 3 <<<<<<<<<<<<<<<<<<<<<<<<<<<

                                                                                                                                                                                                                    CHILD 4 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 12000

         EPOCHS = 55
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/55
2018-07-18 11:34:10.817114: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 11:34:10.822671: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 318.5452 - val_loss: 298.2858
Epoch 2/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 289.7564 - val_loss: 295.7926
Epoch 3/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 278.6695 - val_loss: 277.7701
Epoch 4/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 275.7676 - val_loss: 273.6239
Epoch 5/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 274.4282 - val_loss: 272.7234
Epoch 6/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 273.4885 - val_loss: 273.0219
Epoch 7/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 272.7140 - val_loss: 273.4341
Epoch 8/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 272.1113 - val_loss: 272.4814
Epoch 9/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 271.6516 - val_loss: 277.9426
Epoch 10/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 271.0977 - val_loss: 271.4284
Epoch 11/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 270.8110 - val_loss: 269.4909
Epoch 12/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 270.3095 - val_loss: 268.0551
Epoch 13/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 269.8973 - val_loss: 271.8939
Epoch 14/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 269.4370 - val_loss: 272.3502
Epoch 15/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 268.9154 - val_loss: 271.6717
Epoch 16/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 268.1419 - val_loss: 272.1741
Epoch 17/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 265.7113 - val_loss: 262.3802
Epoch 18/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 259.6834 - val_loss: 263.0296
Epoch 19/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 254.9261 - val_loss: 250.7513
Epoch 20/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 251.6123 - val_loss: 254.6316
Epoch 21/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 248.8575 - val_loss: 249.5650
Epoch 22/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 246.6560 - val_loss: 247.3524
Epoch 23/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 244.6716 - val_loss: 245.0545
Epoch 24/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 243.0682 - val_loss: 243.0842
Epoch 25/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 241.5480 - val_loss: 238.3039
Epoch 26/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 240.2461 - val_loss: 240.7922
Epoch 27/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 239.2324 - val_loss: 237.6656
Epoch 28/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 238.1678 - val_loss: 246.9863
Epoch 29/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 237.3457 - val_loss: 242.0818
Epoch 30/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 236.4849 - val_loss: 242.7418
Epoch 31/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 235.5853 - val_loss: 238.7634
Epoch 32/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 235.1163 - val_loss: 253.1786
Epoch 33/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 234.3178 - val_loss: 227.0486
Epoch 34/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 233.7748 - val_loss: 235.6536
Epoch 35/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 233.1250 - val_loss: 235.8391
Epoch 36/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 232.6712 - val_loss: 240.9963
Epoch 37/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 232.0698 - val_loss: 240.3698
Epoch 38/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 231.7645 - val_loss: 240.9077
Epoch 39/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 231.4278 - val_loss: 241.7034
Epoch 40/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 230.7797 - val_loss: 231.4191
Epoch 41/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 230.5607 - val_loss: 235.2322
Epoch 42/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 230.1651 - val_loss: 237.0837
Epoch 43/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 229.6510 - val_loss: 230.6962
Epoch 44/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 229.3583 - val_loss: 227.0916
Epoch 45/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 228.7419 - val_loss: 226.1850
Epoch 46/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 228.6147 - val_loss: 232.0064
Epoch 47/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 228.4035 - val_loss: 229.1346
Epoch 48/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 227.8900 - val_loss: 243.0715
Epoch 49/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 227.6829 - val_loss: 228.1076
Epoch 50/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 227.4601 - val_loss: 232.2198
Epoch 51/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 226.9198 - val_loss: 222.1609                                                                                                              Epoch 52/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 226.7963 - val_loss: 222.1769
Epoch 53/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 226.4843 - val_loss: 236.1023
Epoch 54/55
9445953/9445953 [==============================] - 33s 3us/step - loss: 226.2148 - val_loss: 229.9409
Epoch 55/55
9445953/9445953 [==============================] - 33s 4us/step - loss: 226.0046 - val_loss: 239.4486

         CHILD ACCURACY = 237.4593427506214


         PARENT ACCURACY = 209.94244174160647


 CHILD 5 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 12000

         EPOCHS = 60
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/60
2018-07-18 12:04:32.302646: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 12:04:32.326484: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 318.6498 - val_loss: 306.2850
Epoch 2/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 292.1434 - val_loss: 283.7501
Epoch 3/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 282.6762 - val_loss: 279.5293
Epoch 4/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 278.5598 - val_loss: 275.7665
Epoch 5/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 275.9338 - val_loss: 275.6815
Epoch 6/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 274.3335 - val_loss: 275.2440
Epoch 7/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 273.0916 - val_loss: 279.2989
Epoch 8/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 272.1355 - val_loss: 269.3982
Epoch 9/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 271.4280 - val_loss: 270.5027
Epoch 10/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 270.7705 - val_loss: 269.7406
Epoch 11/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 270.1685 - val_loss: 269.0083
Epoch 12/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 269.6980 - val_loss: 270.0097
Epoch 13/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 269.2678 - val_loss: 269.8426
Epoch 14/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 268.8649 - val_loss: 270.8650
Epoch 15/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 268.4326 - val_loss: 268.9524
Epoch 16/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 268.1320 - val_loss: 267.1033
Epoch 17/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 267.7823 - val_loss: 269.1595
Epoch 18/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 267.4521 - val_loss: 267.2728
Epoch 19/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 267.1103 - val_loss: 265.7828
Epoch 20/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 266.7730 - val_loss: 264.2251
Epoch 21/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 266.3134 - val_loss: 265.3594
Epoch 22/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 265.7849 - val_loss: 268.6998
Epoch 23/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 265.1373 - val_loss: 263.3044
Epoch 24/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 264.0319 - val_loss: 264.4591
Epoch 25/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 261.5270 - val_loss: 257.1618
Epoch 26/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 257.8626 - val_loss: 256.5396
Epoch 27/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 254.6009 - val_loss: 249.8881
Epoch 28/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 252.3924 - val_loss: 254.4475
Epoch 29/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 250.4822 - val_loss: 250.0968
Epoch 30/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 248.5936 - val_loss: 249.7464
Epoch 31/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 247.1349 - val_loss: 250.8535
Epoch 32/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 245.7426 - val_loss: 252.9385
Epoch 33/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 244.5250 - val_loss: 247.7800
Epoch 34/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 243.5088 - val_loss: 248.1795
Epoch 35/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 242.4012 - val_loss: 245.6955
Epoch 36/60                                                                                                                                                                                                        9445953/9445953 [==============================] - 33s 4us/step - loss: 241.5401 - val_loss: 242.6673
Epoch 37/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 240.6529 - val_loss: 237.6250
Epoch 38/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 239.8950 - val_loss: 239.9452
Epoch 39/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 239.0165 - val_loss: 233.2432
Epoch 40/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 238.3066 - val_loss: 241.1426
Epoch 41/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 237.5972 - val_loss: 232.0881
Epoch 42/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 237.1115 - val_loss: 230.1266
Epoch 43/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 236.2880 - val_loss: 240.3311
Epoch 44/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 235.8246 - val_loss: 227.6584
Epoch 45/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 235.2534 - val_loss: 230.9841
Epoch 46/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 234.8272 - val_loss: 236.1319
Epoch 47/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 234.2805 - val_loss: 230.1513
Epoch 48/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 233.8537 - val_loss: 226.0749
Epoch 49/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 233.4304 - val_loss: 230.2871
Epoch 50/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 232.9388 - val_loss: 227.9772
Epoch 51/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 232.7140 - val_loss: 228.8780
Epoch 52/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 232.0962 - val_loss: 231.3774
Epoch 53/60
9445953/9445953 [==============================] - 33s 4us/step - loss: 231.6237 - val_loss: 229.7144
Epoch 54/60
9445953/9445953 [==============================] - 33s 3us/step - loss: 231.5306 - val_loss: 229.1752
Epoch 55/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 231.0693 - val_loss: 234.0089
Epoch 56/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 230.6738 - val_loss: 237.9549
Epoch 57/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 230.4271 - val_loss: 231.9626
Epoch 58/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 230.0897 - val_loss: 222.1612
Epoch 59/60
9445953/9445953 [==============================] - 35s 4us/step - loss: 229.7476 - val_loss: 226.0435
Epoch 60/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 229.3285 - val_loss: 226.7469

         CHILD ACCURACY = 223.55888390056032


         PARENT ACCURACY = 209.94244174160647



 QUEUE SIZE BEFORE GET = 3


 NODE SELECTED <<<------ Epochs = 60 -------- BatchSize = 9000--------- Accuracy = 206.56094494221642 -------->>>


 CHILD 1 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7500

         EPOCHS = 55
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/55
2018-07-18 12:37:57.163199: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 12:37:57.166830: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 39s 4us/step - loss: 313.7798 - val_loss: 292.5923
Epoch 2/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 287.7564 - val_loss: 290.1488
Epoch 3/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 280.8128 - val_loss: 290.0640
Epoch 4/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 278.3319 - val_loss: 279.2262
Epoch 5/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 277.4680 - val_loss: 278.8084
Epoch 6/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 276.8827 - val_loss: 280.9273
Epoch 7/55
9445953/9445953 [==============================] - 36s 4us/step - loss: 276.5132 - val_loss: 274.2538
Epoch 8/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 276.1502 - val_loss: 279.3748
Epoch 9/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 275.8374 - val_loss: 277.5363
Epoch 10/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 275.5388 - val_loss: 276.5968
Epoch 11/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 275.2098 - val_loss: 274.2777
Epoch 12/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 274.7229 - val_loss: 276.7641
Epoch 13/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 274.1040 - val_loss: 272.4673
Epoch 14/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 272.1268 - val_loss: 268.3955
Epoch 15/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 267.7044 - val_loss: 264.7903
Epoch 16/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 264.8877 - val_loss: 263.1967
Epoch 17/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 263.0352 - val_loss: 261.5609
Epoch 18/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 261.4728 - val_loss: 264.2241
Epoch 19/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 260.5257 - val_loss: 257.7977
Epoch 20/55                                                                                                                                                                                                        9445953/9445953 [==============================] - 38s 4us/step - loss: 259.5775 - val_loss: 258.8018
Epoch 21/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 258.8708 - val_loss: 255.7578
Epoch 22/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 258.1963 - val_loss: 254.5111
Epoch 23/55
9445953/9445953 [==============================] - 38s 4us/step - loss: 257.5255 - val_loss: 255.3193
Epoch 24/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 257.0260 - val_loss: 258.3916
Epoch 25/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 256.5011 - val_loss: 255.5160
Epoch 26/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 256.0991 - val_loss: 256.6096
Epoch 27/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 255.6905 - val_loss: 252.1735
Epoch 28/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 255.2832 - val_loss: 252.1510
Epoch 29/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 254.9874 - val_loss: 251.0342
Epoch 30/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 254.7221 - val_loss: 251.5680
Epoch 31/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 254.4463 - val_loss: 253.8466
Epoch 32/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 254.2321 - val_loss: 253.8619
Epoch 33/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 253.9673 - val_loss: 252.0827
Epoch 34/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 253.7171 - val_loss: 256.8256
Epoch 35/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 253.5609 - val_loss: 254.8967
Epoch 36/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 253.2409 - val_loss: 250.3127
Epoch 37/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 253.1245 - val_loss: 250.6839
Epoch 38/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 252.9212 - val_loss: 250.0515
Epoch 39/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 252.7521 - val_loss: 251.0245
Epoch 40/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 252.5538 - val_loss: 256.2335
Epoch 41/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 252.4646 - val_loss: 250.7195
Epoch 42/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 252.2114 - val_loss: 248.7843
Epoch 43/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 252.1512 - val_loss: 249.6361
Epoch 44/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 252.0293 - val_loss: 248.5069
Epoch 45/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 251.9009 - val_loss: 249.4091
Epoch 46/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 251.6945 - val_loss: 252.6367
Epoch 47/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 251.5674 - val_loss: 248.6790
Epoch 48/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 251.4566 - val_loss: 249.5317
Epoch 49/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 251.3371 - val_loss: 253.4034
Epoch 50/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 251.2641 - val_loss: 248.3032
Epoch 51/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 251.0619 - val_loss: 248.5036
Epoch 52/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 251.0936 - val_loss: 248.0531
Epoch 53/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 250.9238 - val_loss: 249.0113
Epoch 54/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 250.7885 - val_loss: 248.3697
Epoch 55/55
9445953/9445953 [==============================] - 37s 4us/step - loss: 250.7785 - val_loss: 252.8088

         CHILD ACCURACY = 248.22533530506612


         PARENT ACCURACY = 206.56094494221642


 CHILD 2 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 9000

         EPOCHS = 65
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/65
2018-07-18 13:12:01.546317: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 13:12:01.551279: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 36s 4us/step - loss: 319.7702 - val_loss: 318.2992
Epoch 2/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 288.3974 - val_loss: 274.9908
Epoch 3/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 276.6922 - val_loss: 273.3801
Epoch 4/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 274.5775 - val_loss: 271.6726                                                                                                              Epoch 5/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 273.2425 - val_loss: 271.5325
Epoch 6/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 271.9919 - val_loss: 270.8114
Epoch 7/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 270.3764 - val_loss: 267.3366
Epoch 8/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 265.7500 - val_loss: 256.7706
Epoch 9/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 260.6851 - val_loss: 256.1757
Epoch 10/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 257.0690 - val_loss: 250.8531
Epoch 11/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 254.1754 - val_loss: 247.0484
Epoch 12/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 251.5978 - val_loss: 245.1703
Epoch 13/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 249.1033 - val_loss: 243.3477
Epoch 14/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 247.2629 - val_loss: 245.7321
Epoch 15/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 245.4509 - val_loss: 241.6096
Epoch 16/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 243.8907 - val_loss: 245.8615
Epoch 17/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 242.5489 - val_loss: 240.2349
Epoch 18/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 241.2937 - val_loss: 233.2915
Epoch 19/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 240.3223 - val_loss: 235.6148
Epoch 20/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 239.1674 - val_loss: 235.2871
Epoch 21/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 238.2958 - val_loss: 230.1699
Epoch 22/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 237.5189 - val_loss: 235.0486
Epoch 23/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 236.6927 - val_loss: 238.9926
Epoch 24/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 235.9176 - val_loss: 232.9898
Epoch 25/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 235.4129 - val_loss: 230.3266
Epoch 26/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 234.7087 - val_loss: 231.5022
Epoch 27/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 234.1206 - val_loss: 233.8882
Epoch 28/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 233.5824 - val_loss: 226.0649
Epoch 29/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 233.2149 - val_loss: 226.3807
Epoch 30/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 232.5777 - val_loss: 226.5834
Epoch 31/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 232.3492 - val_loss: 232.4064
Epoch 32/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 231.8770 - val_loss: 230.7041
Epoch 33/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 231.4381 - val_loss: 228.9991
Epoch 34/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 231.0401 - val_loss: 225.5938
Epoch 35/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.5863 - val_loss: 227.9274
Epoch 36/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.2582 - val_loss: 224.7221
Epoch 37/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 229.9523 - val_loss: 225.7168
Epoch 38/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 229.7038 - val_loss: 228.4527
Epoch 39/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 229.1026 - val_loss: 221.3922
Epoch 40/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.9327 - val_loss: 222.4715
Epoch 41/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.6795 - val_loss: 223.4375
Epoch 42/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.5245 - val_loss: 230.0914
Epoch 43/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.0932 - val_loss: 234.5685
Epoch 44/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.9932 - val_loss: 220.9116
Epoch 45/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.5540 - val_loss: 223.6085
Epoch 46/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.4570 - val_loss: 224.6985
Epoch 47/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.1644 - val_loss: 220.4305
Epoch 48/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.9568 - val_loss: 222.0582
Epoch 49/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.7228 - val_loss: 221.7431
Epoch 50/65
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.4830 - val_loss: 218.7390
Epoch 51/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.2895 - val_loss: 224.3837
Epoch 52/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.0419 - val_loss: 218.1259
Epoch 53/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.8413 - val_loss: 223.8760
Epoch 54/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.8999 - val_loss: 227.0303
Epoch 55/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.5688 - val_loss: 219.9463
Epoch 56/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.3820 - val_loss: 216.6303
Epoch 57/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.1454 - val_loss: 224.0031
Epoch 58/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.0240 - val_loss: 228.1964
Epoch 59/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.7525 - val_loss: 232.0989
Epoch 60/65                                                                                                                                                                                                        9445953/9445953 [==============================] - 35s 4us/step - loss: 224.6373 - val_loss: 226.0567
Epoch 61/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.3286 - val_loss: 220.4554
Epoch 62/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.3688 - val_loss: 225.6826
Epoch 63/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.0933 - val_loss: 215.7468
Epoch 64/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 223.9922 - val_loss: 216.8627
Epoch 65/65
9445953/9445953 [==============================] - 35s 4us/step - loss: 223.7342 - val_loss: 227.4503

         CHILD ACCURACY = 218.82404590170762


         PARENT ACCURACY = 206.56094494221642


 CHILD 3 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 10500

         EPOCHS = 60
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/60
2018-07-18 13:50:08.130976: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 13:50:08.137970: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 35s 4us/step - loss: 320.6849 - val_loss: 307.0338
Epoch 2/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 296.9605 - val_loss: 284.1355
Epoch 3/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 283.3036 - val_loss: 280.7486
Epoch 4/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 279.6676 - val_loss: 281.3148
Epoch 5/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 278.3094 - val_loss: 277.6412
Epoch 6/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 277.2831 - val_loss: 276.9779
Epoch 7/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 276.0699 - val_loss: 276.3283
Epoch 8/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 275.1926 - val_loss: 277.7894
Epoch 9/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 274.4145 - val_loss: 273.9068
Epoch 10/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 273.3059 - val_loss: 271.4693
Epoch 11/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 272.3553 - val_loss: 270.8502
Epoch 12/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 271.6553 - val_loss: 271.0777
Epoch 13/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 271.1922 - val_loss: 269.8559
Epoch 14/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 270.7276 - val_loss: 268.7001
Epoch 15/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 270.3732 - val_loss: 269.1030
Epoch 16/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 270.1074 - val_loss: 269.9386
Epoch 17/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 269.8434 - val_loss: 270.2640
Epoch 18/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 269.5699 - val_loss: 268.1398
Epoch 19/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 269.3865 - val_loss: 268.4035
Epoch 20/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 269.2487 - val_loss: 267.5257
Epoch 21/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 269.0034 - val_loss: 268.7211
Epoch 22/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 268.7995 - val_loss: 268.0417
Epoch 23/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 268.6398 - val_loss: 267.6036
Epoch 24/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 268.4582 - val_loss: 267.5854
Epoch 25/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 268.3060 - val_loss: 267.0426
Epoch 26/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 268.1192 - val_loss: 266.9064
Epoch 27/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 267.9568 - val_loss: 266.4039
Epoch 28/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 267.7544 - val_loss: 265.9384
Epoch 29/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 267.5920 - val_loss: 266.6224
Epoch 30/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 267.4192 - val_loss: 266.1884
Epoch 31/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 267.3130 - val_loss: 265.4171
Epoch 32/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 267.0882 - val_loss: 265.7870
Epoch 33/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 266.9747 - val_loss: 265.8077
Epoch 34/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 266.7839 - val_loss: 266.1815
Epoch 35/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 266.6050 - val_loss: 264.6601
Epoch 36/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 266.4470 - val_loss: 264.9820
Epoch 37/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 266.2936 - val_loss: 265.4883
Epoch 38/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 266.0323 - val_loss: 264.1915
Epoch 39/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 265.9740 - val_loss: 263.9897
Epoch 40/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 265.8042 - val_loss: 264.3024
Epoch 41/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 265.5718 - val_loss: 265.8964
Epoch 42/60                                                                                                                                                                                                        9445953/9445953 [==============================] - 34s 4us/step - loss: 265.4752 - val_loss: 263.7560
Epoch 43/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 265.2861 - val_loss: 264.6570
Epoch 44/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 265.1232 - val_loss: 263.5843
Epoch 45/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 264.9477 - val_loss: 263.6411
Epoch 46/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 264.8308 - val_loss: 264.2162
Epoch 47/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 264.6027 - val_loss: 262.7807
Epoch 48/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 264.3368 - val_loss: 263.1977
Epoch 49/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 264.2692 - val_loss: 262.5361
Epoch 50/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 264.0714 - val_loss: 262.9237
Epoch 51/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 263.8650 - val_loss: 262.2562
Epoch 52/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 263.6752 - val_loss: 263.9883
Epoch 53/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 263.3889 - val_loss: 261.6135
Epoch 54/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 260.3987 - val_loss: 255.9725
Epoch 55/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 256.0006 - val_loss: 251.2792
Epoch 56/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 252.6337 - val_loss: 253.8200
Epoch 57/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 250.0704 - val_loss: 246.7138
Epoch 58/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 247.9965 - val_loss: 246.3873
Epoch 59/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 246.2042 - val_loss: 242.1806
Epoch 60/60
9445953/9445953 [==============================] - 34s 4us/step - loss: 244.8941 - val_loss: 239.6213

         CHILD ACCURACY = 240.16016801031003


         PARENT ACCURACY = 206.56094494221642


 CHILD 4 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7500

         EPOCHS = 65
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/65
2018-07-18 14:24:14.835747: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 14:24:14.842350: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 38s 4us/step - loss: 319.0430 - val_loss: 304.8973
Epoch 2/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 287.2916 - val_loss: 276.6934
Epoch 3/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 276.9350 - val_loss: 276.3140
Epoch 4/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 274.9635 - val_loss: 271.8461
Epoch 5/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 273.8034 - val_loss: 270.5743
Epoch 6/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 273.0410 - val_loss: 269.9731
Epoch 7/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 272.4894 - val_loss: 271.0680
Epoch 8/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 272.0479 - val_loss: 269.3082
Epoch 9/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 271.6929 - val_loss: 272.0772
Epoch 10/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 271.3682 - val_loss: 269.5559
Epoch 11/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 271.0422 - val_loss: 268.2798
Epoch 12/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 270.8038 - val_loss: 268.5633
Epoch 13/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 270.5183 - val_loss: 267.9414
Epoch 14/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 270.2646 - val_loss: 267.4501
Epoch 15/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 270.0356 - val_loss: 267.3462
Epoch 16/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 269.7614 - val_loss: 267.2178
Epoch 17/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 269.5151 - val_loss: 267.1360                                                                                                              Epoch 18/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 269.3859 - val_loss: 268.6428
Epoch 19/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 269.1338 - val_loss: 266.6688
Epoch 20/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 268.8853 - val_loss: 267.1471
Epoch 21/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 268.6190 - val_loss: 265.9943
Epoch 22/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 268.3731 - val_loss: 268.5123
Epoch 23/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 267.8164 - val_loss: 264.6118
Epoch 24/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 267.0896 - val_loss: 264.0578
Epoch 25/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 264.1566 - val_loss: 257.4422
Epoch 26/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 256.8382 - val_loss: 249.1075
Epoch 27/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 251.3374 - val_loss: 248.7338
Epoch 28/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 247.5788 - val_loss: 241.2347
Epoch 29/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 245.2046 - val_loss: 238.4856
Epoch 30/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 243.0556 - val_loss: 246.4192
Epoch 31/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 241.3194 - val_loss: 232.7095
Epoch 32/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 239.9249 - val_loss: 244.0747
Epoch 33/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 238.7310 - val_loss: 234.6317
Epoch 34/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 237.5529 - val_loss: 235.7520
Epoch 35/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 236.6001 - val_loss: 229.9792
Epoch 36/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 235.7738 - val_loss: 228.7740
Epoch 37/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 235.0797 - val_loss: 250.0166
Epoch 38/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 234.2235 - val_loss: 232.1326
Epoch 39/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 233.6161 - val_loss: 238.2977
Epoch 40/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 232.7801 - val_loss: 226.4407
Epoch 41/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 232.4493 - val_loss: 236.5547
Epoch 42/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 231.7973 - val_loss: 225.6004
Epoch 43/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 231.2783 - val_loss: 227.6445
Epoch 44/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 231.1658 - val_loss: 237.9972
Epoch 45/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 230.4737 - val_loss: 231.9321
Epoch 46/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 229.9526 - val_loss: 223.1667
Epoch 47/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 229.4813 - val_loss: 223.2188
Epoch 48/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 229.1182 - val_loss: 228.1512
Epoch 49/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 228.8733 - val_loss: 229.5635
Epoch 50/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 228.6132 - val_loss: 222.4150
Epoch 51/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 228.1545 - val_loss: 221.9480
Epoch 52/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 228.4036 - val_loss: 222.3312
Epoch 53/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 227.7903 - val_loss: 228.9746
Epoch 54/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 227.6485 - val_loss: 221.5035
Epoch 55/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 227.1945 - val_loss: 226.5698
Epoch 56/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 226.9334 - val_loss: 219.5535
Epoch 57/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 226.8003 - val_loss: 226.9288
Epoch 58/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 226.6050 - val_loss: 230.5092
Epoch 59/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 226.3537 - val_loss: 221.7587
Epoch 60/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 225.9994 - val_loss: 220.0711
Epoch 61/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 225.6200 - val_loss: 220.7452
Epoch 62/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 225.3396 - val_loss: 222.2546
Epoch 63/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 225.4745 - val_loss: 222.3221
Epoch 64/65
9445953/9445953 [==============================] - 37s 4us/step - loss: 225.1995 - val_loss: 221.9400
Epoch 65/65                                                                                                                                                                                                        9445953/9445953 [==============================] - 37s 4us/step - loss: 225.7962 - val_loss: 224.6318

         CHILD ACCURACY = 220.12175746947514


         PARENT ACCURACY = 206.56094494221642



 QUEUE SIZE BEFORE GET = 2


 NODE SELECTED <<<------ Epochs = 45 -------- BatchSize = 10500--------- Accuracy = 211.74131495095924 -------->>>


 CHILD 1 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 12000

         EPOCHS = 40
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/40
2018-07-18 15:04:20.189986: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 15:04:20.194591: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 323.5545 - val_loss: 310.0046
Epoch 2/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 299.6291 - val_loss: 298.0767
Epoch 3/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 285.6312 - val_loss: 284.5750
Epoch 4/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 280.6674 - val_loss: 280.1023
Epoch 5/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 278.7496 - val_loss: 284.2219
Epoch 6/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.8567 - val_loss: 273.2396
Epoch 7/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 275.2977 - val_loss: 283.3381
Epoch 8/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 274.2854 - val_loss: 273.8536
Epoch 9/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 273.4868 - val_loss: 272.7079
Epoch 10/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 273.0272 - val_loss: 273.9351
Epoch 11/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 272.4549 - val_loss: 273.5223
Epoch 12/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 272.0500 - val_loss: 270.2805
Epoch 13/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 271.6490 - val_loss: 275.1950
Epoch 14/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 271.2845 - val_loss: 269.2007
Epoch 15/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 271.0608 - val_loss: 270.7015
Epoch 16/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 270.8224 - val_loss: 271.9381
Epoch 17/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 270.6252 - val_loss: 268.3713
Epoch 18/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 270.4427 - val_loss: 272.3813
Epoch 19/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 270.2390 - val_loss: 270.6326
Epoch 20/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 270.1006 - val_loss: 268.9511
Epoch 21/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 270.0012 - val_loss: 270.9042
Epoch 22/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 269.8152 - val_loss: 271.1281
Epoch 23/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 269.7310 - val_loss: 271.9794
Epoch 24/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 269.6472 - val_loss: 267.5906
Epoch 25/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 269.4609 - val_loss: 267.8385
Epoch 26/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 269.4809 - val_loss: 269.1857
Epoch 27/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 269.4234 - val_loss: 267.4389
Epoch 28/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 269.2157 - val_loss: 270.9198
Epoch 29/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 269.2121 - val_loss: 268.0937
Epoch 30/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 269.0960 - val_loss: 268.8193
Epoch 31/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 269.0428 - val_loss: 268.0300
Epoch 32/40                                                                                                                                                                                                        9445953/9445953 [==============================] - 33s 4us/step - loss: 268.9183 - val_loss: 271.6124
Epoch 33/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 268.8523 - val_loss: 268.1387
Epoch 34/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 268.7856 - val_loss: 266.9638
Epoch 35/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 268.7184 - val_loss: 267.7803
Epoch 36/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 268.6577 - val_loss: 267.2340
Epoch 37/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 268.5752 - val_loss: 269.7431
Epoch 38/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 268.5546 - val_loss: 267.3033
Epoch 39/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 268.4978 - val_loss: 266.3548
Epoch 40/40
9445953/9445953 [==============================] - 33s 4us/step - loss: 268.4034 - val_loss: 267.9740

         CHILD ACCURACY = 267.1798154526723


         PARENT ACCURACY = 211.74131495095924


 CHILD 2 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 10500

         EPOCHS = 50
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/50
2018-07-18 15:26:31.618770: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 15:26:31.624461: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 320.7235 - val_loss: 294.7515
Epoch 2/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 291.9687 - val_loss: 290.3565
Epoch 3/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 281.3828 - val_loss: 281.5743
Epoch 4/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 277.4668 - val_loss: 273.4622
Epoch 5/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 275.3775 - val_loss: 274.0613
Epoch 6/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 274.1365 - val_loss: 270.7048
Epoch 7/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 273.2151 - val_loss: 273.8222
Epoch 8/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 272.0432 - val_loss: 268.3550
Epoch 9/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 269.6262 - val_loss: 265.7759
Epoch 10/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 265.3138 - val_loss: 261.3778
Epoch 11/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 261.0813 - val_loss: 256.9332
Epoch 12/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 257.4849 - val_loss: 251.7450
Epoch 13/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 254.2836 - val_loss: 246.3513
Epoch 14/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 251.8722 - val_loss: 247.4293
Epoch 15/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 249.7644 - val_loss: 244.4066
Epoch 16/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 247.8269 - val_loss: 240.8779
Epoch 17/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 246.1456 - val_loss: 241.1258
Epoch 18/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 244.4691 - val_loss: 241.3643
Epoch 19/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 242.9073 - val_loss: 237.2682
Epoch 20/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 241.5206 - val_loss: 236.7823
Epoch 21/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 240.0827 - val_loss: 234.5648
Epoch 22/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 238.6471 - val_loss: 233.8027
Epoch 23/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 237.2274 - val_loss: 234.7428
Epoch 24/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 235.9151 - val_loss: 230.1567
Epoch 25/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 234.6368 - val_loss: 228.3946
Epoch 26/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 233.6420 - val_loss: 228.0099
Epoch 27/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 232.6676 - val_loss: 231.9020
Epoch 28/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 231.7956 - val_loss: 223.3961
Epoch 29/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 230.8423 - val_loss: 225.6503
Epoch 30/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 230.1121 - val_loss: 235.0295
Epoch 31/50                                                                                                                                                                                                        9445953/9445953 [==============================] - 34s 4us/step - loss: 229.4551 - val_loss: 231.8745
Epoch 32/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 228.7925 - val_loss: 230.5301
Epoch 33/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.9957 - val_loss: 221.1570
Epoch 34/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.4582 - val_loss: 233.0079
Epoch 35/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.9398 - val_loss: 222.7468
Epoch 36/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.4134 - val_loss: 227.3464
Epoch 37/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 225.9312 - val_loss: 216.4201
Epoch 38/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 225.3934 - val_loss: 217.1579
Epoch 39/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.8970 - val_loss: 223.3183
Epoch 40/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.4157 - val_loss: 215.4716
Epoch 41/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 223.8091 - val_loss: 214.3807
Epoch 42/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 223.6214 - val_loss: 228.7960
Epoch 43/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 223.3440 - val_loss: 222.6642
Epoch 44/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 223.0117 - val_loss: 215.0296
Epoch 45/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 222.5893 - val_loss: 215.8248
Epoch 46/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 222.1416 - val_loss: 214.6395
Epoch 47/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 221.8292 - val_loss: 220.8487
Epoch 48/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 221.6467 - val_loss: 217.7631
Epoch 49/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 221.3407 - val_loss: 213.4566
Epoch 50/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 220.9599 - val_loss: 214.9476

         CHILD ACCURACY = 212.06388263246856


         PARENT ACCURACY = 211.74131495095924


 CHILD 3 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 9000

         EPOCHS = 40
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/40
2018-07-18 15:54:58.525574: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 15:54:58.529570: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 36s 4us/step - loss: 307.6667 - val_loss: 280.3161
Epoch 2/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 279.7747 - val_loss: 273.7556
Epoch 3/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 275.1202 - val_loss: 270.6957
Epoch 4/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 272.5543 - val_loss: 269.3743
Epoch 5/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 268.2927 - val_loss: 260.6326
Epoch 6/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 262.9422 - val_loss: 254.9353
Epoch 7/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 258.9344 - val_loss: 259.2884
Epoch 8/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 255.3679 - val_loss: 249.4503
Epoch 9/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 252.7052 - val_loss: 245.9545
Epoch 10/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 250.3058 - val_loss: 244.9518
Epoch 11/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 248.3933 - val_loss: 240.7955
Epoch 12/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 246.3987 - val_loss: 241.8219
Epoch 13/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 244.7565 - val_loss: 239.3151
Epoch 14/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 243.1896 - val_loss: 238.9401
Epoch 15/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 241.5937 - val_loss: 237.8807
Epoch 16/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 240.5389 - val_loss: 235.1314                                                                                                              Epoch 17/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 238.9397 - val_loss: 236.8677
Epoch 18/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 237.9091 - val_loss: 242.1437
Epoch 19/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 236.8855 - val_loss: 237.6098
Epoch 20/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 235.6860 - val_loss: 236.1494
Epoch 21/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 234.7431 - val_loss: 231.3185
Epoch 22/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 233.7984 - val_loss: 225.1359
Epoch 23/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 233.0166 - val_loss: 226.4162
Epoch 24/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 232.1653 - val_loss: 226.9675
Epoch 25/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 231.3080 - val_loss: 229.1861
Epoch 26/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.9546 - val_loss: 225.1427
Epoch 27/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 229.9486 - val_loss: 222.3275
Epoch 28/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 229.4742 - val_loss: 221.7959
Epoch 29/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 228.9095 - val_loss: 220.2932
Epoch 30/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 228.3457 - val_loss: 229.6587
Epoch 31/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 227.7550 - val_loss: 220.2180
Epoch 32/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 227.3038 - val_loss: 221.7683
Epoch 33/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 227.0466 - val_loss: 225.6498
Epoch 34/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 226.3293 - val_loss: 218.9826
Epoch 35/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 225.8467 - val_loss: 231.7987
Epoch 36/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 225.6128 - val_loss: 217.9092
Epoch 37/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 225.2043 - val_loss: 219.0331
Epoch 38/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 224.7528 - val_loss: 217.8269
Epoch 39/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 224.6490 - val_loss: 225.9592
Epoch 40/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 224.2814 - val_loss: 217.1841

         CHILD ACCURACY = 215.27972987884186


         PARENT ACCURACY = 211.74131495095924


 CHILD 4 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 12000

         EPOCHS = 45
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-07-18 16:18:46.708010: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 16:18:46.713710: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 326.8579 - val_loss: 328.5931
Epoch 2/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 311.7083 - val_loss: 286.7144
Epoch 3/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 288.0983 - val_loss: 281.0311
Epoch 4/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 282.2343 - val_loss: 281.7037
Epoch 5/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 279.0034 - val_loss: 276.6415
Epoch 6/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 277.2837 - val_loss: 274.3064
Epoch 7/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 275.7245 - val_loss: 278.5367
Epoch 8/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 274.3366 - val_loss: 275.3270
Epoch 9/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 273.2059 - val_loss: 281.8849
Epoch 10/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 271.7229 - val_loss: 277.1142
Epoch 11/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 269.5146 - val_loss: 269.4531
Epoch 12/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 264.6713 - val_loss: 266.2688
Epoch 13/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 260.6302 - val_loss: 267.2988
Epoch 14/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 257.5002 - val_loss: 265.7144
Epoch 15/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 254.5738 - val_loss: 249.3113
Epoch 16/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 251.9597 - val_loss: 251.4852
Epoch 17/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 249.4375 - val_loss: 244.0580                                                                                                              Epoch 18/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 247.2400 - val_loss: 240.1355
Epoch 19/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 245.1992 - val_loss: 241.5072
Epoch 20/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 243.5733 - val_loss: 236.1391
Epoch 21/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 241.8678 - val_loss: 236.3182
Epoch 22/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 240.4050 - val_loss: 236.5250
Epoch 23/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 239.0141 - val_loss: 240.6590
Epoch 24/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 237.8794 - val_loss: 238.6658
Epoch 25/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 236.9398 - val_loss: 231.6998
Epoch 26/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 235.6729 - val_loss: 238.8587
Epoch 27/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 234.9436 - val_loss: 239.1561
Epoch 28/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 234.0192 - val_loss: 233.9528
Epoch 29/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 233.3016 - val_loss: 227.1808
Epoch 30/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 232.6548 - val_loss: 228.2742
Epoch 31/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 231.7647 - val_loss: 229.9025
Epoch 32/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 231.2831 - val_loss: 239.8175
Epoch 33/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 230.8023 - val_loss: 243.1877
Epoch 34/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 230.2049 - val_loss: 228.1293
Epoch 35/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 229.7027 - val_loss: 232.7921
Epoch 36/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 229.1964 - val_loss: 223.3200
Epoch 37/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 228.7878 - val_loss: 223.4004
Epoch 38/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 228.1804 - val_loss: 240.8290
Epoch 39/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 228.0138 - val_loss: 244.0802
Epoch 40/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 227.6674 - val_loss: 222.8376
Epoch 41/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 227.1513 - val_loss: 223.7532
Epoch 42/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 226.8111 - val_loss: 219.7055
Epoch 43/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 226.3121 - val_loss: 240.1627
Epoch 44/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 226.1017 - val_loss: 246.4952
Epoch 45/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 225.6088 - val_loss: 223.3785

         CHILD ACCURACY = 238.66253659459787


         PARENT ACCURACY = 211.74131495095924


 CHILD 5 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 10500

         EPOCHS = 40
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/40
2018-07-18 16:44:01.887059: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 16:44:01.893441: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 35s 4us/step - loss: 321.6719 - val_loss: 291.5346
Epoch 2/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 286.9751 - val_loss: 285.3086
Epoch 3/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 277.4516 - val_loss: 272.6820
Epoch 4/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 272.7523 - val_loss: 266.6055
Epoch 5/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 268.2996 - val_loss: 270.6540
Epoch 6/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 264.0876 - val_loss: 257.7011
Epoch 7/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 260.6670 - val_loss: 258.8698
Epoch 8/40                                                                                                                                                                                                         9445953/9445953 [==============================] - 34s 4us/step - loss: 257.7962 - val_loss: 252.3639
Epoch 9/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 255.3585 - val_loss: 254.3601
Epoch 10/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 253.0233 - val_loss: 253.5843
Epoch 11/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 250.7443 - val_loss: 245.2958
Epoch 12/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 248.7739 - val_loss: 242.1430
Epoch 13/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 246.8271 - val_loss: 242.3099
Epoch 14/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 245.1484 - val_loss: 243.2451
Epoch 15/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 243.5926 - val_loss: 240.2914
Epoch 16/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 241.9909 - val_loss: 239.7635
Epoch 17/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 240.3128 - val_loss: 233.4920
Epoch 18/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 238.9056 - val_loss: 236.3955
Epoch 19/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 237.4193 - val_loss: 231.2524
Epoch 20/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 236.0550 - val_loss: 232.5826
Epoch 21/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 234.8966 - val_loss: 227.0294
Epoch 22/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 233.7035 - val_loss: 226.8363
Epoch 23/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 232.7051 - val_loss: 224.9320
Epoch 24/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 231.7234 - val_loss: 225.2193
Epoch 25/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.9535 - val_loss: 225.1330
Epoch 26/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.0563 - val_loss: 225.2882
Epoch 27/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 229.4568 - val_loss: 222.0733
Epoch 28/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 228.7946 - val_loss: 229.7630
Epoch 29/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 228.0560 - val_loss: 229.0802
Epoch 30/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 227.5806 - val_loss: 224.0788
Epoch 31/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.9969 - val_loss: 221.1183
Epoch 32/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 226.6052 - val_loss: 217.6023
Epoch 33/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.0350 - val_loss: 226.0120
Epoch 34/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.4997 - val_loss: 217.9552
Epoch 35/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.3134 - val_loss: 219.2861
Epoch 36/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.6002 - val_loss: 229.0307
Epoch 37/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.2479 - val_loss: 216.4710
Epoch 38/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 224.0125 - val_loss: 224.6927
Epoch 39/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 223.3876 - val_loss: 218.0693
Epoch 40/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 223.1741 - val_loss: 215.8826

         CHILD ACCURACY = 213.85220170725324


         PARENT ACCURACY = 211.74131495095924



 QUEUE SIZE BEFORE GET = 1


 NODE SELECTED <<<------ Epochs = 50 -------- BatchSize = 10500--------- Accuracy = 212.1617828397996 -------->>>


 CHILD 1 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 9000

         EPOCHS = 50
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/50
2018-07-18 17:07:02.594901: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 17:07:02.600737: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 36s 4us/step - loss: 324.9887 - val_loss: 312.6985
Epoch 2/50
9445953/9445953 [==============================] - 36s 4us/step - loss: 308.9675 - val_loss: 291.2020
Epoch 3/50
9445953/9445953 [==============================] - 36s 4us/step - loss: 290.2161 - val_loss: 287.3898
Epoch 4/50
9445953/9445953 [==============================] - 36s 4us/step - loss: 282.6168 - val_loss: 277.4465
Epoch 5/50                                                                                                                                                                                                         9445953/9445953 [==============================] - 34s 4us/step - loss: 279.2649 - val_loss: 275.2895
Epoch 6/50
9445953/9445953 [==============================] - 34s 4us/step - loss: 277.9739 - val_loss: 274.3171
Epoch 7/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 276.9696 - val_loss: 273.5364
Epoch 8/50
9445953/9445953 [==============================] - 36s 4us/step - loss: 274.9121 - val_loss: 270.5501
Epoch 9/50
9445953/9445953 [==============================] - 36s 4us/step - loss: 271.1372 - val_loss: 266.2520
Epoch 10/50
9445953/9445953 [==============================] - 36s 4us/step - loss: 267.8430 - val_loss: 262.6551
Epoch 11/50
9445953/9445953 [==============================] - 37s 4us/step - loss: 265.5597 - val_loss: 260.2100
Epoch 12/50
9445953/9445953 [==============================] - 36s 4us/step - loss: 264.0717 - val_loss: 260.5757
Epoch 13/50
9445953/9445953 [==============================] - 36s 4us/step - loss: 262.8309 - val_loss: 260.2723
Epoch 14/50
9445953/9445953 [==============================] - 36s 4us/step - loss: 261.5877 - val_loss: 257.1792
Epoch 15/50
9445953/9445953 [==============================] - 36s 4us/step - loss: 260.5024 - val_loss: 256.2447
Epoch 16/50
9445953/9445953 [==============================] - 36s 4us/step - loss: 259.5507 - val_loss: 254.5837
Epoch 17/50
9445953/9445953 [==============================] - 36s 4us/step - loss: 258.7415 - val_loss: 255.7209
Epoch 18/50
9445953/9445953 [==============================] - 36s 4us/step - loss: 257.9212 - val_loss: 253.7511
Epoch 19/50
9445953/9445953 [==============================] - 36s 4us/step - loss: 257.1752 - val_loss: 253.1994
Epoch 20/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 256.6098 - val_loss: 255.9205
Epoch 21/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 255.9467 - val_loss: 256.0316
Epoch 22/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 255.4310 - val_loss: 259.2204
Epoch 23/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 254.9295 - val_loss: 250.8394
Epoch 24/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 254.4345 - val_loss: 251.4199
Epoch 25/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 253.9960 - val_loss: 252.6660
Epoch 26/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 253.5968 - val_loss: 252.3553
Epoch 27/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 253.1649 - val_loss: 250.2294
Epoch 28/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 252.9272 - val_loss: 251.0330
Epoch 29/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 252.6311 - val_loss: 249.9270
Epoch 30/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 252.2506 - val_loss: 247.8922
Epoch 31/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 252.0117 - val_loss: 250.1923
Epoch 32/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 251.8520 - val_loss: 247.7386
Epoch 33/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 251.5222 - val_loss: 252.0120
Epoch 34/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 251.2727 - val_loss: 247.8706
Epoch 35/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 251.1277 - val_loss: 247.6957
Epoch 36/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 250.8364 - val_loss: 246.5974
Epoch 37/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 250.7983 - val_loss: 246.9792
Epoch 38/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 250.4685 - val_loss: 246.2944
Epoch 39/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 250.2761 - val_loss: 248.9186
Epoch 40/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 250.1224 - val_loss: 250.1368
Epoch 41/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 249.9677 - val_loss: 247.0155
Epoch 42/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 249.7181 - val_loss: 248.4819
Epoch 43/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 249.5698 - val_loss: 245.9627
Epoch 44/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 249.4215 - val_loss: 249.0010
Epoch 45/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 249.3181 - val_loss: 248.4667
Epoch 46/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 249.1442 - val_loss: 245.8919
Epoch 47/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 248.9773 - val_loss: 246.7346
Epoch 48/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 248.9011 - val_loss: 244.0736                                                                                                              Epoch 49/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 248.6010 - val_loss: 249.6521
Epoch 50/50
9445953/9445953 [==============================] - 35s 4us/step - loss: 248.5270 - val_loss: 248.0734

         CHILD ACCURACY = 245.5152755568162


         PARENT ACCURACY = 212.1617828397996


 CHILD 2 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 10500

         EPOCHS = 45
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-07-18 17:36:38.077904: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 17:36:38.083697: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 35s 4us/step - loss: 320.2293 - val_loss: 307.6703
Epoch 2/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 297.4523 - val_loss: 288.3458
Epoch 3/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 278.8787 - val_loss: 273.8064
Epoch 4/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 275.5992 - val_loss: 270.7636
Epoch 5/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 273.9729 - val_loss: 272.2516
Epoch 6/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 272.9866 - val_loss: 270.2556
Epoch 7/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 272.3253 - val_loss: 269.8342
Epoch 8/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 271.7713 - val_loss: 269.1194
Epoch 9/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 271.3771 - val_loss: 268.7589
Epoch 10/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 271.0144 - val_loss: 267.8936
Epoch 11/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 270.6929 - val_loss: 268.6135
Epoch 12/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 270.3566 - val_loss: 269.4566
Epoch 13/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 270.0724 - val_loss: 269.5712
Epoch 14/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 269.8157 - val_loss: 267.3331
Epoch 15/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 269.5563 - val_loss: 268.0180
Epoch 16/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 269.3697 - val_loss: 267.7373
Epoch 17/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 269.1890 - val_loss: 267.7462
Epoch 18/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 268.9944 - val_loss: 266.1554
Epoch 19/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 268.8516 - val_loss: 266.4884
Epoch 20/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 268.6470 - val_loss: 267.4403
Epoch 21/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 268.4038 - val_loss: 265.9460
Epoch 22/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 268.2956 - val_loss: 265.8573
Epoch 23/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 268.1762 - val_loss: 268.1881
Epoch 24/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 267.9443 - val_loss: 265.7757
Epoch 25/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 267.8816 - val_loss: 265.1597
Epoch 26/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 267.7199 - val_loss: 265.2843
Epoch 27/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 267.5943 - val_loss: 265.4265
Epoch 28/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 267.4414 - val_loss: 265.1073
Epoch 29/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 267.3457 - val_loss: 265.2910
Epoch 30/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 267.1757 - val_loss: 264.9934
Epoch 31/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 267.0947 - val_loss: 264.6885
Epoch 32/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 266.9282 - val_loss: 264.6560
Epoch 33/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 266.8199 - val_loss: 264.9632
Epoch 34/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 266.6787 - val_loss: 265.1534
Epoch 35/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 266.5038 - val_loss: 266.0544
Epoch 36/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 266.2500 - val_loss: 264.7529
Epoch 37/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 266.1148 - val_loss: 263.7280
Epoch 38/45                                                                                                                                                                                                        9445953/9445953 [==============================] - 34s 4us/step - loss: 265.8581 - val_loss: 263.3114
Epoch 39/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 265.4727 - val_loss: 263.0851
Epoch 40/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 264.9542 - val_loss: 262.0451
Epoch 41/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 264.0594 - val_loss: 262.0024
Epoch 42/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 258.7768 - val_loss: 252.9221
Epoch 43/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 253.0222 - val_loss: 246.0399
Epoch 44/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 249.0057 - val_loss: 243.3932
Epoch 45/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 246.1745 - val_loss: 241.2674

         CHILD ACCURACY = 240.06649125626248


         PARENT ACCURACY = 212.1617828397996


 CHILD 3 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 12000

         EPOCHS = 45
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-07-18 18:02:14.666567: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 18:02:14.672228: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 34s 4us/step - loss: 329.4260 - val_loss: 312.2406
Epoch 2/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 306.2051 - val_loss: 290.9454
Epoch 3/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 289.8744 - val_loss: 285.3739
Epoch 4/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 287.0660 - val_loss: 283.9724
Epoch 5/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 285.9002 - val_loss: 284.5357
Epoch 6/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 285.1009 - val_loss: 291.1762
Epoch 7/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 284.4362 - val_loss: 286.5818
Epoch 8/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 283.3776 - val_loss: 282.9612
Epoch 9/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 282.8408 - val_loss: 280.6766
Epoch 10/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 282.1345 - val_loss: 281.6934
Epoch 11/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 281.3887 - val_loss: 279.8665
Epoch 12/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 279.6940 - val_loss: 280.5902
Epoch 13/45
9445953/9445953 [==============================] - 34s 4us/step - loss: 277.9122 - val_loss: 276.8791
Epoch 14/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 277.5646 - val_loss: 275.6235
Epoch 15/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 277.3351 - val_loss: 274.8067
Epoch 16/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 277.1904 - val_loss: 276.0101
Epoch 17/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 277.0977 - val_loss: 275.3238
Epoch 18/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 277.0020 - val_loss: 274.5364
Epoch 19/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.9269 - val_loss: 274.7765
Epoch 20/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.8604 - val_loss: 274.3068
Epoch 21/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.8000 - val_loss: 274.5318
Epoch 22/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.7341 - val_loss: 274.4636
Epoch 23/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.6859 - val_loss: 274.4766
Epoch 24/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.6681 - val_loss: 274.8011
Epoch 25/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.6009 - val_loss: 274.8126
Epoch 26/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.5641 - val_loss: 275.3681
Epoch 27/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.5229 - val_loss: 275.4702
Epoch 28/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.5042 - val_loss: 274.5815                                                                                                              Epoch 29/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.4506 - val_loss: 276.4814
Epoch 30/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.4105 - val_loss: 274.7115
Epoch 31/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.4068 - val_loss: 275.2469
Epoch 32/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.3508 - val_loss: 274.9244
Epoch 33/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.3224 - val_loss: 276.8654
Epoch 34/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.2792 - val_loss: 273.9182
Epoch 35/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.2474 - val_loss: 275.4272
Epoch 36/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.2357 - val_loss: 275.9713
Epoch 37/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.2218 - val_loss: 274.0634
Epoch 38/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.1307 - val_loss: 275.8016
Epoch 39/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.1213 - val_loss: 274.4503
Epoch 40/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.0885 - val_loss: 275.0815
Epoch 41/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.0827 - val_loss: 274.0679
Epoch 42/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.0069 - val_loss: 274.9007
Epoch 43/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 276.0156 - val_loss: 274.3515
Epoch 44/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 275.9656 - val_loss: 274.0988
Epoch 45/45
9445953/9445953 [==============================] - 33s 4us/step - loss: 275.9213 - val_loss: 273.8343

         CHILD ACCURACY = 272.615300549543


         PARENT ACCURACY = 212.1617828397996


 CHILD 4 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 9000

         EPOCHS = 45
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-07-18 18:27:19.931939: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 18:27:19.936318: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 36s 4us/step - loss: 322.8826 - val_loss: 304.5822
Epoch 2/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 303.7351 - val_loss: 288.4859
Epoch 3/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 280.7944 - val_loss: 276.0215
Epoch 4/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 276.8088 - val_loss: 282.9080
Epoch 5/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 274.7427 - val_loss: 275.7016
Epoch 6/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 273.0497 - val_loss: 274.2547
Epoch 7/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 271.3452 - val_loss: 269.6093
Epoch 8/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 267.5152 - val_loss: 264.6085
Epoch 9/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 262.5684 - val_loss: 264.6266
Epoch 10/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 258.8084 - val_loss: 254.1723
Epoch 11/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 255.5517 - val_loss: 250.6771
Epoch 12/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 252.7332 - val_loss: 251.4791
Epoch 13/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 250.2897 - val_loss: 246.1627
Epoch 14/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 247.9132 - val_loss: 242.0007
Epoch 15/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 245.8909 - val_loss: 240.2763
Epoch 16/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 243.9863 - val_loss: 240.8018
Epoch 17/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 242.2180 - val_loss: 240.1912
Epoch 18/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 240.4573 - val_loss: 240.7293
Epoch 19/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 239.1046 - val_loss: 232.8155
Epoch 20/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 237.7182 - val_loss: 231.7640
Epoch 21/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 236.6233 - val_loss: 228.4001
Epoch 22/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 235.3778 - val_loss: 241.2839                                                                                                              Epoch 23/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 234.4264 - val_loss: 232.1431
Epoch 24/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 233.3527 - val_loss: 227.0939
Epoch 25/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 232.5670 - val_loss: 227.2583
Epoch 26/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 231.7100 - val_loss: 225.9359
Epoch 27/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.9242 - val_loss: 222.2031
Epoch 28/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 230.3143 - val_loss: 226.5411
Epoch 29/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 229.5821 - val_loss: 223.0133
Epoch 30/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.9777 - val_loss: 218.9493
Epoch 31/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 228.3400 - val_loss: 227.0832
Epoch 32/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.7674 - val_loss: 230.8858
Epoch 33/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.4526 - val_loss: 218.7279
Epoch 34/45
9445953/9445953 [==============================] - 36s 4us/step - loss: 226.7479 - val_loss: 217.6213
Epoch 35/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.3220 - val_loss: 218.7465
Epoch 36/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.8759 - val_loss: 218.7441
Epoch 37/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.4552 - val_loss: 221.5996
Epoch 38/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.0214 - val_loss: 218.7904
Epoch 39/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.6228 - val_loss: 216.1746
Epoch 40/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.2436 - val_loss: 213.7241
Epoch 41/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.2343 - val_loss: 217.9229
Epoch 42/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 223.6288 - val_loss: 217.7064
Epoch 43/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 223.1166 - val_loss: 217.6115
Epoch 44/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 222.9862 - val_loss: 217.4806
Epoch 45/45
9445953/9445953 [==============================] - 35s 4us/step - loss: 222.6572 - val_loss: 215.7506

         CHILD ACCURACY = 211.17729297032733


         PARENT ACCURACY = 212.1617828397996


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 1 <<<<<<<<<<<<<<<<<<<<<<<<<<<



 QUEUE SIZE BEFORE GET = 1


 NODE SELECTED <<<------ Epochs = 45 -------- BatchSize = 9000--------- Accuracy = 211.17729297032733 -------->>>


 CHILD 1 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 10500

         EPOCHS = 40
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/40
2018-07-18 18:53:53.163493: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 18:53:53.170475: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 35s 4us/step - loss: 324.3399 - val_loss: 307.3301
Epoch 2/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 299.0415 - val_loss: 285.7818
Epoch 3/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 284.9635 - val_loss: 280.8310
Epoch 4/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 280.6681 - val_loss: 276.7322
Epoch 5/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 278.1777 - val_loss: 273.9709                                                                                                              Epoch 6/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 274.8553 - val_loss: 270.0014
Epoch 7/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 271.6199 - val_loss: 268.3896
Epoch 8/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 268.8357 - val_loss: 263.4815
Epoch 9/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 266.8398 - val_loss: 264.9854
Epoch 10/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 265.1191 - val_loss: 262.5936
Epoch 11/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 263.8610 - val_loss: 260.4898
Epoch 12/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 262.6978 - val_loss: 259.5072
Epoch 13/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 261.7514 - val_loss: 259.1699
Epoch 14/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 260.6091 - val_loss: 257.7618
Epoch 15/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 259.7722 - val_loss: 255.5251
Epoch 16/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 258.9314 - val_loss: 255.4893
Epoch 17/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 258.1284 - val_loss: 254.9030
Epoch 18/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 257.3287 - val_loss: 252.6879
Epoch 19/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 256.4598 - val_loss: 253.7041
Epoch 20/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 255.6403 - val_loss: 252.8691
Epoch 21/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 254.8462 - val_loss: 253.3221
Epoch 22/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 254.1493 - val_loss: 251.0265
Epoch 23/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 253.4715 - val_loss: 250.0503
Epoch 24/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 252.7884 - val_loss: 254.7868
Epoch 25/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 252.1244 - val_loss: 248.7647
Epoch 26/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 251.7182 - val_loss: 248.9560
Epoch 27/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 251.1769 - val_loss: 248.6470
Epoch 28/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 250.6692 - val_loss: 248.9985
Epoch 29/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 250.2015 - val_loss: 246.8112
Epoch 30/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 249.7810 - val_loss: 249.5105
Epoch 31/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 249.4321 - val_loss: 248.1381
Epoch 32/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 249.0211 - val_loss: 247.6399
Epoch 33/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 248.6306 - val_loss: 245.2276
Epoch 34/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 248.2786 - val_loss: 244.5032
Epoch 35/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 247.9874 - val_loss: 247.7431
Epoch 36/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 247.7129 - val_loss: 245.4585
Epoch 37/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 247.2885 - val_loss: 246.2090
Epoch 38/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 246.8817 - val_loss: 242.6693
Epoch 39/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 246.4349 - val_loss: 243.9328
Epoch 40/40
9445953/9445953 [==============================] - 34s 4us/step - loss: 245.7594 - val_loss: 245.6794

         CHILD ACCURACY = 242.65412500819892


         PARENT ACCURACY = 211.17729297032733


 CHILD 2 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7500

         EPOCHS = 45
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-07-18 19:16:44.323800: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 19:16:44.330712: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 38s 4us/step - loss: 307.7060 - val_loss: 293.7519
Epoch 2/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 282.8756 - val_loss: 284.6995                                                                                                              Epoch 3/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 276.9615 - val_loss: 275.4999
Epoch 4/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 274.6355 - val_loss: 280.9994
Epoch 5/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 273.1018 - val_loss: 273.9925
Epoch 6/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 272.1181 - val_loss: 272.7964
Epoch 7/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 271.0293 - val_loss: 272.0219
Epoch 8/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 268.7534 - val_loss: 267.7541
Epoch 9/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 264.3585 - val_loss: 269.5012
Epoch 10/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 259.4082 - val_loss: 255.2386
Epoch 11/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 255.4242 - val_loss: 251.1856
Epoch 12/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 252.2257 - val_loss: 250.9260
Epoch 13/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 249.4935 - val_loss: 248.4834
Epoch 14/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 247.1019 - val_loss: 244.1574
Epoch 15/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 245.2390 - val_loss: 242.3912
Epoch 16/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 243.1688 - val_loss: 247.0148
Epoch 17/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 241.6722 - val_loss: 237.2471
Epoch 18/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 240.1717 - val_loss: 240.6561
Epoch 19/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 238.8234 - val_loss: 232.6714
Epoch 20/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 237.5375 - val_loss: 233.5903
Epoch 21/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 236.5193 - val_loss: 233.6591
Epoch 22/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 235.5651 - val_loss: 229.4076
Epoch 23/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 234.4318 - val_loss: 229.3312
Epoch 24/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 233.6487 - val_loss: 227.2255
Epoch 25/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 232.6633 - val_loss: 232.2326
Epoch 26/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 231.9606 - val_loss: 225.8771
Epoch 27/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 231.2605 - val_loss: 244.2950
Epoch 28/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 230.5560 - val_loss: 223.2098
Epoch 29/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 229.8199 - val_loss: 222.3848
Epoch 30/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 229.3215 - val_loss: 221.1770
Epoch 31/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 228.5766 - val_loss: 221.9715
Epoch 32/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 228.0334 - val_loss: 226.6295
Epoch 33/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 227.3674 - val_loss: 240.2781
Epoch 34/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 227.0239 - val_loss: 220.3312
Epoch 35/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 226.4002 - val_loss: 234.4791
Epoch 36/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 226.0048 - val_loss: 219.1144
Epoch 37/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 225.5103 - val_loss: 221.0717
Epoch 38/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 225.1161 - val_loss: 228.7005
Epoch 39/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 224.6615 - val_loss: 220.9385
Epoch 40/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 224.3872 - val_loss: 219.1528
Epoch 41/45
9445953/9445953 [==============================] - 42s 4us/step - loss: 223.9432 - val_loss: 217.1741
Epoch 42/45
9445953/9445953 [==============================] - 38s 4us/step - loss: 223.3900 - val_loss: 214.3438
Epoch 43/45
9445953/9445953 [==============================] - 38s 4us/step - loss: 223.1592 - val_loss: 223.1122
Epoch 44/45
9445953/9445953 [==============================] - 38s 4us/step - loss: 222.9139 - val_loss: 218.9999
Epoch 45/45
9445953/9445953 [==============================] - 37s 4us/step - loss: 222.2763 - val_loss: 218.7502

         CHILD ACCURACY = 214.66818805433925


         PARENT ACCURACY = 211.17729297032733


 CHILD 3 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 9000

         EPOCHS = 40
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/40
2018-07-18 19:44:45.720184: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 19:44:45.726443: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 36s 4us/step - loss: 308.1928 - val_loss: 284.4144
Epoch 2/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 282.4426 - val_loss: 275.7065
Epoch 3/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 277.5499 - val_loss: 273.6016
Epoch 4/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 275.5596 - val_loss: 273.8247
Epoch 5/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 274.2472 - val_loss: 273.8731
Epoch 6/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 273.3359 - val_loss: 270.7968
Epoch 7/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 272.4410 - val_loss: 271.5512
Epoch 8/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 269.4861 - val_loss: 266.2916
Epoch 9/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 264.1519 - val_loss: 260.0809
Epoch 10/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 258.9966 - val_loss: 255.7660
Epoch 11/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 254.8131 - val_loss: 249.0786
Epoch 12/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 251.6390 - val_loss: 247.1269
Epoch 13/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 249.2111 - val_loss: 244.7959
Epoch 14/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 247.1222 - val_loss: 242.5216
Epoch 15/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 245.3434 - val_loss: 239.1148
Epoch 16/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 243.8334 - val_loss: 237.1134
Epoch 17/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 242.1436 - val_loss: 240.0163
Epoch 18/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 240.7265 - val_loss: 238.6051
Epoch 19/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 239.3456 - val_loss: 241.9166
Epoch 20/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 238.0957 - val_loss: 235.4941
Epoch 21/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 236.8423 - val_loss: 232.3996
Epoch 22/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 235.7888 - val_loss: 233.2067
Epoch 23/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 234.7596 - val_loss: 229.1525
Epoch 24/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 233.7093 - val_loss: 231.2871
Epoch 25/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 232.9667 - val_loss: 230.6760
Epoch 26/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 232.1280 - val_loss: 223.3789
Epoch 27/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 231.4120 - val_loss: 227.7029
Epoch 28/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 230.5374 - val_loss: 222.8549
Epoch 29/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 229.9100 - val_loss: 222.8341
Epoch 30/40
9445953/9445953 [==============================] - 38s 4us/step - loss: 229.2280 - val_loss: 221.7075
Epoch 31/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 228.8038 - val_loss: 225.9728
Epoch 32/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 228.1992 - val_loss: 226.7181
Epoch 33/40
9445953/9445953 [==============================] - 36s 4us/step - loss: 227.4532 - val_loss: 220.3673
Epoch 34/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 227.0579 - val_loss: 222.8459
Epoch 35/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.5297 - val_loss: 222.1928
Epoch 36/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 226.2267 - val_loss: 226.4730
Epoch 37/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.6517 - val_loss: 223.2303
Epoch 38/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 225.0442 - val_loss: 221.2836
Epoch 39/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.7829 - val_loss: 218.2815
Epoch 40/40
9445953/9445953 [==============================] - 35s 4us/step - loss: 224.4191 - val_loss: 216.9285

         CHILD ACCURACY = 214.8874583874089


         PARENT ACCURACY = 211.17729297032733


 CHILD 4 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7500

         EPOCHS = 40
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/40
2018-07-18 20:08:46.050769: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-18 20:08:46.055787: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 37s 4us/step - loss: 319.9649 - val_loss: 300.5355
Epoch 2/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 287.4553 - val_loss: 275.9154
Epoch 3/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 277.2058 - val_loss: 272.4654
Epoch 4/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 274.5464 - val_loss: 272.3824
Epoch 5/40
9445953/9445953 [==============================] - 38s 4us/step - loss: 271.7963 - val_loss: 268.5275
Epoch 6/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 267.4248 - val_loss: 260.6361
Epoch 7/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 262.4330 - val_loss: 256.2350
Epoch 8/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 258.4190 - val_loss: 253.6512
Epoch 9/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 255.4011 - val_loss: 250.9345
Epoch 10/40
9445953/9445953 [==============================] - 38s 4us/step - loss: 252.8106 - val_loss: 249.2172
Epoch 11/40
9445953/9445953 [==============================] - 40s 4us/step - loss: 250.5682 - val_loss: 245.1287
Epoch 12/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 248.4807 - val_loss: 245.5355
Epoch 13/40
9445953/9445953 [==============================] - 38s 4us/step - loss: 246.8441 - val_loss: 244.5276
Epoch 14/40
9445953/9445953 [==============================] - 38s 4us/step - loss: 244.9174 - val_loss: 244.3320
Epoch 15/40
9445953/9445953 [==============================] - 38s 4us/step - loss: 243.3543 - val_loss: 235.3311
Epoch 16/40
9445953/9445953 [==============================] - 39s 4us/step - loss: 241.8949 - val_loss: 243.3795
Epoch 17/40
9445953/9445953 [==============================] - 39s 4us/step - loss: 240.4826 - val_loss: 233.4007
Epoch 18/40
9445953/9445953 [==============================] - 38s 4us/step - loss: 239.1002 - val_loss: 240.1297
Epoch 19/40
9445953/9445953 [==============================] - 38s 4us/step - loss: 238.2011 - val_loss: 235.1050
Epoch 20/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 236.9685 - val_loss: 237.2598
Epoch 21/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 235.7829 - val_loss: 228.7746
Epoch 22/40
9445953/9445953 [==============================] - 38s 4us/step - loss: 234.8940 - val_loss: 225.9817
Epoch 23/40
9445953/9445953 [==============================] - 38s 4us/step - loss: 234.0070 - val_loss: 234.8286
Epoch 24/40
9445953/9445953 [==============================] - 38s 4us/step - loss: 233.0873 - val_loss: 238.1033
Epoch 25/40
9445953/9445953 [==============================] - 38s 4us/step - loss: 232.4428 - val_loss: 242.3408
Epoch 26/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 231.8559 - val_loss: 240.9938
Epoch 27/40
9445953/9445953 [==============================] - 38s 4us/step - loss: 232.1016 - val_loss: 223.0093
Epoch 28/40
9445953/9445953 [==============================] - 38s 4us/step - loss: 230.7141 - val_loss: 224.6563
Epoch 29/40
9445953/9445953 [==============================] - 38s 4us/step - loss: 230.0920 - val_loss: 225.0192
Epoch 30/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 229.3319 - val_loss: 225.5614
Epoch 31/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 229.0797 - val_loss: 225.4917
Epoch 32/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 228.5248 - val_loss: 220.8557
Epoch 33/40
9445953/9445953 [==============================] - 38s 4us/step - loss: 227.9736 - val_loss: 220.4893
Epoch 34/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 227.6046 - val_loss: 226.5834
Epoch 35/40
9445953/9445953 [==============================] - 40s 4us/step - loss: 227.2313 - val_loss: 224.3978
Epoch 36/40
9445953/9445953 [==============================] - 38s 4us/step - loss: 226.7295 - val_loss: 217.3346
Epoch 37/40
9445953/9445953 [==============================] - 38s 4us/step - loss: 226.5382 - val_loss: 225.6340
Epoch 38/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 226.0621 - val_loss: 223.2344
Epoch 39/40
9445953/9445953 [==============================] - 39s 4us/step - loss: 225.6562 - val_loss: 228.8848
Epoch 40/40
9445953/9445953 [==============================] - 37s 4us/step - loss: 225.4041 - val_loss: 227.0082

         CHILD ACCURACY = 226.46554898155222


         PARENT ACCURACY = 211.17729297032733


 NODES EXPLORED:
(55, 10500)
(45, 7500)
(55, 7500)
(45, 10500)
(50, 10500)
(50, 7500)
(55, 9000)
(45, 9000)
(50, 9000)
(40, 9000)
(60, 10500)
(65, 10500)
(60, 7500)
(65, 9000)
(60, 12000)
(50, 12000)
(55, 12000)
(65, 7500)
(45, 12000)
(40, 10500)



 #########################  TRAINING COMPLETED  ###############################




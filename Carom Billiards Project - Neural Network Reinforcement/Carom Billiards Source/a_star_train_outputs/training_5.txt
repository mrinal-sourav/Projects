
Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45

9445953/9445953 [==============================] - 26s 3us/step - loss: 302.0654 - val_loss: 287.6888
Epoch 2/45
9445953/9445953 [==============================] - 24s 2us/step - loss: 279.5125 - val_loss: 275.8605
Epoch 3/45
9445953/9445953 [==============================] - 24s 2us/step - loss: 276.6109 - val_loss: 274.5779
Epoch 4/45
9445953/9445953 [==============================] - 24s 3us/step - loss: 274.7869 - val_loss: 270.6514
Epoch 5/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 271.7296 - val_loss: 274.6740
Epoch 6/45
9445953/9445953 [==============================] - 24s 3us/step - loss: 266.3560 - val_loss: 270.2541
Epoch 7/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 262.5028 - val_loss: 257.3118
Epoch 8/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 259.6367 - val_loss: 256.1405
Epoch 9/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 257.3081 - val_loss: 259.4004
Epoch 10/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 255.2413 - val_loss: 253.4119
Epoch 11/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 253.4548 - val_loss: 255.4251
Epoch 12/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 251.7676 - val_loss: 248.1436
Epoch 13/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 250.3869 - val_loss: 244.3837
Epoch 14/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 249.0342 - val_loss: 240.8194
Epoch 15/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 247.7200 - val_loss: 241.8802
Epoch 16/45
9445953/9445953 [==============================] - 24s 2us/step - loss: 246.6302 - val_loss: 245.3730
Epoch 17/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 245.5211 - val_loss: 242.6358
Epoch 18/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 244.5391 - val_loss: 239.9475
Epoch 19/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 243.7956 - val_loss: 236.7606
Epoch 20/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 243.1215 - val_loss: 233.8403
Epoch 21/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 242.3356 - val_loss: 237.8769
Epoch 22/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 241.6112 - val_loss: 235.7611
Epoch 23/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 240.9414 - val_loss: 233.7330
Epoch 24/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 240.4804 - val_loss: 240.2951
Epoch 25/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 239.8393 - val_loss: 233.9349
Epoch 26/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 239.3020 - val_loss: 255.0109
Epoch 27/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 238.8338 - val_loss: 245.1752
Epoch 28/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 238.4912 - val_loss: 232.5007
Epoch 29/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 237.9818 - val_loss: 238.9852                   Epoch 30/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 237.6753 - val_loss: 241.5709
Epoch 31/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 237.1243 - val_loss: 235.5649
Epoch 32/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 236.7950 - val_loss: 240.7227
Epoch 33/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 236.5038 - val_loss: 232.7534
Epoch 34/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 236.0761 - val_loss: 232.0212
Epoch 35/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 235.8946 - val_loss: 244.8836
Epoch 36/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 235.5030 - val_loss: 229.4227
Epoch 37/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 235.1532 - val_loss: 225.4848
Epoch 38/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 234.9463 - val_loss: 230.8417
Epoch 39/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 234.6876 - val_loss: 229.1395
Epoch 40/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 234.1839 - val_loss: 231.8383
Epoch 41/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 234.0329 - val_loss: 228.9020
Epoch 42/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 233.8440 - val_loss: 230.1368
Epoch 43/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 233.4823 - val_loss: 230.5149
Epoch 44/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 233.3518 - val_loss: 233.8472
Epoch 45/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 233.1272 - val_loss: 235.5095

 ###### inititial_accuracy = 231.55284984869024



 QUEUE SIZE BEFORE GET = 1


 NODE SELECTED <<<------ Epochs = 45 -------- BatchSize = 6000--------- Accuracy = 231.55284984869024 -------->>>

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/49
2018-07-17 01:13:55.552288: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0                                                                          2018-07-17 01:13:55.557537: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 25s 3us/step - loss: 301.7480 - val_loss: 286.2575
Epoch 2/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 281.9906 - val_loss: 277.2990
Epoch 3/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 278.5866 - val_loss: 276.2272
Epoch 4/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 277.3470 - val_loss: 278.4372
Epoch 5/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 276.5825 - val_loss: 274.5546
Epoch 6/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 276.1719 - val_loss: 274.0846
Epoch 7/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 275.7324 - val_loss: 273.8672
Epoch 8/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 275.3622 - val_loss: 275.8201
Epoch 9/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 274.8609 - val_loss: 277.0304
Epoch 10/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 273.7540 - val_loss: 274.2301
Epoch 11/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 273.1191 - val_loss: 270.1664
Epoch 12/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 272.5613 - val_loss: 271.3148
Epoch 13/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 272.2812 - val_loss: 270.1913
Epoch 14/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 271.9576 - val_loss: 270.2620
Epoch 15/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 271.7422 - val_loss: 271.3975
Epoch 16/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 271.5221 - val_loss: 271.5367
Epoch 17/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 271.3089 - val_loss: 268.6365
Epoch 18/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 271.1363 - val_loss: 270.3694
Epoch 19/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 270.9774 - val_loss: 268.9303
Epoch 20/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 270.8494 - val_loss: 268.7004
Epoch 21/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 270.7319 - val_loss: 275.2367
Epoch 22/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 270.6058 - val_loss: 269.1911
Epoch 23/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 270.4891 - val_loss: 268.3501
Epoch 24/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 270.3625 - val_loss: 268.2535
Epoch 25/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 270.2375 - val_loss: 270.3018
Epoch 26/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 270.1956 - val_loss: 270.4928
Epoch 27/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 270.1482 - val_loss: 271.9641
Epoch 28/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.9743 - val_loss: 271.7620
Epoch 29/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.9488 - val_loss: 268.7478
Epoch 30/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.8590 - val_loss: 269.2052
Epoch 31/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.7420 - val_loss: 267.4757
Epoch 32/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.7291 - val_loss: 268.1133                   Epoch 33/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.7010 - val_loss: 268.9596
Epoch 34/49                                                                                                             9445953/9445953 [==============================] - 25s 3us/step - loss: 269.6086 - val_loss: 271.9113
Epoch 35/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.5793 - val_loss: 268.5103                   Epoch 36/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.4487 - val_loss: 267.9731
Epoch 37/49                                                                                                             9445953/9445953 [==============================] - 25s 3us/step - loss: 269.3939 - val_loss: 267.5033
Epoch 38/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.3603 - val_loss: 269.6027                   Epoch 39/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.2422 - val_loss: 267.1343
Epoch 40/49                                                                                                             9445953/9445953 [==============================] - 25s 3us/step - loss: 269.1713 - val_loss: 266.7796
Epoch 41/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.0665 - val_loss: 267.1841                   Epoch 42/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.0043 - val_loss: 267.5187
Epoch 43/49                                                                                                             9445953/9445953 [==============================] - 25s 3us/step - loss: 268.9582 - val_loss: 267.8868
Epoch 44/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 268.9082 - val_loss: 272.6295
Epoch 45/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 268.8535 - val_loss: 266.6662
Epoch 46/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 268.7513 - val_loss: 267.2188
Epoch 47/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 268.7142 - val_loss: 266.8390
Epoch 48/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 268.6315 - val_loss: 267.3945
Epoch 49/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 268.5856 - val_loss: 269.0010

 CHILD 1 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 49

         CHILD ACCURACY = 266.55605799294824

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-07-17 01:34:22.296166: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 01:34:22.302077: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 23s 2us/step - loss: 305.6722 - val_loss: 284.6505
Epoch 2/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 286.1089 - val_loss: 281.9023
Epoch 3/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 282.1331 - val_loss: 279.1965
Epoch 4/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 278.7385 - val_loss: 273.6832
Epoch 5/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 275.5805 - val_loss: 274.7291
Epoch 6/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 273.1231 - val_loss: 270.4049
Epoch 7/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 271.2387 - val_loss: 268.0229
Epoch 8/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 269.7775 - val_loss: 266.9085
Epoch 9/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 268.4704 - val_loss: 268.8002
Epoch 10/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 267.3043 - val_loss: 263.0787
Epoch 11/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 266.1903 - val_loss: 261.2360
Epoch 12/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 265.3123 - val_loss: 260.7467
Epoch 13/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 264.3433 - val_loss: 261.2980
Epoch 14/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 263.6692 - val_loss: 266.9288
Epoch 15/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 262.9949 - val_loss: 264.7229
Epoch 16/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 262.4208 - val_loss: 261.9161
Epoch 17/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 261.8848 - val_loss: 257.8496
Epoch 18/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 261.4690 - val_loss: 258.3586
Epoch 19/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 261.0353 - val_loss: 259.1975
Epoch 20/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 260.7295 - val_loss: 258.0634
Epoch 21/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 260.3710 - val_loss: 256.6397
Epoch 22/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 260.1412 - val_loss: 260.6901
Epoch 23/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 259.8645 - val_loss: 259.0296
Epoch 24/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 259.6542 - val_loss: 260.7462
Epoch 25/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 259.4582 - val_loss: 256.7052
Epoch 26/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 259.2195 - val_loss: 256.0967
Epoch 27/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 259.0527 - val_loss: 256.5880
Epoch 28/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 258.9016 - val_loss: 256.5243
Epoch 29/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 258.7766 - val_loss: 255.0257
Epoch 30/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 258.5882 - val_loss: 257.6181
Epoch 31/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 258.3946 - val_loss: 260.1424
Epoch 32/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 258.2490 - val_loss: 260.6882
Epoch 33/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 258.1635 - val_loss: 255.7898
Epoch 34/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 257.8922 - val_loss: 262.0388
Epoch 35/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 257.9313 - val_loss: 258.9091
Epoch 36/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 257.6461 - val_loss: 257.8165
Epoch 37/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 257.6652 - val_loss: 258.2185
Epoch 38/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 257.4772 - val_loss: 262.3422
Epoch 39/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 257.3988 - val_loss: 256.4282
Epoch 40/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 257.2181 - val_loss: 254.0647
Epoch 41/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 257.2666 - val_loss: 254.3739
Epoch 42/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 257.0248 - val_loss: 255.0851
Epoch 43/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 256.9665 - val_loss: 254.7990
Epoch 44/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 256.9455 - val_loss: 255.0272
Epoch 45/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 256.7222 - val_loss: 256.8934

 CHILD 2 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7000

         EPOCHS = 45

         CHILD ACCURACY = 253.98760024338662

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/41
2018-07-17 01:51:14.621425: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 01:51:14.626883: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 26s 3us/step - loss: 301.8418 - val_loss: 284.1586
Epoch 2/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 284.6651 - val_loss: 284.1940
Epoch 3/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 279.6441 - val_loss: 278.8587
Epoch 4/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 276.2814 - val_loss: 273.0524
Epoch 5/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 274.5056 - val_loss: 271.5436
Epoch 6/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 272.0714 - val_loss: 266.9107
Epoch 7/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 268.0506 - val_loss: 268.1109
Epoch 8/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 263.1359 - val_loss: 262.7122
Epoch 9/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 259.6408 - val_loss: 261.2449
Epoch 10/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 256.7156 - val_loss: 249.2487
Epoch 11/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 254.3744 - val_loss: 252.5435
Epoch 12/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 252.2037 - val_loss: 252.9401
Epoch 13/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 250.4228 - val_loss: 244.4932
Epoch 14/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 248.7458 - val_loss: 243.2805
Epoch 15/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 247.4481 - val_loss: 242.5895
Epoch 16/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 246.3480 - val_loss: 239.8002
Epoch 17/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 245.2835 - val_loss: 241.9418
Epoch 18/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 244.5420 - val_loss: 242.1976
Epoch 19/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.6698 - val_loss: 249.3150
Epoch 20/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.8716 - val_loss: 252.8436
Epoch 21/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.2387 - val_loss: 250.5510
Epoch 22/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.6124 - val_loss: 236.7996
Epoch 23/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.9697 - val_loss: 241.3314
Epoch 24/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.4490 - val_loss: 238.1249
Epoch 25/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.9473 - val_loss: 235.1961
Epoch 26/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.3498 - val_loss: 239.6734
Epoch 27/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.9616 - val_loss: 234.4170
Epoch 28/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.3463 - val_loss: 233.5550
Epoch 29/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.9770 - val_loss: 244.1007
Epoch 30/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.4991 - val_loss: 230.9015
Epoch 31/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.4029 - val_loss: 234.1753
Epoch 32/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.7697 - val_loss: 245.2255
Epoch 33/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.5386 - val_loss: 238.1242
Epoch 34/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.2850 - val_loss: 249.2839
Epoch 35/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.8981 - val_loss: 246.7250
Epoch 36/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.6118 - val_loss: 246.3721
Epoch 37/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.3134 - val_loss: 242.8388
Epoch 38/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.8974 - val_loss: 235.3758
Epoch 39/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.6175 - val_loss: 249.9959
Epoch 40/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.3390 - val_loss: 226.1610
Epoch 41/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.1286 - val_loss: 244.9598

 CHILD 3 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 41

         CHILD ACCURACY = 243.75066516875194

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/49
2018-07-17 02:08:19.539295: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 02:08:19.544687: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 23s 2us/step - loss: 302.4022 - val_loss: 284.7725
Epoch 2/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 283.4947 - val_loss: 281.8257
Epoch 3/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 279.8430 - val_loss: 291.2040
Epoch 4/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 277.7159 - val_loss: 278.7256
Epoch 5/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 276.0174 - val_loss: 274.5222
Epoch 6/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 274.1836 - val_loss: 273.3069
Epoch 7/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 272.4421 - val_loss: 269.4962
Epoch 8/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 270.3087 - val_loss: 267.5255
Epoch 9/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 268.1745 - val_loss: 263.3901
Epoch 10/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 265.2519 - val_loss: 261.2809
Epoch 11/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 261.2587 - val_loss: 254.2106
Epoch 12/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 257.4085 - val_loss: 254.4438
Epoch 13/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 254.5281 - val_loss: 255.4254
Epoch 14/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 251.8942 - val_loss: 242.7892
Epoch 15/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 249.5846 - val_loss: 245.0600
Epoch 16/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 247.7934 - val_loss: 239.5705
Epoch 17/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 246.0363 - val_loss: 237.7995
Epoch 18/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 244.6286 - val_loss: 237.6740
Epoch 19/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 243.4728 - val_loss: 242.1900
Epoch 20/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 242.1781 - val_loss: 232.8957
Epoch 21/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 241.3268 - val_loss: 241.5436
Epoch 22/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 240.3164 - val_loss: 232.4736
Epoch 23/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 239.6038 - val_loss: 234.4791
Epoch 24/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 238.8932 - val_loss: 231.9672
Epoch 25/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 238.0894 - val_loss: 233.3710
Epoch 26/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 237.3826 - val_loss: 232.4856
Epoch 27/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 236.8106 - val_loss: 228.2047
Epoch 28/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 236.0936 - val_loss: 244.3437
Epoch 29/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 235.8682 - val_loss: 233.6925
Epoch 30/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 235.0419 - val_loss: 240.6406
Epoch 31/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 234.7807 - val_loss: 228.3579
Epoch 32/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 234.2453 - val_loss: 241.5886
Epoch 33/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 233.8039 - val_loss: 225.5745
Epoch 34/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 233.5216 - val_loss: 222.6338
Epoch 35/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 233.0694 - val_loss: 225.0263
Epoch 36/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 232.7157 - val_loss: 224.5955
Epoch 37/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 232.2694 - val_loss: 224.2339
Epoch 38/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 232.0730 - val_loss: 228.9466
Epoch 39/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 231.6803 - val_loss: 227.4318
Epoch 40/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 231.3424 - val_loss: 237.7870
Epoch 41/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 231.0805 - val_loss: 238.5945
Epoch 42/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 230.7644 - val_loss: 220.9584
Epoch 43/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 230.3522 - val_loss: 222.8692
Epoch 44/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 230.2548 - val_loss: 229.1659
Epoch 45/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 229.8970 - val_loss: 222.5729
Epoch 46/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 229.6207 - val_loss: 221.3370
Epoch 47/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 229.5637 - val_loss: 225.0985
Epoch 48/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 229.2838 - val_loss: 222.6087
Epoch 49/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 229.0926 - val_loss: 225.8609

 CHILD 4 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7000

         EPOCHS = 49

         CHILD ACCURACY = 218.0623812581094


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 1 <<<<<<<<<<<<<<<<<<<<<<<<<<<


                         ********** BEST MODEL SAVED | EPOCHS = 49 | BATCH_SIZE = 7000 | ACCURACY = 218.0623812581094 ********



Train on 9445953 samples, validate on 1049551 samples
Epoch 1/41
2018-07-17 02:26:46.029742: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 02:26:46.035165: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 24s 3us/step - loss: 304.8522 - val_loss: 281.1497
Epoch 2/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 280.3213 - val_loss: 275.6795
Epoch 3/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 275.6083 - val_loss: 273.0278
Epoch 4/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 273.4566 - val_loss: 272.9832
Epoch 5/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 271.9455 - val_loss: 270.8259
Epoch 6/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 270.4963 - val_loss: 266.6603
Epoch 7/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 267.6721 - val_loss: 263.5505
Epoch 8/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 262.2215 - val_loss: 257.7821
Epoch 9/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 258.2168 - val_loss: 263.7370
Epoch 10/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 255.3770 - val_loss: 249.7167
Epoch 11/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 252.8834 - val_loss: 247.8624
Epoch 12/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 250.7388 - val_loss: 246.2723
Epoch 13/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 248.7232 - val_loss: 248.1924
Epoch 14/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 246.9501 - val_loss: 248.9391
Epoch 15/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 245.4680 - val_loss: 248.3576
Epoch 16/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 244.1421 - val_loss: 234.6997
Epoch 17/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 242.8485 - val_loss: 244.9035
Epoch 18/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 241.7053 - val_loss: 237.6967
Epoch 19/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 240.6297 - val_loss: 234.4182
Epoch 20/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 239.5120 - val_loss: 233.8508
Epoch 21/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 238.5940 - val_loss: 231.7691
Epoch 22/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 237.8675 - val_loss: 234.8597
Epoch 23/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 237.1351 - val_loss: 231.2452
Epoch 24/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 236.3384 - val_loss: 239.3937
Epoch 25/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 235.5738 - val_loss: 231.8283
Epoch 26/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 234.9647 - val_loss: 233.3199
Epoch 27/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 234.2364 - val_loss: 227.6854
Epoch 28/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 233.6983 - val_loss: 228.2531
Epoch 29/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 233.2161 - val_loss: 224.6248
Epoch 30/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 232.7836 - val_loss: 241.6139
Epoch 31/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 232.1984 - val_loss: 224.9355
Epoch 32/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 231.8390 - val_loss: 224.2054
Epoch 33/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 231.2893 - val_loss: 236.2081
Epoch 34/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 230.9413 - val_loss: 226.7036
Epoch 35/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 230.3897 - val_loss: 227.6257
Epoch 36/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 230.1455 - val_loss: 222.1472
Epoch 37/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 229.8370 - val_loss: 223.3716
Epoch 38/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 229.4283 - val_loss: 224.2750
Epoch 39/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 229.1660 - val_loss: 219.7475
Epoch 40/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 228.7295 - val_loss: 231.6881
Epoch 41/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 228.5091 - val_loss: 220.6432

 CHILD 5 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 6000

         EPOCHS = 41

         CHILD ACCURACY = 219.2186484041065


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 2 <<<<<<<<<<<<<<<<<<<<<<<<<<<

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-07-17 02:42:38.752555: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 02:42:38.758657: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 26s 3us/step - loss: 305.1388 - val_loss: 278.4392
Epoch 2/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 279.2203 - val_loss: 275.3595
Epoch 3/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 276.4048 - val_loss: 274.6640
Epoch 4/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 274.7732 - val_loss: 273.0718
Epoch 5/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 272.2214 - val_loss: 271.9621
Epoch 6/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.0933 - val_loss: 264.9723
Epoch 7/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 266.0249 - val_loss: 260.2798
Epoch 8/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 262.8485 - val_loss: 258.4355
Epoch 9/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 260.0968 - val_loss: 256.4834
Epoch 10/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 257.4738 - val_loss: 252.2387
Epoch 11/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 255.1567 - val_loss: 247.9939
Epoch 12/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 253.1908 - val_loss: 265.3103
Epoch 13/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 251.7017 - val_loss: 252.4114
Epoch 14/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 250.1237 - val_loss: 244.6457
Epoch 15/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 248.8715 - val_loss: 244.3581
Epoch 16/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 247.7262 - val_loss: 248.2117
Epoch 17/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 246.7462 - val_loss: 239.7913
Epoch 18/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 245.6197 - val_loss: 244.8580
Epoch 19/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 244.7138 - val_loss: 252.5988
Epoch 20/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.7646 - val_loss: 247.9043
Epoch 21/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.5604 - val_loss: 240.8756
Epoch 22/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.2931 - val_loss: 238.2658
Epoch 23/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.3415 - val_loss: 244.8895
Epoch 24/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.5574 - val_loss: 237.4176
Epoch 25/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.7705 - val_loss: 237.6497
Epoch 26/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.0598 - val_loss: 235.8208
Epoch 27/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.3167 - val_loss: 236.8663
Epoch 28/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.7413 - val_loss: 273.0351
Epoch 29/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.1020 - val_loss: 232.0356
Epoch 30/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.5890 - val_loss: 238.2348
Epoch 31/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.9968 - val_loss: 239.3559
Epoch 32/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.5402 - val_loss: 239.4194
Epoch 33/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.9478 - val_loss: 228.3297
Epoch 34/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.7346 - val_loss: 230.5210
Epoch 35/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.1200 - val_loss: 245.7588
Epoch 36/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 232.7769 - val_loss: 245.8065
Epoch 37/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 232.4371 - val_loss: 258.0779
Epoch 38/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 232.0938 - val_loss: 226.0902
Epoch 39/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 231.5814 - val_loss: 232.7010
Epoch 40/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 231.1573 - val_loss: 238.7304
Epoch 41/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 231.1527 - val_loss: 231.8537
Epoch 42/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 230.6670 - val_loss: 222.8235
Epoch 43/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 230.4638 - val_loss: 223.9044
Epoch 44/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 230.1638 - val_loss: 223.1156
Epoch 45/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 229.8217 - val_loss: 226.1497

 CHILD 6 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 45

         CHILD ACCURACY = 217.71751731770837


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 3 <<<<<<<<<<<<<<<<<<<<<<<<<<<


                         ********** BEST MODEL SAVED | EPOCHS = 45 | BATCH_SIZE = 5000 | ACCURACY = 217.71751731770837 ********



Train on 9445953 samples, validate on 1049551 samples
Epoch 1/49
2018-07-17 03:01:23.533852: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 03:01:23.539842: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 23s 2us/step - loss: 364.8521 - val_loss: 344.8537
Epoch 2/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 336.3368 - val_loss: 325.4816
Epoch 3/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 323.4652 - val_loss: 318.3191
Epoch 4/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.7220 - val_loss: 317.1157
Epoch 5/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3089 - val_loss: 317.0900
Epoch 6/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3031 - val_loss: 317.0907
Epoch 7/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3031 - val_loss: 317.0907
Epoch 8/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3033 - val_loss: 317.0908
Epoch 9/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0904
Epoch 10/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3031 - val_loss: 317.0893
Epoch 11/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3033 - val_loss: 317.0904
Epoch 12/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3031 - val_loss: 317.0896
Epoch 13/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0909
Epoch 14/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0893
Epoch 15/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3031 - val_loss: 317.0908
Epoch 16/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3030 - val_loss: 317.0904
Epoch 17/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3031 - val_loss: 317.0894
Epoch 18/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0898
Epoch 19/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0898
Epoch 20/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3033 - val_loss: 317.0895
Epoch 21/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3031 - val_loss: 317.0923
Epoch 22/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0898
Epoch 23/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0909
Epoch 24/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0899
Epoch 25/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0899
Epoch 26/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0893
Epoch 27/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0907
Epoch 28/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3029 - val_loss: 317.0893
Epoch 29/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0903
Epoch 30/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0895
Epoch 31/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0897
Epoch 32/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3033 - val_loss: 317.0901
Epoch 33/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0900
Epoch 34/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0916
Epoch 35/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3031 - val_loss: 317.0910
Epoch 36/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3033 - val_loss: 317.0903
Epoch 37/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0924
Epoch 38/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0903
Epoch 39/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0906
Epoch 40/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3033 - val_loss: 317.0895
Epoch 41/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3031 - val_loss: 317.0894
Epoch 42/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3034 - val_loss: 317.0895
Epoch 43/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3031 - val_loss: 317.0901
Epoch 44/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0896
Epoch 45/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3033 - val_loss: 317.0908
Epoch 46/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3033 - val_loss: 317.0906
Epoch 47/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3030 - val_loss: 317.0896
Epoch 48/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3033 - val_loss: 317.0902
Epoch 49/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3031 - val_loss: 317.0900

 CHILD 7 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 6000

         EPOCHS = 49

         CHILD ACCURACY = 314.8770229439091

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/41
2018-07-17 03:19:57.841601: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 03:19:57.846978: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 23s 2us/step - loss: 300.6561 - val_loss: 278.9192
Epoch 2/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 279.6636 - val_loss: 273.0311
Epoch 3/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 273.5807 - val_loss: 268.3897
Epoch 4/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 267.9957 - val_loss: 263.0473
Epoch 5/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 263.8375 - val_loss: 258.4396
Epoch 6/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 260.2089 - val_loss: 253.1163
Epoch 7/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 257.1611 - val_loss: 251.8108
Epoch 8/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 254.7532 - val_loss: 248.5257
Epoch 9/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 252.4995 - val_loss: 245.9821
Epoch 10/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 250.4889 - val_loss: 257.7576
Epoch 11/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 248.6271 - val_loss: 244.8917
Epoch 12/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 246.7576 - val_loss: 239.7894
Epoch 13/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 245.2546 - val_loss: 245.1400
Epoch 14/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 243.8429 - val_loss: 246.1519
Epoch 15/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 242.4909 - val_loss: 231.8766
Epoch 16/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 241.3533 - val_loss: 234.1645
Epoch 17/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 239.9978 - val_loss: 233.1617
Epoch 18/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 239.2242 - val_loss: 230.3204
Epoch 19/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 238.2636 - val_loss: 239.5135
Epoch 20/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 237.3908 - val_loss: 242.9869
Epoch 21/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 236.6181 - val_loss: 230.5135
Epoch 22/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 235.8335 - val_loss: 227.8912
Epoch 23/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 235.0013 - val_loss: 229.0968
Epoch 24/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 234.5792 - val_loss: 227.9437
Epoch 25/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 233.8511 - val_loss: 226.5296
Epoch 26/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 233.2416 - val_loss: 227.6615
Epoch 27/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 232.7136 - val_loss: 225.5375
Epoch 28/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 232.1057 - val_loss: 221.7108
Epoch 29/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 231.6900 - val_loss: 222.0092
Epoch 30/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 231.2228 - val_loss: 221.3704
Epoch 31/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 230.6345 - val_loss: 223.4756
Epoch 32/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 230.3430 - val_loss: 222.6525
Epoch 33/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 229.8264 - val_loss: 219.2923
Epoch 34/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 229.5751 - val_loss: 240.3789
Epoch 35/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 229.0734 - val_loss: 233.5634
Epoch 36/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 228.6430 - val_loss: 223.9045
Epoch 37/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 228.2990 - val_loss: 218.0313
Epoch 38/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 228.2422 - val_loss: 226.8273
Epoch 39/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 227.6823 - val_loss: 227.9984
Epoch 40/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 227.4799 - val_loss: 224.3258
Epoch 41/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 227.1502 - val_loss: 231.7175

 CHILD 8 out of 8 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7000

         EPOCHS = 41

         CHILD ACCURACY = 227.79588350645906


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 4 <<<<<<<<<<<<<<<<<<<<<<<<<<<



 QUEUE SIZE BEFORE GET = 4


 NODE SELECTED <<<------ Epochs = 45 -------- BatchSize = 5000--------- Accuracy = 217.71751731770837 -------->>>

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/41
2018-07-17 03:35:21.210343: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 03:35:21.216259: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 28s 3us/step - loss: 300.4596 - val_loss: 283.4682
Epoch 2/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 284.8464 - val_loss: 280.3271
Epoch 3/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 282.0800 - val_loss: 281.1658
Epoch 4/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 280.7216 - val_loss: 278.4531
Epoch 5/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 279.8453 - val_loss: 277.2568
Epoch 6/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 278.9755 - val_loss: 276.6409
Epoch 7/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 278.2625 - val_loss: 276.1900
Epoch 8/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 277.8112 - val_loss: 276.0711
Epoch 9/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 277.5730 - val_loss: 275.2528
Epoch 10/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 277.3790 - val_loss: 274.9892
Epoch 11/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 277.2345 - val_loss: 275.3171
Epoch 12/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 277.0830 - val_loss: 275.4769
Epoch 13/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 276.8955 - val_loss: 274.4333
Epoch 14/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 276.6956 - val_loss: 273.8657
Epoch 15/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 276.4293 - val_loss: 274.8233
Epoch 16/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 275.9928 - val_loss: 273.7715
Epoch 17/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 274.9158 - val_loss: 271.1913
Epoch 18/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 272.3115 - val_loss: 269.1358
Epoch 19/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 269.9180 - val_loss: 268.6291
Epoch 20/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 267.2614 - val_loss: 262.5149
Epoch 21/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 265.1869 - val_loss: 260.7594
Epoch 22/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 263.8381 - val_loss: 261.4643
Epoch 23/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 262.9741 - val_loss: 260.6005
Epoch 24/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 262.3240 - val_loss: 260.6161
Epoch 25/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 261.8185 - val_loss: 261.7642
Epoch 26/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 261.3337 - val_loss: 257.7521
Epoch 27/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 261.0409 - val_loss: 258.1153
Epoch 28/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 260.6777 - val_loss: 257.2958
Epoch 29/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 260.3678 - val_loss: 257.4712
Epoch 30/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 260.0441 - val_loss: 258.2009
Epoch 31/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 259.8288 - val_loss: 255.7401
Epoch 32/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 259.5933 - val_loss: 257.2695
Epoch 33/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 259.2959 - val_loss: 255.9325
Epoch 34/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 259.1594 - val_loss: 257.6175
Epoch 35/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 258.9725 - val_loss: 257.8799
Epoch 36/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 258.8202 - val_loss: 256.5510
Epoch 37/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 258.7460 - val_loss: 256.2309
Epoch 38/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 258.4565 - val_loss: 255.1563
Epoch 39/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 258.3769 - val_loss: 256.5225
Epoch 40/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 258.2281 - val_loss: 254.3822
Epoch 41/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 258.0258 - val_loss: 255.8061

 CHILD 1 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 4000

         EPOCHS = 41

         CHILD ACCURACY = 252.661776901633

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/49
2018-07-17 03:54:07.410696: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 03:54:07.415811: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 28s 3us/step - loss: 302.5122 - val_loss: 293.5825
Epoch 2/49
9445953/9445953 [==============================] - 28s 3us/step - loss: 279.2120 - val_loss: 274.0851
Epoch 3/49
9445953/9445953 [==============================] - 28s 3us/step - loss: 274.7176 - val_loss: 268.6827
Epoch 4/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 268.4301 - val_loss: 266.9398
Epoch 5/49
9445953/9445953 [==============================] - 28s 3us/step - loss: 263.0767 - val_loss: 262.6626
Epoch 6/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 259.5809 - val_loss: 257.7158
Epoch 7/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 256.4819 - val_loss: 250.8947
Epoch 8/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 253.6396 - val_loss: 253.3318
Epoch 9/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 251.0524 - val_loss: 245.6076
Epoch 10/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 248.5720 - val_loss: 246.9493
Epoch 11/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 246.5978 - val_loss: 239.2749
Epoch 12/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 244.7458 - val_loss: 238.2310
Epoch 13/49
9445953/9445953 [==============================] - 28s 3us/step - loss: 243.3190 - val_loss: 235.2327
Epoch 14/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 241.8449 - val_loss: 237.9801
Epoch 15/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 240.7126 - val_loss: 233.8955
Epoch 16/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 239.7283 - val_loss: 231.3557
Epoch 17/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 238.5749 - val_loss: 236.8371
Epoch 18/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 237.8277 - val_loss: 234.5036
Epoch 19/49
9445953/9445953 [==============================] - 28s 3us/step - loss: 237.2198 - val_loss: 229.8126
Epoch 20/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 236.2834 - val_loss: 235.4119
Epoch 21/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 235.5790 - val_loss: 242.9176
Epoch 22/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 234.9870 - val_loss: 227.6414
Epoch 23/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 234.4132 - val_loss: 226.5853
Epoch 24/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 233.7846 - val_loss: 232.1369
Epoch 25/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 233.1346 - val_loss: 229.7237
Epoch 26/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 232.6522 - val_loss: 227.4105
Epoch 27/49
9445953/9445953 [==============================] - 28s 3us/step - loss: 232.0792 - val_loss: 227.1552
Epoch 28/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 231.6297 - val_loss: 221.8557
Epoch 29/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 231.1828 - val_loss: 227.6593
Epoch 30/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 230.5527 - val_loss: 223.2075
Epoch 31/49
9445953/9445953 [==============================] - 28s 3us/step - loss: 230.2425 - val_loss: 220.2468
Epoch 32/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 229.7799 - val_loss: 223.2899
Epoch 33/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 229.4711 - val_loss: 219.9396
Epoch 34/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 229.0014 - val_loss: 222.8115
Epoch 35/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 228.6524 - val_loss: 221.2380
Epoch 36/49
9445953/9445953 [==============================] - 28s 3us/step - loss: 228.3084 - val_loss: 222.0311
Epoch 37/49
9445953/9445953 [==============================] - 28s 3us/step - loss: 227.8484 - val_loss: 222.2384
Epoch 38/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 227.6443 - val_loss: 223.0967
Epoch 39/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 227.2897 - val_loss: 219.0119
Epoch 40/49
9445953/9445953 [==============================] - 28s 3us/step - loss: 226.8918 - val_loss: 219.3163
Epoch 41/49
9445953/9445953 [==============================] - 28s 3us/step - loss: 226.5698 - val_loss: 229.8769
Epoch 42/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 226.1403 - val_loss: 221.0146
Epoch 43/49
9445953/9445953 [==============================] - 28s 3us/step - loss: 225.9099 - val_loss: 219.1025
Epoch 44/49
9445953/9445953 [==============================] - 28s 3us/step - loss: 225.5972 - val_loss: 223.2116
Epoch 45/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 225.3105 - val_loss: 217.6418
Epoch 46/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 225.0732 - val_loss: 214.9098
Epoch 47/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 224.8535 - val_loss: 226.7946
Epoch 48/49
9445953/9445953 [==============================] - 28s 3us/step - loss: 224.7593 - val_loss: 222.0029
Epoch 49/49
9445953/9445953 [==============================] - 27s 3us/step - loss: 224.2481 - val_loss: 215.6475

 CHILD 2 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 4000

         EPOCHS = 49

         CHILD ACCURACY = 214.94385499987484


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 4 <<<<<<<<<<<<<<<<<<<<<<<<<<<


                         ********** BEST MODEL SAVED | EPOCHS = 49 | BATCH_SIZE = 4000 | ACCURACY = 214.94385499987484 ********



Train on 9445953 samples, validate on 1049551 samples
Epoch 1/41
2018-07-17 04:16:35.273103: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 04:16:35.277560: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 25s 3us/step - loss: 297.8507 - val_loss: 281.8388
Epoch 2/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 280.1934 - val_loss: 276.4642
Epoch 3/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 276.2545 - val_loss: 272.4817
Epoch 4/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 271.8799 - val_loss: 275.1290
Epoch 5/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 267.5538 - val_loss: 268.6538
Epoch 6/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 263.8476 - val_loss: 266.8082
Epoch 7/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 261.0712 - val_loss: 262.8106
Epoch 8/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 258.9434 - val_loss: 260.3631
Epoch 9/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 257.2838 - val_loss: 258.7369
Epoch 10/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 255.6123 - val_loss: 251.2485
Epoch 11/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 254.2907 - val_loss: 261.1993
Epoch 12/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 252.8939 - val_loss: 256.1761
Epoch 13/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 251.7870 - val_loss: 246.2576
Epoch 14/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 250.8106 - val_loss: 256.0101
Epoch 15/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 249.8661 - val_loss: 249.5752
Epoch 16/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 249.2808 - val_loss: 254.2162
Epoch 17/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 248.5339 - val_loss: 244.0472
Epoch 18/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 247.9313 - val_loss: 250.0226
Epoch 19/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 247.3520 - val_loss: 252.9080
Epoch 20/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 246.7910 - val_loss: 275.7135
Epoch 21/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 246.3676 - val_loss: 246.0940
Epoch 22/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 245.9321 - val_loss: 258.8825
Epoch 23/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 245.5786 - val_loss: 242.9852
Epoch 24/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 245.2072 - val_loss: 251.8520
Epoch 25/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 244.8431 - val_loss: 240.0476
Epoch 26/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 244.4537 - val_loss: 246.1763
Epoch 27/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.9129 - val_loss: 241.1177
Epoch 28/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.8548 - val_loss: 245.6798
Epoch 29/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.5376 - val_loss: 239.6420
Epoch 30/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.2677 - val_loss: 241.4764
Epoch 31/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.9697 - val_loss: 247.3485
Epoch 32/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.6665 - val_loss: 242.0583
Epoch 33/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.5018 - val_loss: 269.6303
Epoch 34/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.4211 - val_loss: 242.4142
Epoch 35/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.9984 - val_loss: 241.0897
Epoch 36/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.7974 - val_loss: 237.2648
Epoch 37/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.4525 - val_loss: 250.6028
Epoch 38/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.4237 - val_loss: 239.6991
Epoch 39/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.2020 - val_loss: 252.3846
Epoch 40/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.9647 - val_loss: 250.5192
Epoch 41/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.8387 - val_loss: 248.7357

 CHILD 3 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 41

         CHILD ACCURACY = 254.56206467624907

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-07-17 04:33:37.389372: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 04:33:37.394531: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 24s 3us/step - loss: 300.1784 - val_loss: 280.1005
Epoch 2/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 280.6036 - val_loss: 275.7646
Epoch 3/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 276.4248 - val_loss: 273.3770
Epoch 4/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 273.7566 - val_loss: 275.1942
Epoch 5/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 271.1809 - val_loss: 274.1798
Epoch 6/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 268.3349 - val_loss: 264.8129
Epoch 7/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 263.9398 - val_loss: 260.3563
Epoch 8/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 259.4811 - val_loss: 254.4635
Epoch 9/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 256.3152 - val_loss: 251.4789
Epoch 10/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 253.7422 - val_loss: 247.3021
Epoch 11/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 251.5978 - val_loss: 247.2208
Epoch 12/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 249.6285 - val_loss: 246.3581
Epoch 13/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 247.9706 - val_loss: 243.3366
Epoch 14/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 246.3248 - val_loss: 250.3193
Epoch 15/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 244.7224 - val_loss: 251.8265
Epoch 16/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 243.4612 - val_loss: 243.9700
Epoch 17/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 242.0609 - val_loss: 232.7315
Epoch 18/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 240.8475 - val_loss: 234.0037
Epoch 19/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 239.7150 - val_loss: 231.0239
Epoch 20/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 238.8488 - val_loss: 231.8713
Epoch 21/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 237.8065 - val_loss: 229.7906
Epoch 22/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 237.0205 - val_loss: 229.1016
Epoch 23/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 236.0671 - val_loss: 233.8611
Epoch 24/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 235.5412 - val_loss: 233.2358
Epoch 25/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 234.6522 - val_loss: 226.5116
Epoch 26/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 233.9922 - val_loss: 226.5262
Epoch 27/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 233.4599 - val_loss: 225.8163
Epoch 28/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 233.0543 - val_loss: 230.9821
Epoch 29/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 232.4382 - val_loss: 222.9031
Epoch 30/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 231.7959 - val_loss: 230.2137
Epoch 31/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 231.3197 - val_loss: 227.8782
Epoch 32/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 230.9859 - val_loss: 232.0040
Epoch 33/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 230.5654 - val_loss: 231.9459
Epoch 34/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 230.0141 - val_loss: 230.3560
Epoch 35/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 229.6517 - val_loss: 218.7261
Epoch 36/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 229.3258 - val_loss: 221.4212
Epoch 37/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 228.9477 - val_loss: 216.8037
Epoch 38/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 228.5544 - val_loss: 226.1510
Epoch 39/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 228.1856 - val_loss: 220.8972
Epoch 40/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 227.7295 - val_loss: 218.5721
Epoch 41/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 227.4310 - val_loss: 226.8337
Epoch 42/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 227.2295 - val_loss: 219.7520
Epoch 43/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 226.8756 - val_loss: 222.8669
Epoch 44/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 226.7316 - val_loss: 222.0353
Epoch 45/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 226.1807 - val_loss: 223.1866

 CHILD 4 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 6000

         EPOCHS = 45

         CHILD ACCURACY = 217.16603643867705


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 5 <<<<<<<<<<<<<<<<<<<<<<<<<<<

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-07-17 04:51:03.948149: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 04:51:03.952626: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 28s 3us/step - loss: 301.4334 - val_loss: 279.0604
Epoch 2/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 279.3051 - val_loss: 275.3059
Epoch 3/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 277.2144 - val_loss: 273.7149
Epoch 4/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 275.0427 - val_loss: 271.5348
Epoch 5/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 273.5801 - val_loss: 270.6423
Epoch 6/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 272.4374 - val_loss: 270.2172
Epoch 7/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 271.0181 - val_loss: 267.0052
Epoch 8/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 266.1450 - val_loss: 259.2246
Epoch 9/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 259.8228 - val_loss: 257.0041
Epoch 10/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 255.6714 - val_loss: 250.4764
Epoch 11/45
9445953/9445953 [==============================] - 28s 3us/step - loss: 252.3592 - val_loss: 244.1438
Epoch 12/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 249.7924 - val_loss: 248.6979
Epoch 13/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 247.4567 - val_loss: 239.4792
Epoch 14/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 245.8382 - val_loss: 240.1497
Epoch 15/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 244.4516 - val_loss: 255.4078
Epoch 16/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 243.2419 - val_loss: 243.1833
Epoch 17/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 242.1445 - val_loss: 233.9253
Epoch 18/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 241.1791 - val_loss: 240.9018
Epoch 19/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 240.3136 - val_loss: 241.4525
Epoch 20/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 239.5542 - val_loss: 230.8431
Epoch 21/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 238.8815 - val_loss: 236.2500
Epoch 22/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 238.1487 - val_loss: 232.6435
Epoch 23/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 237.6236 - val_loss: 231.4879
Epoch 24/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 236.8920 - val_loss: 232.4935
Epoch 25/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 236.1929 - val_loss: 248.9903
Epoch 26/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 235.7571 - val_loss: 241.7112
Epoch 27/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 235.3479 - val_loss: 229.6718
Epoch 28/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 234.8331 - val_loss: 230.0092
Epoch 29/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 234.3045 - val_loss: 227.9753
Epoch 30/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 233.8824 - val_loss: 231.9356
Epoch 31/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 233.4584 - val_loss: 238.0232
Epoch 32/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 233.0240 - val_loss: 233.0583
Epoch 33/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 232.7827 - val_loss: 225.6207
Epoch 34/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 232.5067 - val_loss: 230.2184
Epoch 35/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 232.0392 - val_loss: 230.8054
Epoch 36/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 231.7639 - val_loss: 222.1010
Epoch 37/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 231.3523 - val_loss: 222.3172
Epoch 38/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 231.0766 - val_loss: 234.7264
Epoch 39/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 230.6859 - val_loss: 235.9577
Epoch 40/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 230.5138 - val_loss: 229.2172
Epoch 41/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 230.0919 - val_loss: 224.8222
Epoch 42/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 229.6435 - val_loss: 229.1550
Epoch 43/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 229.6220 - val_loss: 234.6238
Epoch 44/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 229.4721 - val_loss: 223.5011
Epoch 45/45
9445953/9445953 [==============================] - 27s 3us/step - loss: 229.0378 - val_loss: 221.1724

 CHILD 5 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 4000

         EPOCHS = 45

         CHILD ACCURACY = 224.78231117788062



 QUEUE SIZE BEFORE GET = 5


 NODE SELECTED <<<------ Epochs = 49 -------- BatchSize = 4000--------- Accuracy = 214.94385499987484 -------->>>

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/49
2018-07-17 05:11:38.228829: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 05:11:38.233882: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 25s 3us/step - loss: 297.8854 - val_loss: 293.5633
Epoch 2/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 281.9603 - val_loss: 285.0788
Epoch 3/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 278.6388 - val_loss: 275.2298
Epoch 4/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 276.9332 - val_loss: 278.5561
Epoch 5/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 275.1581 - val_loss: 279.2520
Epoch 6/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 270.8028 - val_loss: 265.5100
Epoch 7/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 266.7920 - val_loss: 272.7287
Epoch 8/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 263.9370 - val_loss: 269.8333
Epoch 9/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 261.3290 - val_loss: 256.8263
Epoch 10/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 259.2230 - val_loss: 264.2269
Epoch 11/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 257.2022 - val_loss: 265.3413
Epoch 12/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 255.6452 - val_loss: 254.0340
Epoch 13/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 254.2354 - val_loss: 251.7851
Epoch 14/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 253.1529 - val_loss: 254.5563
Epoch 15/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 251.9958 - val_loss: 257.2251
Epoch 16/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 250.9891 - val_loss: 250.1045
Epoch 17/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 250.2041 - val_loss: 253.0754
Epoch 18/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 249.3863 - val_loss: 252.9526
Epoch 19/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 248.4979 - val_loss: 253.8339
Epoch 20/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 247.9655 - val_loss: 244.4234
Epoch 21/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 247.3564 - val_loss: 244.2296
Epoch 22/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 246.7960 - val_loss: 238.8127
Epoch 23/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 246.0238 - val_loss: 259.0091
Epoch 24/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 245.4632 - val_loss: 246.2795
Epoch 25/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 244.9865 - val_loss: 243.3195
Epoch 26/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 244.6498 - val_loss: 239.5372
Epoch 27/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 244.0428 - val_loss: 260.4684
Epoch 28/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.5943 - val_loss: 244.1803
Epoch 29/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.2410 - val_loss: 239.9295
Epoch 30/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.7868 - val_loss: 244.1191
Epoch 31/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.3616 - val_loss: 241.2213
Epoch 32/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.1580 - val_loss: 238.2734
Epoch 33/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.7044 - val_loss: 239.4785
Epoch 34/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.3533 - val_loss: 239.1625
Epoch 35/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.0071 - val_loss: 235.7345
Epoch 36/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.5190 - val_loss: 233.2532
Epoch 37/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.2857 - val_loss: 242.8015
Epoch 38/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.8971 - val_loss: 247.3772
Epoch 39/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.5863 - val_loss: 248.3571
Epoch 40/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.4494 - val_loss: 234.8309
Epoch 41/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.1237 - val_loss: 249.0466
Epoch 42/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.7942 - val_loss: 252.7273
Epoch 43/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.4708 - val_loss: 241.6349
Epoch 44/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.9847 - val_loss: 256.1007
Epoch 45/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.9115 - val_loss: 254.3883
Epoch 46/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.5315 - val_loss: 232.3744
Epoch 47/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.4815 - val_loss: 244.9059
Epoch 48/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.1781 - val_loss: 231.9482
Epoch 49/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.0403 - val_loss: 232.9964

 CHILD 1 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 49

         CHILD ACCURACY = 233.80458573702342

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-07-17 05:32:00.000838: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 05:32:00.009639: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 32s 3us/step - loss: 297.3125 - val_loss: 280.5983
Epoch 2/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 281.1229 - val_loss: 276.8829
Epoch 3/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 276.7055 - val_loss: 273.1516
Epoch 4/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 274.1495 - val_loss: 273.6825
Epoch 5/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 272.3673 - val_loss: 269.5214
Epoch 6/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 270.1000 - val_loss: 266.9412
Epoch 7/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 267.6802 - val_loss: 262.9728
Epoch 8/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 265.8907 - val_loss: 264.9629
Epoch 9/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 264.1658 - val_loss: 260.8661
Epoch 10/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 261.5962 - val_loss: 256.0458
Epoch 11/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 258.9343 - val_loss: 253.1196
Epoch 12/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 256.7538 - val_loss: 252.2002
Epoch 13/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 255.1144 - val_loss: 254.0782
Epoch 14/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 254.0284 - val_loss: 250.1276
Epoch 15/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 252.9987 - val_loss: 251.2868
Epoch 16/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 252.2584 - val_loss: 249.3427
Epoch 17/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 251.6081 - val_loss: 247.7182
Epoch 18/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 250.8997 - val_loss: 247.8638
Epoch 19/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 250.2832 - val_loss: 247.8748
Epoch 20/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 249.6666 - val_loss: 246.7199
Epoch 21/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 249.2811 - val_loss: 243.4903
Epoch 22/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 248.6687 - val_loss: 243.0752
Epoch 23/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 248.3441 - val_loss: 244.7905
Epoch 24/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 247.6335 - val_loss: 245.4275
Epoch 25/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 247.3105 - val_loss: 246.6951
Epoch 26/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 246.8381 - val_loss: 242.5952
Epoch 27/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 246.3117 - val_loss: 244.5724
Epoch 28/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 245.9790 - val_loss: 243.4511
Epoch 29/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 245.4719 - val_loss: 239.8930
Epoch 30/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 245.0404 - val_loss: 243.2595
Epoch 31/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 244.6968 - val_loss: 239.4505
Epoch 32/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 244.2740 - val_loss: 242.8096
Epoch 33/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 244.1174 - val_loss: 238.5776
Epoch 34/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 243.5449 - val_loss: 237.8429
Epoch 35/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 243.1242 - val_loss: 242.9138
Epoch 36/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 242.9207 - val_loss: 236.4834
Epoch 37/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 242.3654 - val_loss: 239.4425
Epoch 38/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 241.9619 - val_loss: 235.5994
Epoch 39/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 241.4486 - val_loss: 236.7743
Epoch 40/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 241.0100 - val_loss: 234.6684
Epoch 41/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 240.4529 - val_loss: 232.7427
Epoch 42/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 239.9242 - val_loss: 234.0084
Epoch 43/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 239.4681 - val_loss: 233.6927
Epoch 44/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 238.9179 - val_loss: 235.4867
Epoch 45/45
9445953/9445953 [==============================] - 32s 3us/step - loss: 238.3886 - val_loss: 238.3398

 CHILD 2 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 3000

         EPOCHS = 45

         CHILD ACCURACY = 231.58907302635697

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/53
2018-07-17 05:55:53.710327: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 05:55:53.716610: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 28s 3us/step - loss: 307.6237 - val_loss: 287.5490
Epoch 2/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 286.7839 - val_loss: 281.7289
Epoch 3/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 283.5604 - val_loss: 281.6741
Epoch 4/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 283.0421 - val_loss: 280.6342
Epoch 5/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 282.8119 - val_loss: 280.9537
Epoch 6/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 282.6750 - val_loss: 280.5208
Epoch 7/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 282.5413 - val_loss: 280.0488
Epoch 8/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 282.3724 - val_loss: 280.5046
Epoch 9/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 282.2303 - val_loss: 279.8020
Epoch 10/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 282.1315 - val_loss: 280.3828
Epoch 11/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 282.0634 - val_loss: 279.7089
Epoch 12/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 282.0018 - val_loss: 279.7658
Epoch 13/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 281.9841 - val_loss: 280.2116
Epoch 14/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 281.9529 - val_loss: 279.7836
Epoch 15/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 281.8772 - val_loss: 280.4400
Epoch 16/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 281.8306 - val_loss: 279.8474
Epoch 17/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 281.8443 - val_loss: 280.0526
Epoch 18/53
9445953/9445953 [==============================] - 28s 3us/step - loss: 281.8122 - val_loss: 280.0614
Epoch 19/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 281.7691 - val_loss: 279.4286
Epoch 20/53
9445953/9445953 [==============================] - 28s 3us/step - loss: 281.7519 - val_loss: 279.9019
Epoch 21/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 281.7233 - val_loss: 279.4104
Epoch 22/53
9445953/9445953 [==============================] - 28s 3us/step - loss: 281.6871 - val_loss: 280.1453
Epoch 23/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 281.6992 - val_loss: 279.3639
Epoch 24/53
9445953/9445953 [==============================] - 28s 3us/step - loss: 281.6567 - val_loss: 279.9886
Epoch 25/53
9445953/9445953 [==============================] - 28s 3us/step - loss: 281.6514 - val_loss: 279.6124
Epoch 26/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 281.6190 - val_loss: 280.4417
Epoch 27/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 281.5868 - val_loss: 279.2171
Epoch 28/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 281.6119 - val_loss: 279.9077
Epoch 29/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 281.5549 - val_loss: 279.8707
Epoch 30/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 281.5385 - val_loss: 280.3519
Epoch 31/53
9445953/9445953 [==============================] - 28s 3us/step - loss: 281.5365 - val_loss: 279.4920
Epoch 32/53
9445953/9445953 [==============================] - 28s 3us/step - loss: 281.5309 - val_loss: 279.5039
Epoch 33/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 281.5328 - val_loss: 279.3551
Epoch 34/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 281.4973 - val_loss: 279.2044
Epoch 35/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 281.5109 - val_loss: 280.2920
Epoch 36/53
9445953/9445953 [==============================] - 28s 3us/step - loss: 281.4999 - val_loss: 279.1245
Epoch 37/53
9445953/9445953 [==============================] - 28s 3us/step - loss: 281.4828 - val_loss: 279.3850
Epoch 38/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 281.4876 - val_loss: 279.5894
Epoch 39/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 281.4758 - val_loss: 279.6285
Epoch 40/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 281.4330 - val_loss: 279.3036
Epoch 41/53
9445953/9445953 [==============================] - 28s 3us/step - loss: 281.4428 - val_loss: 279.1054
Epoch 42/53
9445953/9445953 [==============================] - 28s 3us/step - loss: 281.4555 - val_loss: 279.7027
Epoch 43/53
9445953/9445953 [==============================] - 28s 3us/step - loss: 281.4502 - val_loss: 279.3244
Epoch 44/53
9445953/9445953 [==============================] - 28s 3us/step - loss: 281.4565 - val_loss: 279.7230
Epoch 45/53
9445953/9445953 [==============================] - 27s 3us/step - loss: 281.4433 - val_loss: 279.2822
Epoch 46/53
9445953/9445953 [==============================] - 28s 3us/step - loss: 281.4174 - val_loss: 279.9643
Epoch 47/53
9445953/9445953 [==============================] - 28s 3us/step - loss: 281.4211 - val_loss: 279.2260
Epoch 48/53
9445953/9445953 [==============================] - 28s 3us/step - loss: 281.4032 - val_loss: 279.7031
Epoch 49/53
9445953/9445953 [==============================] - 28s 3us/step - loss: 281.4071 - val_loss: 279.1065
Epoch 50/53
9445953/9445953 [==============================] - 28s 3us/step - loss: 281.4218 - val_loss: 279.2253
Epoch 51/53
9445953/9445953 [==============================] - 28s 3us/step - loss: 281.3874 - val_loss: 279.5727
Epoch 52/53
9445953/9445953 [==============================] - 28s 3us/step - loss: 281.3867 - val_loss: 279.4032
Epoch 53/53
9445953/9445953 [==============================] - 28s 3us/step - loss: 281.3852 - val_loss: 280.7782

 CHILD 3 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 4000

         EPOCHS = 53

         CHILD ACCURACY = 278.094421216681

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/53
2018-07-17 06:20:11.349380: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 06:20:11.354643: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 25s 3us/step - loss: 361.3400 - val_loss: 339.6199
Epoch 2/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 331.3475 - val_loss: 321.4818
Epoch 3/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 320.9459 - val_loss: 317.2712
Epoch 4/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3436 - val_loss: 317.0894
Epoch 5/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3031 - val_loss: 317.0905
Epoch 6/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 321.2707 - val_loss: 317.0990
Epoch 7/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3041 - val_loss: 317.0902
Epoch 8/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3030 - val_loss: 317.0913
Epoch 9/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3031 - val_loss: 317.0918
Epoch 10/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3033 - val_loss: 317.0895
Epoch 11/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0897
Epoch 12/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3033 - val_loss: 317.0905
Epoch 13/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3034 - val_loss: 317.0895
Epoch 14/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0905
Epoch 15/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3033 - val_loss: 317.0900
Epoch 16/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0896
Epoch 17/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3030 - val_loss: 317.0896
Epoch 18/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3031 - val_loss: 317.0897
Epoch 19/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0905
Epoch 20/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0903
Epoch 21/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0900
Epoch 22/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0893
Epoch 23/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3033 - val_loss: 317.0904
Epoch 24/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3031 - val_loss: 317.0928
Epoch 25/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3033 - val_loss: 317.0908
Epoch 26/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3031 - val_loss: 317.0895
Epoch 27/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3033 - val_loss: 317.0899
Epoch 28/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0904
Epoch 29/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0896
Epoch 30/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3031 - val_loss: 317.0901
Epoch 31/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3033 - val_loss: 317.0895
Epoch 32/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3033 - val_loss: 317.0910
Epoch 33/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3034 - val_loss: 317.0901
Epoch 34/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0906
Epoch 35/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3031 - val_loss: 317.0911
Epoch 36/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3033 - val_loss: 317.0894
Epoch 37/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3031 - val_loss: 317.0913
Epoch 38/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3031 - val_loss: 317.0894
Epoch 39/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3033 - val_loss: 317.0894
Epoch 40/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0913
Epoch 41/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3033 - val_loss: 317.0903
Epoch 42/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0904
Epoch 43/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0896
Epoch 44/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3033 - val_loss: 317.0910
Epoch 45/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0894
Epoch 46/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0893
Epoch 47/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3030 - val_loss: 317.0909
Epoch 48/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3033 - val_loss: 317.0896
Epoch 49/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0897
Epoch 50/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3031 - val_loss: 317.0908
Epoch 51/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3034 - val_loss: 317.0905
Epoch 52/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3031 - val_loss: 317.0894
Epoch 53/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0916

 CHILD 4 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 53

         CHILD ACCURACY = 314.87789078135404

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/49
2018-07-17 06:41:42.869591: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 06:41:42.876004: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 32s 3us/step - loss: 297.5605 - val_loss: 276.9465
Epoch 2/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 278.0374 - val_loss: 273.7757
Epoch 3/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 274.9813 - val_loss: 272.9118
Epoch 4/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 269.6787 - val_loss: 262.4453
Epoch 5/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 263.1059 - val_loss: 257.4647
Epoch 6/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 259.0429 - val_loss: 253.1253
Epoch 7/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 256.1492 - val_loss: 251.5097
Epoch 8/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 253.7070 - val_loss: 251.1731
Epoch 9/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 251.4773 - val_loss: 245.6772
Epoch 10/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 249.4218 - val_loss: 245.1297
Epoch 11/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 247.8081 - val_loss: 241.1041
Epoch 12/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 246.3877 - val_loss: 238.0805
Epoch 13/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 245.1583 - val_loss: 238.3643
Epoch 14/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 243.8915 - val_loss: 236.1952
Epoch 15/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 242.9134 - val_loss: 233.8037
Epoch 16/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 241.9363 - val_loss: 238.3561
Epoch 17/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 241.2443 - val_loss: 232.4451
Epoch 18/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 240.3529 - val_loss: 238.1753
Epoch 19/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 239.8681 - val_loss: 233.6394
Epoch 20/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 239.1646 - val_loss: 231.4387
Epoch 21/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 238.6255 - val_loss: 233.5658
Epoch 22/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 237.8475 - val_loss: 236.4579
Epoch 23/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 237.3878 - val_loss: 233.5546
Epoch 24/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 237.0247 - val_loss: 232.2077
Epoch 25/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 236.7554 - val_loss: 227.9284
Epoch 26/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 236.2136 - val_loss: 239.7940
Epoch 27/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 235.7376 - val_loss: 228.2285
Epoch 28/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 235.2155 - val_loss: 226.6564
Epoch 29/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 234.9989 - val_loss: 226.9805
Epoch 30/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 234.7372 - val_loss: 224.4071
Epoch 31/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 234.2358 - val_loss: 230.3697
Epoch 32/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 234.0764 - val_loss: 225.0881
Epoch 33/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 233.7961 - val_loss: 227.7923
Epoch 34/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 233.5823 - val_loss: 232.9470
Epoch 35/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 233.2692 - val_loss: 228.4076
Epoch 36/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 233.0242 - val_loss: 225.3769
Epoch 37/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 232.7390 - val_loss: 224.2028
Epoch 38/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 232.4995 - val_loss: 223.7663
Epoch 39/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 232.3239 - val_loss: 223.8503
Epoch 40/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 232.0741 - val_loss: 227.8026
Epoch 41/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 232.0539 - val_loss: 230.9372
Epoch 42/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 231.8326 - val_loss: 222.0605
Epoch 43/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 231.5923 - val_loss: 223.4952
Epoch 44/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 231.5578 - val_loss: 226.5696
Epoch 45/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 231.3977 - val_loss: 223.5994
Epoch 46/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 231.1443 - val_loss: 226.4415
Epoch 47/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 231.1966 - val_loss: 222.3151
Epoch 48/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 230.9724 - val_loss: 222.9070
Epoch 49/49
9445953/9445953 [==============================] - 32s 3us/step - loss: 230.7066 - val_loss: 223.5293

 CHILD 5 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 3000

         EPOCHS = 49

         CHILD ACCURACY = 216.59145595040243

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/53
2018-07-17 07:07:52.009040: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 07:07:52.014358: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 32s 3us/step - loss: 297.7647 - val_loss: 276.6960
Epoch 2/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 278.0289 - val_loss: 273.7421
Epoch 3/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 275.4252 - val_loss: 272.0286
Epoch 4/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 273.9613 - val_loss: 270.5867
Epoch 5/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 272.8014 - val_loss: 269.7212
Epoch 6/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 271.1649 - val_loss: 270.1082
Epoch 7/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 265.7521 - val_loss: 257.7807
Epoch 8/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 259.6515 - val_loss: 253.9103
Epoch 9/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 256.1080 - val_loss: 252.1411
Epoch 10/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 253.2787 - val_loss: 248.7572
Epoch 11/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 250.7699 - val_loss: 244.4533
Epoch 12/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 248.4451 - val_loss: 240.4533
Epoch 13/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 246.6569 - val_loss: 238.6579
Epoch 14/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 244.7644 - val_loss: 239.9633
Epoch 15/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 243.3581 - val_loss: 239.7452
Epoch 16/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 242.2741 - val_loss: 234.1929
Epoch 17/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 241.2860 - val_loss: 232.9384
Epoch 18/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 240.2139 - val_loss: 238.8804
Epoch 19/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 239.5451 - val_loss: 233.2620
Epoch 20/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 238.6915 - val_loss: 234.5948
Epoch 21/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 238.0717 - val_loss: 228.9229
Epoch 22/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 237.3955 - val_loss: 229.8367
Epoch 23/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 236.7882 - val_loss: 230.8572
Epoch 24/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 236.2298 - val_loss: 227.2493
Epoch 25/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 235.7231 - val_loss: 228.1237
Epoch 26/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 235.2907 - val_loss: 229.6058
Epoch 27/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 234.5592 - val_loss: 226.4805
Epoch 28/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 234.2079 - val_loss: 229.2794
Epoch 29/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 233.8148 - val_loss: 230.1998
Epoch 30/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 233.6148 - val_loss: 228.0131
Epoch 31/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 233.3523 - val_loss: 224.5995
Epoch 32/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 232.9501 - val_loss: 224.2653
Epoch 33/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 232.5614 - val_loss: 230.6141
Epoch 34/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 231.9844 - val_loss: 239.2774
Epoch 35/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 231.7611 - val_loss: 224.7994
Epoch 36/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 231.5641 - val_loss: 223.7499
Epoch 37/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 231.2257 - val_loss: 222.6479
Epoch 38/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 230.9149 - val_loss: 224.0977
Epoch 39/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 230.6836 - val_loss: 227.7081
Epoch 40/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 230.5328 - val_loss: 223.5985
Epoch 41/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 230.1686 - val_loss: 223.6978
Epoch 42/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 229.9868 - val_loss: 224.9733
Epoch 43/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 229.8374 - val_loss: 220.3414
Epoch 44/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 229.4379 - val_loss: 219.6203
Epoch 45/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 229.1553 - val_loss: 223.8619
Epoch 46/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 229.0370 - val_loss: 225.3392
Epoch 47/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 228.9282 - val_loss: 225.7612
Epoch 48/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 228.7474 - val_loss: 225.8405
Epoch 49/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 228.4856 - val_loss: 225.0595
Epoch 50/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 228.1545 - val_loss: 221.5570
Epoch 51/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 228.1033 - val_loss: 221.8334
Epoch 52/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 228.0015 - val_loss: 226.5404
Epoch 53/53
9445953/9445953 [==============================] - 32s 3us/step - loss: 227.6852 - val_loss: 220.7180

 CHILD 6 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 3000

         EPOCHS = 53

         CHILD ACCURACY = 217.33829862959894



 QUEUE SIZE BEFORE GET = 4


 NODE SELECTED <<<------ Epochs = 45 -------- BatchSize = 6000--------- Accuracy = 217.16603643867705 -------->>>

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/41
2018-07-17 07:35:58.870477: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 07:35:58.875970: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 25s 3us/step - loss: 296.3828 - val_loss: 293.3004
Epoch 2/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 280.8589 - val_loss: 276.3587
Epoch 3/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 275.9028 - val_loss: 271.6481
Epoch 4/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 271.7190 - val_loss: 268.3484
Epoch 5/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 268.9675 - val_loss: 268.8303
Epoch 6/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 267.1168 - val_loss: 263.8749
Epoch 7/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 265.4102 - val_loss: 262.7231
Epoch 8/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 264.1031 - val_loss: 264.0960
Epoch 9/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 263.0816 - val_loss: 261.7268
Epoch 10/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 262.3700 - val_loss: 267.8534
Epoch 11/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 261.7000 - val_loss: 261.0913
Epoch 12/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 261.1132 - val_loss: 260.0585
Epoch 13/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 258.6938 - val_loss: 257.8861
Epoch 14/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 254.7772 - val_loss: 257.9006
Epoch 15/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 251.8708 - val_loss: 251.2779
Epoch 16/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 249.6825 - val_loss: 255.6297
Epoch 17/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 247.7407 - val_loss: 248.5475
Epoch 18/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 246.3602 - val_loss: 240.8530
Epoch 19/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 245.0989 - val_loss: 240.0446
Epoch 20/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 244.0410 - val_loss: 250.6959
Epoch 21/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.0889 - val_loss: 237.3478
Epoch 22/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.1519 - val_loss: 235.8231
Epoch 23/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.3607 - val_loss: 234.2073
Epoch 24/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.5971 - val_loss: 231.4501
Epoch 25/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.9031 - val_loss: 231.5993
Epoch 26/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.4816 - val_loss: 240.3067
Epoch 27/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.5916 - val_loss: 239.6620
Epoch 28/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.1910 - val_loss: 231.7507
Epoch 29/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.7433 - val_loss: 238.0225
Epoch 30/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.1578 - val_loss: 238.3578
Epoch 31/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.8458 - val_loss: 234.6193
Epoch 32/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.3638 - val_loss: 230.1560
Epoch 33/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.9610 - val_loss: 240.5008
Epoch 34/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.6432 - val_loss: 237.9130
Epoch 35/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.2473 - val_loss: 261.9686
Epoch 36/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.9335 - val_loss: 228.5159
Epoch 37/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.4983 - val_loss: 229.6879
Epoch 38/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.1994 - val_loss: 234.6192
Epoch 39/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.9149 - val_loss: 237.0641
Epoch 40/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.4515 - val_loss: 257.8802
Epoch 41/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.3605 - val_loss: 246.3602

 CHILD 1 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 41

         CHILD ACCURACY = 254.23033229959057

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/41
2018-07-17 07:53:02.722290: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 07:53:02.727880: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 24s 3us/step - loss: 306.7820 - val_loss: 284.1542
Epoch 2/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 283.4458 - val_loss: 293.8095
Epoch 3/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 279.2265 - val_loss: 284.3850
Epoch 4/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 275.4657 - val_loss: 274.9176
Epoch 5/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 271.8192 - val_loss: 267.1154
Epoch 6/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 269.2320 - val_loss: 268.8592
Epoch 7/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 266.9490 - val_loss: 261.8015
Epoch 8/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 264.9752 - val_loss: 263.2827
Epoch 9/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 263.3576 - val_loss: 257.6756
Epoch 10/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 261.9372 - val_loss: 258.6911
Epoch 11/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 260.8737 - val_loss: 258.2466
Epoch 12/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 259.7857 - val_loss: 255.7878
Epoch 13/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 258.9002 - val_loss: 257.8981
Epoch 14/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 258.1504 - val_loss: 254.1033
Epoch 15/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 257.4089 - val_loss: 255.9405
Epoch 16/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 256.8367 - val_loss: 253.9605
Epoch 17/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 256.3019 - val_loss: 252.1921
Epoch 18/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 255.8608 - val_loss: 253.4809
Epoch 19/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 255.4555 - val_loss: 253.7595
Epoch 20/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 255.0156 - val_loss: 252.0848
Epoch 21/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 254.7752 - val_loss: 253.5295
Epoch 22/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 254.5323 - val_loss: 254.3072
Epoch 23/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 254.0634 - val_loss: 258.0873
Epoch 24/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 253.8091 - val_loss: 249.0202
Epoch 25/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 253.3711 - val_loss: 250.8123
Epoch 26/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 253.2395 - val_loss: 250.6324
Epoch 27/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 252.9289 - val_loss: 250.9518
Epoch 28/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 252.7401 - val_loss: 247.7599
Epoch 29/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 252.5391 - val_loss: 248.4041
Epoch 30/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 252.2662 - val_loss: 249.7540
Epoch 31/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 252.0168 - val_loss: 252.1074
Epoch 32/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 251.7998 - val_loss: 252.9998
Epoch 33/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 251.6545 - val_loss: 248.0530
Epoch 34/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 251.4506 - val_loss: 248.9289
Epoch 35/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 251.1192 - val_loss: 247.6600
Epoch 36/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 250.8921 - val_loss: 246.9911
Epoch 37/41
9445953/9445953 [==============================] - 24s 2us/step - loss: 250.6869 - val_loss: 247.9224
Epoch 38/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 250.5014 - val_loss: 248.5676
Epoch 39/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 250.4155 - val_loss: 249.2701
Epoch 40/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 250.0976 - val_loss: 248.6394
Epoch 41/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 249.9831 - val_loss: 249.1687

 CHILD 2 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 6000

         EPOCHS = 41

         CHILD ACCURACY = 247.57351021685827

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-07-17 08:08:57.001180: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 08:08:57.006245: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 25s 3us/step - loss: 301.8193 - val_loss: 282.4439
Epoch 2/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 281.1430 - val_loss: 285.8517
Epoch 3/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 274.7743 - val_loss: 271.3421
Epoch 4/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.3115 - val_loss: 266.1344
Epoch 5/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 263.7177 - val_loss: 265.3311
Epoch 6/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 259.6703 - val_loss: 263.0514
Epoch 7/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 256.4050 - val_loss: 253.4365
Epoch 8/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 253.7296 - val_loss: 247.1562
Epoch 9/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 251.4033 - val_loss: 245.0935
Epoch 10/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 249.1560 - val_loss: 245.6936
Epoch 11/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 247.2600 - val_loss: 247.5368
Epoch 12/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 245.7003 - val_loss: 239.9943
Epoch 13/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 244.4784 - val_loss: 239.8843
Epoch 14/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.1921 - val_loss: 252.8025
Epoch 15/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.2825 - val_loss: 236.2759
Epoch 16/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.2236 - val_loss: 250.7947
Epoch 17/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.5912 - val_loss: 234.9789
Epoch 18/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.8280 - val_loss: 257.4988
Epoch 19/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.0161 - val_loss: 248.1846
Epoch 20/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.5261 - val_loss: 236.6034
Epoch 21/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.8972 - val_loss: 233.1319
Epoch 22/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.2703 - val_loss: 231.3197
Epoch 23/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.6201 - val_loss: 241.3709
Epoch 24/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.2894 - val_loss: 240.6043
Epoch 25/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.8113 - val_loss: 234.3521
Epoch 26/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.3681 - val_loss: 229.8926
Epoch 27/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.8904 - val_loss: 241.5023
Epoch 28/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.6745 - val_loss: 241.4603
Epoch 29/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.0906 - val_loss: 238.4746
Epoch 30/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.9069 - val_loss: 228.2598
Epoch 31/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.4738 - val_loss: 226.2502
Epoch 32/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.0019 - val_loss: 231.1149
Epoch 33/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 232.8036 - val_loss: 242.4664
Epoch 34/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 232.6701 - val_loss: 228.5769
Epoch 35/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 232.0954 - val_loss: 227.3422
Epoch 36/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 231.9898 - val_loss: 231.2342
Epoch 37/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 231.6626 - val_loss: 225.7217
Epoch 38/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 231.3666 - val_loss: 225.8819
Epoch 39/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 231.0912 - val_loss: 239.6073
Epoch 40/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 231.0178 - val_loss: 235.2348
Epoch 41/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 230.5548 - val_loss: 236.3964
Epoch 42/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 230.3565 - val_loss: 223.2602
Epoch 43/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 230.1457 - val_loss: 230.0365
Epoch 44/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 229.8823 - val_loss: 234.6977
Epoch 45/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 229.7977 - val_loss: 227.8177

 CHILD 3 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 45

         CHILD ACCURACY = 227.8604752870395

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/41
2018-07-17 08:27:39.473719: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 08:27:39.480490: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 23s 2us/step - loss: 303.5031 - val_loss: 285.3830
Epoch 2/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 285.0757 - val_loss: 280.1882
Epoch 3/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 281.8208 - val_loss: 278.5566
Epoch 4/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 280.2628 - val_loss: 279.6323
Epoch 5/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 279.0544 - val_loss: 275.7849
Epoch 6/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 277.9910 - val_loss: 277.7275
Epoch 7/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 276.9682 - val_loss: 277.5361
Epoch 8/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 275.6703 - val_loss: 274.3078
Epoch 9/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 274.1105 - val_loss: 270.2754
Epoch 10/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 272.3917 - val_loss: 268.1432
Epoch 11/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 270.8554 - val_loss: 270.4463
Epoch 12/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 269.5839 - val_loss: 271.6929
Epoch 13/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 268.4373 - val_loss: 264.4928
Epoch 14/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 267.3984 - val_loss: 267.9995
Epoch 15/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 266.5827 - val_loss: 261.9568
Epoch 16/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 265.8973 - val_loss: 264.1965
Epoch 17/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 265.2561 - val_loss: 261.1345
Epoch 18/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 264.7092 - val_loss: 262.2362
Epoch 19/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 264.0954 - val_loss: 262.1525
Epoch 20/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 263.6500 - val_loss: 258.8756
Epoch 21/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 263.2626 - val_loss: 266.9248
Epoch 22/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 262.8072 - val_loss: 259.3477
Epoch 23/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 262.4541 - val_loss: 259.7911
Epoch 24/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 262.0202 - val_loss: 258.9050
Epoch 25/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 261.6526 - val_loss: 258.3529
Epoch 26/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 261.2577 - val_loss: 257.5155
Epoch 27/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 260.9802 - val_loss: 256.4082
Epoch 28/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 260.5833 - val_loss: 256.4204
Epoch 29/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 260.2043 - val_loss: 257.2967
Epoch 30/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 259.7573 - val_loss: 256.5786
Epoch 31/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 259.5383 - val_loss: 255.0828
Epoch 32/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 259.0749 - val_loss: 256.5346
Epoch 33/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 258.7141 - val_loss: 255.0890
Epoch 34/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 258.2730 - val_loss: 254.0771
Epoch 35/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 257.7105 - val_loss: 260.3402
Epoch 36/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 253.2215 - val_loss: 242.3488
Epoch 37/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 247.3144 - val_loss: 239.4032
Epoch 38/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 244.7390 - val_loss: 235.3545
Epoch 39/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 242.8358 - val_loss: 240.8530
Epoch 40/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 241.3269 - val_loss: 232.0912
Epoch 41/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 240.1992 - val_loss: 233.4659

 CHILD 4 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7000

         EPOCHS = 41

         CHILD ACCURACY = 228.60707929681155



 QUEUE SIZE BEFORE GET = 3


 NODE SELECTED <<<------ Epochs = 49 -------- BatchSize = 7000--------- Accuracy = 218.0623812581094 -------->>>

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/53
2018-07-17 08:43:02.992130: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 08:43:02.997439: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 23s 2us/step - loss: 304.8449 - val_loss: 279.9522
Epoch 2/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 280.7988 - val_loss: 274.7667
Epoch 3/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 276.8938 - val_loss: 272.5089
Epoch 4/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 274.8916 - val_loss: 272.9961
Epoch 5/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 273.6218 - val_loss: 270.4948
Epoch 6/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 272.6286 - val_loss: 270.5097
Epoch 7/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 271.6886 - val_loss: 269.1188
Epoch 8/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 270.7606 - val_loss: 268.2415
Epoch 9/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 269.6065 - val_loss: 269.4874
Epoch 10/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 264.5550 - val_loss: 255.8355
Epoch 11/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 258.4999 - val_loss: 258.5248
Epoch 12/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 254.9596 - val_loss: 250.4238
Epoch 13/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 252.4073 - val_loss: 248.2225
Epoch 14/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 250.2917 - val_loss: 244.7983
Epoch 15/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 248.1359 - val_loss: 244.9148
Epoch 16/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 246.5192 - val_loss: 243.4345
Epoch 17/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 244.7473 - val_loss: 238.7496
Epoch 18/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 243.2097 - val_loss: 240.2842
Epoch 19/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 241.9482 - val_loss: 248.1090
Epoch 20/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 240.7720 - val_loss: 233.4970
Epoch 21/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 239.9333 - val_loss: 241.6547
Epoch 22/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 239.0272 - val_loss: 237.4418
Epoch 23/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 238.1672 - val_loss: 230.7259
Epoch 24/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 237.3225 - val_loss: 232.8725
Epoch 25/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 236.7312 - val_loss: 234.2057
Epoch 26/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 235.9300 - val_loss: 231.5797
Epoch 27/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 235.5386 - val_loss: 229.6817
Epoch 28/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 234.8426 - val_loss: 232.2480
Epoch 29/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 234.6666 - val_loss: 231.8745
Epoch 30/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 233.9103 - val_loss: 234.8188
Epoch 31/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 233.5693 - val_loss: 224.7070
Epoch 32/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 232.9925 - val_loss: 237.0914
Epoch 33/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 232.6570 - val_loss: 231.2196
Epoch 34/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 232.2268 - val_loss: 224.5011
Epoch 35/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 231.9673 - val_loss: 225.1079
Epoch 36/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 231.5616 - val_loss: 226.6353
Epoch 37/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 231.1755 - val_loss: 227.3338
Epoch 38/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 230.9243 - val_loss: 220.8928
Epoch 39/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 230.4949 - val_loss: 221.3370
Epoch 40/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 230.1487 - val_loss: 222.6240
Epoch 41/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 229.8636 - val_loss: 232.2298
Epoch 42/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 229.6698 - val_loss: 229.1764
Epoch 43/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 229.3105 - val_loss: 224.6506
Epoch 44/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 229.1279 - val_loss: 220.0888
Epoch 45/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 228.7880 - val_loss: 220.5258
Epoch 46/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 228.6491 - val_loss: 223.1363
Epoch 47/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 228.5789 - val_loss: 221.1104
Epoch 48/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 228.1384 - val_loss: 228.5170
Epoch 49/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 227.9562 - val_loss: 224.8397
Epoch 50/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 227.8390 - val_loss: 224.8368
Epoch 51/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 227.5177 - val_loss: 227.2911
Epoch 52/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 227.3676 - val_loss: 218.6967
Epoch 53/53
9445953/9445953 [==============================] - 23s 2us/step - loss: 227.0073 - val_loss: 227.1445

 CHILD 1 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7000

         EPOCHS = 53

         CHILD ACCURACY = 221.55164471866402

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/53
2018-07-17 09:02:57.852177: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 09:02:57.857719: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 22s 2us/step - loss: 300.4124 - val_loss: 282.6487
Epoch 2/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 284.5492 - val_loss: 280.8866
Epoch 3/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 279.8258 - val_loss: 275.3828
Epoch 4/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 277.2297 - val_loss: 273.4380
Epoch 5/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 275.9087 - val_loss: 273.4437
Epoch 6/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 274.9348 - val_loss: 272.4459
Epoch 7/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 274.2127 - val_loss: 270.6368
Epoch 8/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 273.2646 - val_loss: 270.4595
Epoch 9/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 271.5138 - val_loss: 267.3691
Epoch 10/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 266.2204 - val_loss: 259.9797
Epoch 11/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 260.6426 - val_loss: 257.9254
Epoch 12/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 256.9365 - val_loss: 255.3737
Epoch 13/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 254.1366 - val_loss: 247.7279
Epoch 14/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 251.8705 - val_loss: 243.9913
Epoch 15/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 249.7292 - val_loss: 244.1584
Epoch 16/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 248.0599 - val_loss: 239.8716
Epoch 17/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 246.8157 - val_loss: 244.7682
Epoch 18/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 245.6693 - val_loss: 239.2389
Epoch 19/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 244.2524 - val_loss: 235.0557
Epoch 20/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 243.4357 - val_loss: 242.1055
Epoch 21/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 242.6252 - val_loss: 241.0246
Epoch 22/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 241.7036 - val_loss: 236.3460
Epoch 23/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 241.1156 - val_loss: 233.2018
Epoch 24/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 240.3030 - val_loss: 237.2320
Epoch 25/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 239.6920 - val_loss: 229.6168
Epoch 26/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 239.0995 - val_loss: 232.9899
Epoch 27/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 238.3745 - val_loss: 231.1310
Epoch 28/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 238.1906 - val_loss: 230.0061
Epoch 29/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 237.4663 - val_loss: 231.2184
Epoch 30/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 237.1576 - val_loss: 229.6812
Epoch 31/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 236.7083 - val_loss: 228.5660
Epoch 32/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 236.1554 - val_loss: 235.1933
Epoch 33/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 235.8797 - val_loss: 226.2064
Epoch 34/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 235.3652 - val_loss: 231.1239
Epoch 35/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 235.1556 - val_loss: 226.9400
Epoch 36/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 234.5310 - val_loss: 228.6102
Epoch 37/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 234.4020 - val_loss: 230.9243
Epoch 38/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 234.1789 - val_loss: 227.7604
Epoch 39/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 233.7766 - val_loss: 227.9050
Epoch 40/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 233.3168 - val_loss: 228.0035
Epoch 41/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 233.1426 - val_loss: 226.9236
Epoch 42/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 232.6867 - val_loss: 227.5834
Epoch 43/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 232.4880 - val_loss: 233.8834
Epoch 44/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 232.2896 - val_loss: 223.8615
Epoch 45/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 231.8753 - val_loss: 223.5659
Epoch 46/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 231.6999 - val_loss: 222.3111
Epoch 47/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 231.5239 - val_loss: 226.6525
Epoch 48/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 231.1501 - val_loss: 220.1947
Epoch 49/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 230.9664 - val_loss: 224.8525
Epoch 50/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 230.8164 - val_loss: 227.4547
Epoch 51/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 230.5615 - val_loss: 228.1732
Epoch 52/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 230.3461 - val_loss: 221.5910
Epoch 53/53
9445953/9445953 [==============================] - 22s 2us/step - loss: 230.1861 - val_loss: 222.2407

 CHILD 2 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 8000

         EPOCHS = 53

         CHILD ACCURACY = 219.2523030446174

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/49
2018-07-17 09:22:02.066798: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 09:22:02.072771: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 22s 2us/step - loss: 308.7821 - val_loss: 287.5416
Epoch 2/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 285.5178 - val_loss: 279.6557
Epoch 3/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 281.3554 - val_loss: 281.1487
Epoch 4/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 279.5949 - val_loss: 276.2812
Epoch 5/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 278.6940 - val_loss: 275.6061
Epoch 6/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 277.9732 - val_loss: 275.6883
Epoch 7/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 277.3104 - val_loss: 275.7622
Epoch 8/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 276.8777 - val_loss: 274.2039
Epoch 9/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 276.3592 - val_loss: 273.6812
Epoch 10/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 275.5086 - val_loss: 272.7609
Epoch 11/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 273.9729 - val_loss: 271.6118
Epoch 12/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 271.9047 - val_loss: 268.6500
Epoch 13/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 269.6490 - val_loss: 266.2361
Epoch 14/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 267.1662 - val_loss: 262.5321
Epoch 15/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 264.6152 - val_loss: 261.8530
Epoch 16/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 261.8383 - val_loss: 255.4610
Epoch 17/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 259.2295 - val_loss: 255.3589
Epoch 18/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 256.8447 - val_loss: 251.1487
Epoch 19/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 254.7330 - val_loss: 249.5742
Epoch 20/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 252.9038 - val_loss: 248.1876
Epoch 21/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 251.1673 - val_loss: 248.3379
Epoch 22/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 249.8445 - val_loss: 250.6000
Epoch 23/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 248.7233 - val_loss: 241.6688
Epoch 24/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 247.5121 - val_loss: 241.7316
Epoch 25/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 246.5553 - val_loss: 239.9547
Epoch 26/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 245.6017 - val_loss: 238.1737
Epoch 27/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 244.8180 - val_loss: 237.8065
Epoch 28/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 243.9473 - val_loss: 237.6229
Epoch 29/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 243.1968 - val_loss: 247.0683
Epoch 30/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 242.6163 - val_loss: 235.2073
Epoch 31/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 241.9535 - val_loss: 234.1813
Epoch 32/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 241.3878 - val_loss: 245.5535
Epoch 33/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 240.7882 - val_loss: 235.5754
Epoch 34/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 240.2401 - val_loss: 232.1125
Epoch 35/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 239.7783 - val_loss: 234.1002
Epoch 36/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 239.2292 - val_loss: 231.9389
Epoch 37/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 238.9099 - val_loss: 233.7406
Epoch 38/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 238.4752 - val_loss: 232.6626
Epoch 39/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 238.0260 - val_loss: 231.6425
Epoch 40/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 237.7511 - val_loss: 229.8294
Epoch 41/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 237.4707 - val_loss: 238.9133
Epoch 42/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 237.0380 - val_loss: 231.3949
Epoch 43/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 236.8936 - val_loss: 232.1353
Epoch 44/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 236.6138 - val_loss: 226.0812
Epoch 45/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 236.2654 - val_loss: 231.7070
Epoch 46/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 235.8394 - val_loss: 228.4145
Epoch 47/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 235.7199 - val_loss: 228.5726
Epoch 48/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 235.4771 - val_loss: 233.4178
Epoch 49/49
9445953/9445953 [==============================] - 22s 2us/step - loss: 235.2545 - val_loss: 228.7408

 CHILD 3 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 8000

         EPOCHS = 49

         CHILD ACCURACY = 224.00012108846283

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-07-17 09:39:42.086568: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 09:39:42.092250: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 24s 3us/step - loss: 313.7639 - val_loss: 286.9478
Epoch 2/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 283.4521 - val_loss: 278.6750
Epoch 3/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 278.1036 - val_loss: 284.9016
Epoch 4/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 275.9134 - val_loss: 274.2207
Epoch 5/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 274.5561 - val_loss: 271.7133
Epoch 6/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 273.7711 - val_loss: 272.1550
Epoch 7/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 273.1624 - val_loss: 273.4700
Epoch 8/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 272.7555 - val_loss: 271.0320
Epoch 9/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 272.4239 - val_loss: 272.3180
Epoch 10/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 272.1727 - val_loss: 269.9829
Epoch 11/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 271.9282 - val_loss: 269.8913
Epoch 12/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 271.7551 - val_loss: 269.9283
Epoch 13/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 271.4919 - val_loss: 269.1042
Epoch 14/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 271.3808 - val_loss: 269.3382
Epoch 15/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 271.2138 - val_loss: 269.6266
Epoch 16/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 271.0426 - val_loss: 268.7741
Epoch 17/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 270.9076 - val_loss: 269.2436
Epoch 18/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 270.7238 - val_loss: 269.5212
Epoch 19/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 270.5181 - val_loss: 267.6334
Epoch 20/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 270.4224 - val_loss: 267.9685
Epoch 21/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 270.3784 - val_loss: 268.5056
Epoch 22/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 270.1894 - val_loss: 268.9992
Epoch 23/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 270.1048 - val_loss: 269.0837
Epoch 24/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 270.0438 - val_loss: 268.3690
Epoch 25/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 269.9150 - val_loss: 267.9676
Epoch 26/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 269.7580 - val_loss: 268.1649
Epoch 27/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 269.6808 - val_loss: 268.0664
Epoch 28/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 269.5662 - val_loss: 267.7522
Epoch 29/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 269.5172 - val_loss: 267.9868
Epoch 30/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 269.4113 - val_loss: 268.6974
Epoch 31/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 269.3484 - val_loss: 267.0086
Epoch 32/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 269.2603 - val_loss: 267.6097
Epoch 33/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 269.1616 - val_loss: 267.1059
Epoch 34/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 269.1034 - val_loss: 267.1826
Epoch 35/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 269.0278 - val_loss: 266.8608
Epoch 36/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 268.9376 - val_loss: 269.1342
Epoch 37/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 268.8372 - val_loss: 268.4792
Epoch 38/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 268.8263 - val_loss: 266.6307
Epoch 39/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 268.7066 - val_loss: 267.2162
Epoch 40/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 268.6527 - val_loss: 267.1619
Epoch 41/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 268.5653 - val_loss: 268.0271
Epoch 42/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 268.5580 - val_loss: 266.5336
Epoch 43/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 268.4700 - val_loss: 266.8813
Epoch 44/45
9445953/9445953 [==============================] - 25s 3us/step - loss: 268.3654 - val_loss: 266.9267
Epoch 45/45
9445953/9445953 [==============================] - 24s 2us/step - loss: 268.2892 - val_loss: 266.2027

 CHILD 4 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 6000

         EPOCHS = 45

         CHILD ACCURACY = 264.8514749128211

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/53
2018-07-17 09:57:10.249607: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 09:57:10.254727: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 24s 3us/step - loss: 304.6452 - val_loss: 286.4235
Epoch 2/53
9445953/9445953 [==============================] - 24s 2us/step - loss: 285.9010 - val_loss: 281.1904
Epoch 3/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 282.7069 - val_loss: 279.2740
Epoch 4/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 278.2829 - val_loss: 272.9051
Epoch 5/53
9445953/9445953 [==============================] - 24s 2us/step - loss: 272.2077 - val_loss: 271.0715
Epoch 6/53
9445953/9445953 [==============================] - 24s 2us/step - loss: 269.1391 - val_loss: 266.8451
Epoch 7/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 267.1333 - val_loss: 266.2225
Epoch 8/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 265.5646 - val_loss: 260.5534
Epoch 9/53
9445953/9445953 [==============================] - 24s 2us/step - loss: 264.2463 - val_loss: 268.7003
Epoch 10/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 263.2678 - val_loss: 262.7413
Epoch 11/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 262.0762 - val_loss: 258.8974
Epoch 12/53
9445953/9445953 [==============================] - 24s 2us/step - loss: 261.2268 - val_loss: 258.4572
Epoch 13/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 260.3260 - val_loss: 257.1253
Epoch 14/53
9445953/9445953 [==============================] - 24s 2us/step - loss: 259.3712 - val_loss: 260.3707
Epoch 15/53
9445953/9445953 [==============================] - 24s 2us/step - loss: 258.5614 - val_loss: 266.0083
Epoch 16/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 257.8309 - val_loss: 255.9852
Epoch 17/53
9445953/9445953 [==============================] - 24s 2us/step - loss: 257.0872 - val_loss: 255.0377
Epoch 18/53
9445953/9445953 [==============================] - 24s 2us/step - loss: 256.4669 - val_loss: 256.1730
Epoch 19/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 255.8056 - val_loss: 258.0967
Epoch 20/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 255.2631 - val_loss: 252.1975
Epoch 21/53
9445953/9445953 [==============================] - 24s 2us/step - loss: 254.7638 - val_loss: 251.0375
Epoch 22/53
9445953/9445953 [==============================] - 24s 2us/step - loss: 254.3143 - val_loss: 251.2111
Epoch 23/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 253.9073 - val_loss: 251.5862
Epoch 24/53
9445953/9445953 [==============================] - 24s 2us/step - loss: 253.6342 - val_loss: 266.1305
Epoch 25/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 253.1750 - val_loss: 252.0382
Epoch 26/53
9445953/9445953 [==============================] - 24s 2us/step - loss: 252.7537 - val_loss: 252.9746
Epoch 27/53
9445953/9445953 [==============================] - 24s 2us/step - loss: 252.5080 - val_loss: 255.7575
Epoch 28/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 252.1199 - val_loss: 249.4968
Epoch 29/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 251.8645 - val_loss: 255.0302
Epoch 30/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 251.6456 - val_loss: 258.7493
Epoch 31/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 251.3941 - val_loss: 248.0804
Epoch 32/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 251.1342 - val_loss: 263.6849
Epoch 33/53
9445953/9445953 [==============================] - 24s 2us/step - loss: 250.8593 - val_loss: 246.9722
Epoch 34/53
9445953/9445953 [==============================] - 24s 2us/step - loss: 250.6255 - val_loss: 250.3271
Epoch 35/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 250.4044 - val_loss: 250.1038
Epoch 36/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 250.1329 - val_loss: 249.5939
Epoch 37/53
9445953/9445953 [==============================] - 24s 2us/step - loss: 249.9862 - val_loss: 244.9527
Epoch 38/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 249.5836 - val_loss: 245.4218
Epoch 39/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 249.5181 - val_loss: 248.7870
Epoch 40/53
9445953/9445953 [==============================] - 24s 2us/step - loss: 249.2543 - val_loss: 246.8219
Epoch 41/53
9445953/9445953 [==============================] - 24s 2us/step - loss: 249.0034 - val_loss: 251.4441
Epoch 42/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 248.9459 - val_loss: 255.2663
Epoch 43/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 248.6365 - val_loss: 255.5310
Epoch 44/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 248.4512 - val_loss: 258.1076
Epoch 45/53
9445953/9445953 [==============================] - 24s 2us/step - loss: 248.2824 - val_loss: 248.5724
Epoch 46/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 247.9738 - val_loss: 244.1736
Epoch 47/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 247.8888 - val_loss: 252.3772
Epoch 48/53
9445953/9445953 [==============================] - 24s 2us/step - loss: 247.7138 - val_loss: 247.0523
Epoch 49/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 247.5521 - val_loss: 254.9778
Epoch 50/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 247.3653 - val_loss: 245.3244
Epoch 51/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 247.0801 - val_loss: 248.3763
Epoch 52/53
9445953/9445953 [==============================] - 24s 2us/step - loss: 247.0418 - val_loss: 250.8721
Epoch 53/53
9445953/9445953 [==============================] - 24s 3us/step - loss: 246.7680 - val_loss: 243.3293

 CHILD 5 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 6000

         EPOCHS = 53

         CHILD ACCURACY = 246.8872703311389

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-07-17 10:18:03.034238: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 10:18:03.040395: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 22s 2us/step - loss: 310.5845 - val_loss: 284.4897
Epoch 2/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 283.7506 - val_loss: 276.4240
Epoch 3/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 278.3899 - val_loss: 272.3530
Epoch 4/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 274.9685 - val_loss: 270.6815
Epoch 5/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 270.0702 - val_loss: 263.4881
Epoch 6/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 265.5733 - val_loss: 259.5497
Epoch 7/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 262.1642 - val_loss: 255.3659
Epoch 8/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 259.1500 - val_loss: 251.9255
Epoch 9/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 256.4963 - val_loss: 249.8766
Epoch 10/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 254.3730 - val_loss: 247.4597
Epoch 11/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 252.4555 - val_loss: 247.5651
Epoch 12/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 250.6711 - val_loss: 246.1143
Epoch 13/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 249.0832 - val_loss: 244.4489
Epoch 14/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 247.6449 - val_loss: 239.5975
Epoch 15/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 246.1945 - val_loss: 241.9240
Epoch 16/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 244.9598 - val_loss: 236.9932
Epoch 17/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 243.5914 - val_loss: 237.1907
Epoch 18/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 242.2181 - val_loss: 236.9891
Epoch 19/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 240.9902 - val_loss: 235.0270
Epoch 20/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 239.8865 - val_loss: 231.0232
Epoch 21/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 238.8326 - val_loss: 230.8787
Epoch 22/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 237.6785 - val_loss: 230.1108
Epoch 23/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 236.7527 - val_loss: 229.1599
Epoch 24/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 235.8367 - val_loss: 229.0289
Epoch 25/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 235.2244 - val_loss: 225.6121
Epoch 26/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 234.3843 - val_loss: 226.4572
Epoch 27/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 233.6773 - val_loss: 224.7048
Epoch 28/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 233.0280 - val_loss: 229.9969
Epoch 29/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 232.4767 - val_loss: 235.1597
Epoch 30/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 231.8465 - val_loss: 224.2703
Epoch 31/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 231.5370 - val_loss: 228.4837
Epoch 32/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 231.0110 - val_loss: 219.8075
Epoch 33/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 230.4635 - val_loss: 220.7691
Epoch 34/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 229.9960 - val_loss: 225.8294
Epoch 35/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 229.7404 - val_loss: 218.2149
Epoch 36/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 229.3912 - val_loss: 225.2864
Epoch 37/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 228.9468 - val_loss: 226.3075
Epoch 38/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 228.7536 - val_loss: 222.5084
Epoch 39/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 228.4242 - val_loss: 221.0980
Epoch 40/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 228.1191 - val_loss: 217.8636
Epoch 41/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 227.7466 - val_loss: 218.4284
Epoch 42/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 227.4049 - val_loss: 215.7334
Epoch 43/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 227.2704 - val_loss: 222.6847
Epoch 44/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 226.8390 - val_loss: 221.7910
Epoch 45/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 226.4931 - val_loss: 214.6148

 CHILD 6 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 8000

         EPOCHS = 45

         CHILD ACCURACY = 210.41012945264993


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 3 <<<<<<<<<<<<<<<<<<<<<<<<<<<


                         ********** BEST MODEL SAVED | EPOCHS = 45 | BATCH_SIZE = 8000 | ACCURACY = 210.41012945264993 ********





 QUEUE SIZE BEFORE GET = 3


 NODE SELECTED <<<------ Epochs = 45 -------- BatchSize = 8000--------- Accuracy = 210.41012945264993 -------->>>

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/49
2018-07-17 10:34:30.477021: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 10:34:30.482936: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 22s 2us/step - loss: 320.2968 - val_loss: 301.4680
Epoch 2/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 291.4456 - val_loss: 287.3048
Epoch 3/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 284.5723 - val_loss: 279.1389
Epoch 4/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 280.8529 - val_loss: 278.0290
Epoch 5/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 278.7698 - val_loss: 283.2718
Epoch 6/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 277.2268 - val_loss: 280.8060
Epoch 7/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 275.7635 - val_loss: 272.2850
Epoch 8/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 273.8681 - val_loss: 268.6575
Epoch 9/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 270.3196 - val_loss: 265.2867
Epoch 10/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 266.9287 - val_loss: 261.0898
Epoch 11/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 263.7358 - val_loss: 261.0555
Epoch 12/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 260.5532 - val_loss: 252.2002
Epoch 13/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 257.8113 - val_loss: 257.2865
Epoch 14/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 255.3645 - val_loss: 251.4358
Epoch 15/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 253.0870 - val_loss: 246.3658
Epoch 16/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 251.2376 - val_loss: 243.6227
Epoch 17/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 249.2047 - val_loss: 242.1223
Epoch 18/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 247.6741 - val_loss: 240.0284
Epoch 19/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 245.9779 - val_loss: 236.7500
Epoch 20/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 244.6090 - val_loss: 238.8091
Epoch 21/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 243.3242 - val_loss: 236.3024
Epoch 22/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 242.2569 - val_loss: 233.5992
Epoch 23/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 241.2087 - val_loss: 231.7032
Epoch 24/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 240.4694 - val_loss: 232.5089
Epoch 25/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 239.4159 - val_loss: 230.7227
Epoch 26/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 238.7003 - val_loss: 236.7693
Epoch 27/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 237.8597 - val_loss: 233.2039
Epoch 28/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 237.2424 - val_loss: 232.0101
Epoch 29/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 236.5608 - val_loss: 225.4691
Epoch 30/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 235.8406 - val_loss: 227.5831
Epoch 31/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 235.3942 - val_loss: 228.6028
Epoch 32/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 234.8519 - val_loss: 234.3283
Epoch 33/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 234.1952 - val_loss: 222.6313
Epoch 34/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 233.8991 - val_loss: 225.1717
Epoch 35/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 233.3171 - val_loss: 234.4531
Epoch 36/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 232.8185 - val_loss: 225.7110
Epoch 37/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 232.4942 - val_loss: 222.5184
Epoch 38/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 231.8869 - val_loss: 230.0821
Epoch 39/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 231.6350 - val_loss: 228.6221
Epoch 40/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 230.9796 - val_loss: 225.9271
Epoch 41/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 230.9109 - val_loss: 225.0951
Epoch 42/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 230.6509 - val_loss: 226.4674
Epoch 43/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 230.2194 - val_loss: 219.9844
Epoch 44/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 229.9342 - val_loss: 219.8927
Epoch 45/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 229.6327 - val_loss: 219.5252
Epoch 46/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 229.4399 - val_loss: 220.1311
Epoch 47/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 228.8841 - val_loss: 226.4149
Epoch 48/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 228.6731 - val_loss: 219.0681
Epoch 49/49
9445953/9445953 [==============================] - 21s 2us/step - loss: 228.5865 - val_loss: 226.3995

 CHILD 1 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 9000

         EPOCHS = 49

         CHILD ACCURACY = 217.11086086775444

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/41
2018-07-17 10:51:46.628168: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 10:51:46.633306: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 22s 2us/step - loss: 314.2948 - val_loss: 285.3994
Epoch 2/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 284.9151 - val_loss: 280.0466
Epoch 3/41
9445953/9445953 [==============================] - 24s 3us/step - loss: 280.8481 - val_loss: 278.6573
Epoch 4/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 279.0418 - val_loss: 275.5056
Epoch 5/41
9445953/9445953 [==============================] - 24s 3us/step - loss: 277.5637 - val_loss: 276.3840
Epoch 6/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 276.5559 - val_loss: 273.7254
Epoch 7/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 275.6016 - val_loss: 272.9835
Epoch 8/41
9445953/9445953 [==============================] - 24s 3us/step - loss: 274.8541 - val_loss: 272.0840
Epoch 9/41
9445953/9445953 [==============================] - 24s 3us/step - loss: 274.1614 - val_loss: 271.4213
Epoch 10/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 273.3351 - val_loss: 270.8055
Epoch 11/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 270.5488 - val_loss: 264.3546
Epoch 12/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 263.5227 - val_loss: 256.6682
Epoch 13/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 259.2022 - val_loss: 251.8955
Epoch 14/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 255.9608 - val_loss: 249.0020
Epoch 15/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 253.2760 - val_loss: 247.6479
Epoch 16/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 250.9661 - val_loss: 244.8389
Epoch 17/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 249.1346 - val_loss: 245.1293
Epoch 18/41
9445953/9445953 [==============================] - 24s 3us/step - loss: 247.3563 - val_loss: 248.5069
Epoch 19/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 245.7727 - val_loss: 241.7052
Epoch 20/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 244.5780 - val_loss: 237.4199
Epoch 21/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 243.5712 - val_loss: 235.2009
Epoch 22/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 242.5984 - val_loss: 234.9656
Epoch 23/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 241.7208 - val_loss: 233.1463
Epoch 24/41
9445953/9445953 [==============================] - 24s 3us/step - loss: 240.6680 - val_loss: 240.0767
Epoch 25/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 239.9968 - val_loss: 240.7365
Epoch 26/41
9445953/9445953 [==============================] - 24s 3us/step - loss: 239.3373 - val_loss: 231.2888
Epoch 27/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 238.7201 - val_loss: 239.0352
Epoch 28/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 237.9940 - val_loss: 232.2566
Epoch 29/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 237.6312 - val_loss: 238.7839
Epoch 30/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 237.0644 - val_loss: 232.2289
Epoch 31/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 236.5809 - val_loss: 230.4970
Epoch 32/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 236.1652 - val_loss: 225.8719
Epoch 33/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 235.7186 - val_loss: 228.9882
Epoch 34/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 235.1640 - val_loss: 233.7493
Epoch 35/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 234.7777 - val_loss: 226.1968
Epoch 36/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 234.4080 - val_loss: 229.6944
Epoch 37/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 233.9661 - val_loss: 229.3144
Epoch 38/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 233.6340 - val_loss: 230.3091
Epoch 39/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 233.2715 - val_loss: 226.2388
Epoch 40/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 232.9157 - val_loss: 225.2622
Epoch 41/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 232.7865 - val_loss: 225.9392

 CHILD 2 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 8000

         EPOCHS = 41

         CHILD ACCURACY = 220.72267649768105

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/49
2018-07-17 11:07:27.435210: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 11:07:27.441470: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 24s 3us/step - loss: 370.1158 - val_loss: 352.5832
Epoch 2/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 344.6389 - val_loss: 333.3878
Epoch 3/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 329.9144 - val_loss: 322.8681
Epoch 4/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 322.5233 - val_loss: 318.3436
Epoch 5/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.8496 - val_loss: 317.1897
Epoch 6/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3356 - val_loss: 317.0895
Epoch 7/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3034 - val_loss: 317.0898
Epoch 8/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3030 - val_loss: 317.0900
Epoch 9/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0900
Epoch 10/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0902
Epoch 11/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3031 - val_loss: 317.0902
Epoch 12/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0898
Epoch 13/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0894
Epoch 14/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3033 - val_loss: 317.0905
Epoch 15/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3031 - val_loss: 317.0895
Epoch 16/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3030 - val_loss: 317.0893
Epoch 17/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3031 - val_loss: 317.0901
Epoch 18/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0902
Epoch 19/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3031 - val_loss: 317.0903
Epoch 20/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3031 - val_loss: 317.0905
Epoch 21/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3041 - val_loss: 317.0899
Epoch 22/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0898
Epoch 23/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0907
Epoch 24/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0894
Epoch 25/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3031 - val_loss: 317.0914
Epoch 26/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3030 - val_loss: 317.0908
Epoch 27/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0900
Epoch 28/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0895
Epoch 29/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0904
Epoch 30/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0906
Epoch 31/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3031 - val_loss: 317.0893
Epoch 32/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0904
Epoch 33/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0905
Epoch 34/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0898
Epoch 35/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0897
Epoch 36/49
9445953/9445953 [==============================] - 24s 2us/step - loss: 319.3031 - val_loss: 317.0895
Epoch 37/49
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0905
Epoch 38/49
9445953/9445953 [==============================] - 24s 2us/step - loss: 319.3032 - val_loss: 317.0900
Epoch 39/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0904
Epoch 40/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0901
Epoch 41/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0906
Epoch 42/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0906
Epoch 43/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0909
Epoch 44/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0901
Epoch 45/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0906
Epoch 46/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3033 - val_loss: 317.0904
Epoch 47/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0917
Epoch 48/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0906
Epoch 49/49
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3032 - val_loss: 317.0896

 CHILD 3 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 8000

         EPOCHS = 49

         CHILD ACCURACY = 314.877921375261

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/41
2018-07-17 11:26:10.357977: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 11:26:10.364321: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 23s 2us/step - loss: 313.8413 - val_loss: 291.7522
Epoch 2/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 288.8355 - val_loss: 281.3796
Epoch 3/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 283.6920 - val_loss: 279.9700
Epoch 4/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 281.8493 - val_loss: 280.5434
Epoch 5/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 280.4844 - val_loss: 278.9846
Epoch 6/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 279.3992 - val_loss: 278.1238
Epoch 7/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 278.7419 - val_loss: 275.7653
Epoch 8/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 278.2183 - val_loss: 275.7540
Epoch 9/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 277.7284 - val_loss: 274.6823
Epoch 10/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 277.0929 - val_loss: 274.4280
Epoch 11/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 276.0131 - val_loss: 273.2710
Epoch 12/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 274.0822 - val_loss: 270.7556
Epoch 13/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 271.8668 - val_loss: 268.5732
Epoch 14/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 269.1701 - val_loss: 266.8800
Epoch 15/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 267.0303 - val_loss: 263.6205
Epoch 16/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 265.1828 - val_loss: 262.2260
Epoch 17/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 263.7477 - val_loss: 258.1652
Epoch 18/41
9445953/9445953 [==============================] - 23s 2us/step - loss: 262.4050 - val_loss: 257.7048
Epoch 19/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 261.1557 - val_loss: 259.8568
Epoch 20/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 260.1377 - val_loss: 255.3254
Epoch 21/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 259.3613 - val_loss: 255.0466
Epoch 22/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 258.7285 - val_loss: 255.3013
Epoch 23/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 258.1224 - val_loss: 255.7321
Epoch 24/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 257.6253 - val_loss: 253.6415
Epoch 25/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 257.0630 - val_loss: 252.2656
Epoch 26/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 256.7384 - val_loss: 253.0211
Epoch 27/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 256.2561 - val_loss: 252.2745
Epoch 28/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 255.9049 - val_loss: 251.4102
Epoch 29/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 255.6695 - val_loss: 256.9473
Epoch 30/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 255.3203 - val_loss: 251.7264
Epoch 31/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 254.9058 - val_loss: 251.4645
Epoch 32/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 254.7042 - val_loss: 252.4425
Epoch 33/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 254.3009 - val_loss: 250.0711
Epoch 34/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 254.0868 - val_loss: 249.8401
Epoch 35/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 253.8167 - val_loss: 250.2626
Epoch 36/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 253.6463 - val_loss: 251.1321
Epoch 37/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 253.3278 - val_loss: 250.6496
Epoch 38/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 253.1656 - val_loss: 248.2187
Epoch 39/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 252.8914 - val_loss: 254.5739
Epoch 40/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 252.7435 - val_loss: 255.0035
Epoch 41/41
9445953/9445953 [==============================] - 22s 2us/step - loss: 252.5390 - val_loss: 257.0559

 CHILD 4 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 9000

         EPOCHS = 41

         CHILD ACCURACY = 254.59111850368714

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/49
2018-07-17 11:41:27.255960: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 11:41:27.322001: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 25s 3us/step - loss: 308.7042 - val_loss: 283.5271
Epoch 2/49
9445953/9445953 [==============================] - 24s 3us/step - loss: 280.7480 - val_loss: 275.2306
Epoch 3/49
9445953/9445953 [==============================] - 24s 3us/step - loss: 276.1798 - val_loss: 273.1864
Epoch 4/49
9445953/9445953 [==============================] - 24s 3us/step - loss: 273.8741 - val_loss: 270.1427
Epoch 5/49
9445953/9445953 [==============================] - 24s 3us/step - loss: 270.7291 - val_loss: 265.0605
Epoch 6/49
9445953/9445953 [==============================] - 24s 3us/step - loss: 265.5335 - val_loss: 259.2194
Epoch 7/49
9445953/9445953 [==============================] - 24s 3us/step - loss: 261.0704 - val_loss: 254.7101
Epoch 8/49
9445953/9445953 [==============================] - 24s 3us/step - loss: 257.8410 - val_loss: 251.3207
Epoch 9/49
9445953/9445953 [==============================] - 24s 3us/step - loss: 255.2762 - val_loss: 256.3395
Epoch 10/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 252.9880 - val_loss: 247.0857
Epoch 11/49
9445953/9445953 [==============================] - 24s 3us/step - loss: 250.9283 - val_loss: 246.1459
Epoch 12/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 249.1117 - val_loss: 246.7471
Epoch 13/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 247.4038 - val_loss: 246.2138
Epoch 14/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 246.1733 - val_loss: 238.7939
Epoch 15/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 244.8711 - val_loss: 240.7462
Epoch 16/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.6806 - val_loss: 236.6002
Epoch 17/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.6431 - val_loss: 242.0315
Epoch 18/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.7459 - val_loss: 240.4300
Epoch 19/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.9357 - val_loss: 236.4005
Epoch 20/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.3068 - val_loss: 240.2892
Epoch 21/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.3021 - val_loss: 236.9316
Epoch 22/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.9237 - val_loss: 237.4974
Epoch 23/49
9445953/9445953 [==============================] - 26s 3us/step - loss: 238.2867 - val_loss: 241.3594
Epoch 24/49
9445953/9445953 [==============================] - 26s 3us/step - loss: 237.6868 - val_loss: 242.8028
Epoch 25/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.3189 - val_loss: 232.2898
Epoch 26/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.8479 - val_loss: 231.6052
Epoch 27/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.3436 - val_loss: 241.0098
Epoch 28/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.8914 - val_loss: 233.7514
Epoch 29/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.5283 - val_loss: 236.2135
Epoch 30/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.0509 - val_loss: 226.1834
Epoch 31/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.6212 - val_loss: 230.8721
Epoch 32/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.3358 - val_loss: 236.7622
Epoch 33/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.8814 - val_loss: 235.5308
Epoch 34/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.8538 - val_loss: 229.0861
Epoch 35/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.3471 - val_loss: 229.0957
Epoch 36/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 232.9604 - val_loss: 231.5744
Epoch 37/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 232.6861 - val_loss: 237.4165
Epoch 38/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 232.3270 - val_loss: 228.6522
Epoch 39/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 232.0778 - val_loss: 229.3110
Epoch 40/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 231.9298 - val_loss: 246.4723
Epoch 41/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 231.6255 - val_loss: 235.5202
Epoch 42/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 231.2782 - val_loss: 225.7460
Epoch 43/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 231.0180 - val_loss: 235.4204
Epoch 44/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 230.8316 - val_loss: 230.6310
Epoch 45/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 230.6095 - val_loss: 236.6361
Epoch 46/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 230.2601 - val_loss: 225.5650
Epoch 47/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 230.0748 - val_loss: 232.1817
Epoch 48/49
9445953/9445953 [==============================] - 25s 3us/step - loss: 229.9572 - val_loss: 232.2420
Epoch 49/49
9445953/9445953 [==============================] - 24s 3us/step - loss: 229.5653 - val_loss: 225.5765

 CHILD 5 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7000

         EPOCHS = 49

         CHILD ACCURACY = 227.8183009402086

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/45
2018-07-17 12:01:39.608690: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 12:01:39.614614: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 23s 2us/step - loss: 306.9633 - val_loss: 281.2177
Epoch 2/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 282.4654 - val_loss: 280.5645
Epoch 3/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 277.9757 - val_loss: 275.7858
Epoch 4/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 275.9847 - val_loss: 271.8095
Epoch 5/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 274.4370 - val_loss: 272.1338
Epoch 6/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 273.1299 - val_loss: 269.6349
Epoch 7/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 270.9453 - val_loss: 266.1638
Epoch 8/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 267.6821 - val_loss: 264.6243
Epoch 9/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 264.9706 - val_loss: 262.6708
Epoch 10/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 262.9165 - val_loss: 257.4103
Epoch 11/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 260.8772 - val_loss: 258.5670
Epoch 12/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 258.7918 - val_loss: 254.1156
Epoch 13/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 256.9249 - val_loss: 258.2990
Epoch 14/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 255.1064 - val_loss: 250.9370
Epoch 15/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 253.3558 - val_loss: 247.8567
Epoch 16/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 251.7626 - val_loss: 247.6062
Epoch 17/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 250.1158 - val_loss: 243.2568
Epoch 18/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 248.8890 - val_loss: 242.4748
Epoch 19/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 247.5138 - val_loss: 242.9003
Epoch 20/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 246.4679 - val_loss: 239.6469
Epoch 21/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 245.1738 - val_loss: 237.2901
Epoch 22/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 244.1811 - val_loss: 243.3429
Epoch 23/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 243.3217 - val_loss: 241.1169
Epoch 24/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 242.3121 - val_loss: 238.8150
Epoch 25/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 241.6577 - val_loss: 235.9800
Epoch 26/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 241.1174 - val_loss: 232.1818
Epoch 27/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 240.4488 - val_loss: 232.5219
Epoch 28/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 239.6803 - val_loss: 231.7486
Epoch 29/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 239.1262 - val_loss: 232.4284
Epoch 30/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 238.7739 - val_loss: 232.1287
Epoch 31/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 238.1409 - val_loss: 237.4914
Epoch 32/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 237.6041 - val_loss: 231.6130
Epoch 33/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 237.4032 - val_loss: 231.7253
Epoch 34/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 236.9362 - val_loss: 231.4294
Epoch 35/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 236.4275 - val_loss: 227.5497
Epoch 36/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 236.0351 - val_loss: 230.8216
Epoch 37/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 235.8865 - val_loss: 228.9834
Epoch 38/45
9445953/9445953 [==============================] - 22s 2us/step - loss: 235.3704 - val_loss: 226.7507
Epoch 39/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 235.0152 - val_loss: 230.9616
Epoch 40/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 234.8954 - val_loss: 232.3184
Epoch 41/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 234.4938 - val_loss: 231.6341
Epoch 42/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 234.1790 - val_loss: 224.3193
Epoch 43/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 233.9466 - val_loss: 230.1394
Epoch 44/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 233.7200 - val_loss: 232.9949
Epoch 45/45
9445953/9445953 [==============================] - 23s 2us/step - loss: 233.4421 - val_loss: 232.1469

 CHILD 6 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 9000

         EPOCHS = 45

         CHILD ACCURACY = 225.9782991717697



 QUEUE SIZE BEFORE GET = 2


 NODE SELECTED <<<------ Epochs = 41 -------- BatchSize = 6000--------- Accuracy = 219.2186484041065 -------->>>

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/37
2018-07-17 12:18:38.020284: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 12:18:38.027251: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 25s 3us/step - loss: 309.8399 - val_loss: 291.6815
Epoch 2/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 284.0069 - val_loss: 280.8473
Epoch 3/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 280.1503 - val_loss: 277.6643
Epoch 4/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 278.5239 - val_loss: 276.2791
Epoch 5/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 277.3128 - val_loss: 274.3928
Epoch 6/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 275.9084 - val_loss: 275.2994
Epoch 7/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 273.5642 - val_loss: 268.9962
Epoch 8/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 271.2726 - val_loss: 268.0591
Epoch 9/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 268.9376 - val_loss: 263.0036
Epoch 10/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 266.2203 - val_loss: 260.8806
Epoch 11/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 262.6065 - val_loss: 258.9770
Epoch 12/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 259.3075 - val_loss: 252.1306
Epoch 13/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 256.6120 - val_loss: 256.2219
Epoch 14/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 254.2690 - val_loss: 246.1215
Epoch 15/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 252.3324 - val_loss: 244.3150
Epoch 16/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 250.6717 - val_loss: 243.3934
Epoch 17/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 249.1117 - val_loss: 243.5749
Epoch 18/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 247.9386 - val_loss: 239.1148
Epoch 19/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 246.8360 - val_loss: 239.8805
Epoch 20/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 245.6555 - val_loss: 245.0871
Epoch 21/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 244.9435 - val_loss: 237.9727
Epoch 22/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 244.0357 - val_loss: 237.8360
Epoch 23/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.2115 - val_loss: 235.3770
Epoch 24/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.5507 - val_loss: 235.7654
Epoch 25/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.9955 - val_loss: 238.9559
Epoch 26/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.2902 - val_loss: 237.7258
Epoch 27/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.7033 - val_loss: 231.2848
Epoch 28/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.3142 - val_loss: 247.1037
Epoch 29/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.6329 - val_loss: 232.9956
Epoch 30/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.1848 - val_loss: 239.8898
Epoch 31/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.6593 - val_loss: 236.9935
Epoch 32/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.3857 - val_loss: 231.8750
Epoch 33/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.7390 - val_loss: 232.7578
Epoch 34/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.2497 - val_loss: 233.6920
Epoch 35/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.1466 - val_loss: 226.2558
Epoch 36/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.5645 - val_loss: 229.0464
Epoch 37/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.3408 - val_loss: 229.7278

 CHILD 1 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7000

         EPOCHS = 37

         CHILD ACCURACY = 222.53557888405888

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/41
2018-07-17 12:33:51.854818: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 12:33:51.858947: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 28s 3us/step - loss: 297.8733 - val_loss: 277.1376
Epoch 2/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 277.2843 - val_loss: 280.2267
Epoch 3/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 274.4996 - val_loss: 272.3531
Epoch 4/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 273.1887 - val_loss: 270.0928
Epoch 5/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 272.2032 - val_loss: 271.7690
Epoch 6/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 271.1431 - val_loss: 274.6657
Epoch 7/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 267.2064 - val_loss: 271.4760
Epoch 8/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 262.2392 - val_loss: 258.0084
Epoch 9/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 258.6484 - val_loss: 253.2547
Epoch 10/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 255.9590 - val_loss: 251.6943
Epoch 11/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 253.5245 - val_loss: 253.8212
Epoch 12/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 251.5381 - val_loss: 248.0791
Epoch 13/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 249.5890 - val_loss: 242.6779
Epoch 14/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 248.0756 - val_loss: 245.6392
Epoch 15/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 246.5832 - val_loss: 269.9225
Epoch 16/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 245.4038 - val_loss: 246.7855
Epoch 17/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 244.2927 - val_loss: 249.0379
Epoch 18/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 243.5546 - val_loss: 238.3685
Epoch 19/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 242.6262 - val_loss: 236.6237
Epoch 20/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 241.8118 - val_loss: 242.3316
Epoch 21/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 241.2073 - val_loss: 254.5290
Epoch 22/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 240.6028 - val_loss: 238.0216
Epoch 23/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 239.8815 - val_loss: 233.4144
Epoch 24/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 239.3851 - val_loss: 239.1466
Epoch 25/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 238.7996 - val_loss: 256.5401
Epoch 26/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 238.1807 - val_loss: 249.8128
Epoch 27/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 237.7655 - val_loss: 236.1820
Epoch 28/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 237.2248 - val_loss: 232.7154
Epoch 29/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 236.7453 - val_loss: 236.6718
Epoch 30/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 236.3894 - val_loss: 231.4527
Epoch 31/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 235.9306 - val_loss: 242.7743
Epoch 32/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 235.6322 - val_loss: 254.2306
Epoch 33/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 235.3873 - val_loss: 235.1725
Epoch 34/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 234.9788 - val_loss: 230.7079
Epoch 35/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 234.5704 - val_loss: 227.2904
Epoch 36/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 234.3021 - val_loss: 230.3937
Epoch 37/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 234.1158 - val_loss: 228.6769
Epoch 38/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 233.5347 - val_loss: 228.0442
Epoch 39/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 233.5021 - val_loss: 246.2142
Epoch 40/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 233.0747 - val_loss: 231.0825
Epoch 41/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 232.8703 - val_loss: 232.9490

 CHILD 2 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 41

         CHILD ACCURACY = 235.8994810321531

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/37
2018-07-17 12:52:23.873442: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 12:52:23.879232: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 28s 3us/step - loss: 299.2960 - val_loss: 308.7352
Epoch 2/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 278.6009 - val_loss: 286.1757
Epoch 3/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 273.3584 - val_loss: 277.4814
Epoch 4/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 270.3248 - val_loss: 270.3514
Epoch 5/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 267.9246 - val_loss: 268.0595
Epoch 6/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 265.3077 - val_loss: 267.7369
Epoch 7/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 262.9658 - val_loss: 258.1904
Epoch 8/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 259.9907 - val_loss: 259.3424
Epoch 9/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 256.6088 - val_loss: 254.1569
Epoch 10/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 254.0003 - val_loss: 248.1037
Epoch 11/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 252.0507 - val_loss: 257.0785
Epoch 12/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 250.2676 - val_loss: 244.4463
Epoch 13/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 248.3933 - val_loss: 250.7920
Epoch 14/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 246.7781 - val_loss: 252.9260
Epoch 15/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 245.2354 - val_loss: 237.8136
Epoch 16/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 243.7557 - val_loss: 238.9538
Epoch 17/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 242.5542 - val_loss: 237.9643
Epoch 18/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 241.4661 - val_loss: 234.3228
Epoch 19/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 240.4541 - val_loss: 244.4885
Epoch 20/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 239.6496 - val_loss: 232.6336
Epoch 21/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 238.7970 - val_loss: 239.8568
Epoch 22/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 238.1442 - val_loss: 237.2764
Epoch 23/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 237.3746 - val_loss: 230.6706
Epoch 24/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 236.7383 - val_loss: 229.1194
Epoch 25/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 236.1233 - val_loss: 231.2928
Epoch 26/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 235.4888 - val_loss: 226.6177
Epoch 27/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 234.9793 - val_loss: 241.0123
Epoch 28/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 234.4827 - val_loss: 228.3252
Epoch 29/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 233.9623 - val_loss: 237.6940
Epoch 30/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 233.4359 - val_loss: 225.7706
Epoch 31/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 232.7831 - val_loss: 222.5467
Epoch 32/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 232.4925 - val_loss: 255.9254
Epoch 33/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 232.1361 - val_loss: 222.7445
Epoch 34/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 231.5910 - val_loss: 227.2651
Epoch 35/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 231.3062 - val_loss: 249.7737
Epoch 36/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 230.8259 - val_loss: 220.8422
Epoch 37/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 230.3197 - val_loss: 229.9505

 CHILD 3 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 37

         CHILD ACCURACY = 232.90507257355543

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/37
2018-07-17 13:09:09.271105: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 13:09:09.277267: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 26s 3us/step - loss: 313.2033 - val_loss: 289.3519
Epoch 2/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 282.7900 - val_loss: 276.9023
Epoch 3/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 278.7103 - val_loss: 277.9281
Epoch 4/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 276.5155 - val_loss: 273.4283
Epoch 5/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 274.6360 - val_loss: 272.1713
Epoch 6/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 271.9180 - val_loss: 265.0816
Epoch 7/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 265.5344 - val_loss: 257.8259
Epoch 8/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 260.9161 - val_loss: 254.4028
Epoch 9/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 258.0412 - val_loss: 256.2008
Epoch 10/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 255.5530 - val_loss: 248.1190
Epoch 11/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 253.2354 - val_loss: 248.7766
Epoch 12/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 251.1119 - val_loss: 247.4770
Epoch 13/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 249.2411 - val_loss: 248.1561
Epoch 14/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 247.1968 - val_loss: 245.7713
Epoch 15/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 245.6603 - val_loss: 241.8395
Epoch 16/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 244.2877 - val_loss: 236.7740
Epoch 17/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.0564 - val_loss: 235.7755
Epoch 18/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.9320 - val_loss: 232.5210
Epoch 19/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.8069 - val_loss: 241.6625
Epoch 20/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.1330 - val_loss: 232.5916
Epoch 21/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.2350 - val_loss: 236.2247
Epoch 22/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.4800 - val_loss: 231.2272
Epoch 23/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.7639 - val_loss: 240.6570
Epoch 24/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.1410 - val_loss: 239.9623
Epoch 25/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.5255 - val_loss: 255.1504
Epoch 26/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.9804 - val_loss: 235.0114
Epoch 27/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.3087 - val_loss: 229.7766
Epoch 28/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.6540 - val_loss: 235.2729
Epoch 29/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.2262 - val_loss: 228.9965
Epoch 30/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.7986 - val_loss: 229.1873
Epoch 31/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.4315 - val_loss: 226.1070
Epoch 32/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 232.9119 - val_loss: 233.1148
Epoch 33/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 232.6710 - val_loss: 227.2802
Epoch 34/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 232.2712 - val_loss: 227.0702
Epoch 35/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 231.8526 - val_loss: 225.7771
Epoch 36/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 231.1497 - val_loss: 232.7449
Epoch 37/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 231.0924 - val_loss: 225.0598

 CHILD 4 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 6000

         EPOCHS = 37

         CHILD ACCURACY = 223.7345339783099



 QUEUE SIZE BEFORE GET = 1


 NODE SELECTED <<<------ Epochs = 41 -------- BatchSize = 7000--------- Accuracy = 227.79588350645906 -------->>>

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/37
2018-07-17 13:24:47.012298: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 13:24:47.019977: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 25s 3us/step - loss: 303.5794 - val_loss: 287.6235
Epoch 2/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 281.3055 - val_loss: 274.7773
Epoch 3/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 275.7426 - val_loss: 275.2567
Epoch 4/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 273.4253 - val_loss: 268.9185
Epoch 5/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.9875 - val_loss: 267.8509
Epoch 6/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 265.1683 - val_loss: 264.3588
Epoch 7/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 261.3975 - val_loss: 288.5793
Epoch 8/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 258.4211 - val_loss: 271.5348
Epoch 9/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 255.7205 - val_loss: 248.7319
Epoch 10/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 253.6281 - val_loss: 253.1511
Epoch 11/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 251.6478 - val_loss: 246.7070
Epoch 12/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 249.9968 - val_loss: 242.0650
Epoch 13/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 248.5268 - val_loss: 244.1010
Epoch 14/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 247.1702 - val_loss: 243.3938
Epoch 15/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 246.0935 - val_loss: 242.9982
Epoch 16/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 245.2192 - val_loss: 242.4497
Epoch 17/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 244.1952 - val_loss: 251.9798
Epoch 18/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.3973 - val_loss: 236.6050
Epoch 19/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.6585 - val_loss: 238.9435
Epoch 20/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.2153 - val_loss: 233.6155
Epoch 21/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.4480 - val_loss: 233.7214
Epoch 22/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.9799 - val_loss: 234.4834
Epoch 23/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.1845 - val_loss: 235.1400
Epoch 24/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.8323 - val_loss: 231.1338
Epoch 25/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.3883 - val_loss: 251.3456
Epoch 26/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.9832 - val_loss: 234.7630
Epoch 27/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.5898 - val_loss: 243.5874
Epoch 28/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.2205 - val_loss: 240.8885
Epoch 29/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.7464 - val_loss: 246.2380
Epoch 30/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.3928 - val_loss: 229.4740
Epoch 31/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.1408 - val_loss: 232.5267
Epoch 32/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.7523 - val_loss: 234.3885
Epoch 33/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.2702 - val_loss: 238.2529
Epoch 34/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.1829 - val_loss: 229.7449
Epoch 35/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.7456 - val_loss: 245.4247
Epoch 36/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.6807 - val_loss: 231.0542
Epoch 37/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.1953 - val_loss: 234.6183

 CHILD 1 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7000

         EPOCHS = 37

         CHILD ACCURACY = 234.7199170483732

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/41
2018-07-17 13:40:01.726533: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 13:40:01.731675: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 26s 3us/step - loss: 298.5454 - val_loss: 277.6360
Epoch 2/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 276.5398 - val_loss: 274.2599
Epoch 3/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 270.2324 - val_loss: 264.0419
Epoch 4/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 265.8396 - val_loss: 259.9252
Epoch 5/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 261.9494 - val_loss: 256.4345
Epoch 6/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 258.6025 - val_loss: 261.5850
Epoch 7/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 255.7454 - val_loss: 248.3697
Epoch 8/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 253.2843 - val_loss: 247.7925
Epoch 9/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 251.3508 - val_loss: 254.8263
Epoch 10/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 249.5352 - val_loss: 249.9331
Epoch 11/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 247.9124 - val_loss: 245.1898
Epoch 12/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 246.4718 - val_loss: 237.5061
Epoch 13/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 245.2755 - val_loss: 245.3229
Epoch 14/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 244.2051 - val_loss: 251.2449
Epoch 15/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.2137 - val_loss: 238.3693
Epoch 16/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.4055 - val_loss: 237.3919
Epoch 17/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.6619 - val_loss: 234.5278
Epoch 18/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.6226 - val_loss: 235.5433
Epoch 19/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.0381 - val_loss: 235.1072
Epoch 20/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.4154 - val_loss: 231.9051
Epoch 21/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.7726 - val_loss: 230.3684
Epoch 22/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.1026 - val_loss: 235.2800
Epoch 23/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.7012 - val_loss: 230.7992
Epoch 24/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.2339 - val_loss: 237.5503
Epoch 25/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.8042 - val_loss: 239.3839
Epoch 26/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.2690 - val_loss: 236.0151
Epoch 27/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.9624 - val_loss: 233.7283
Epoch 28/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.4812 - val_loss: 234.4180
Epoch 29/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.2193 - val_loss: 231.2950
Epoch 30/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.8035 - val_loss: 239.0386
Epoch 31/41
9445953/9445953 [==============================] - 26s 3us/step - loss: 234.4784 - val_loss: 245.1975
Epoch 32/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.0188 - val_loss: 240.4271
Epoch 33/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.8208 - val_loss: 236.3868
Epoch 34/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.4947 - val_loss: 233.9328
Epoch 35/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.2113 - val_loss: 226.4125
Epoch 36/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 232.7653 - val_loss: 231.2136
Epoch 37/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 232.6813 - val_loss: 226.8363
Epoch 38/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 232.2469 - val_loss: 226.1709
Epoch 39/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 231.9248 - val_loss: 225.4638
Epoch 40/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 231.7831 - val_loss: 229.5697
Epoch 41/41
9445953/9445953 [==============================] - 25s 3us/step - loss: 231.6452 - val_loss: 226.7092

 CHILD 2 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 6000

         EPOCHS = 41

         CHILD ACCURACY = 222.05674764264245


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 1 <<<<<<<<<<<<<<<<<<<<<<<<<<<

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/37
2018-07-17 13:57:19.838012: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 13:57:19.843635: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 26s 3us/step - loss: 299.6215 - val_loss: 280.1225
Epoch 2/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 279.8660 - val_loss: 278.4038
Epoch 3/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 277.1707 - val_loss: 273.4230
Epoch 4/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 275.8770 - val_loss: 272.6939
Epoch 5/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 274.4351 - val_loss: 270.9172
Epoch 6/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 268.9716 - val_loss: 261.8868
Epoch 7/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 263.2839 - val_loss: 263.9564
Epoch 8/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 259.6569 - val_loss: 269.3244
Epoch 9/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 257.0391 - val_loss: 252.0279
Epoch 10/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 254.7320 - val_loss: 247.1758
Epoch 11/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 252.6153 - val_loss: 262.4556
Epoch 12/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 250.6815 - val_loss: 243.7362
Epoch 13/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 249.0693 - val_loss: 247.2220
Epoch 14/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 247.4567 - val_loss: 242.5373
Epoch 15/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 246.1857 - val_loss: 243.5776
Epoch 16/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 244.9740 - val_loss: 238.8957
Epoch 17/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.8362 - val_loss: 241.3467
Epoch 18/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.0025 - val_loss: 239.6463
Epoch 19/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.0915 - val_loss: 235.3920
Epoch 20/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.1581 - val_loss: 234.5288
Epoch 21/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.4281 - val_loss: 235.7788
Epoch 22/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.8758 - val_loss: 232.8002
Epoch 23/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.2635 - val_loss: 232.5051
Epoch 24/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.7169 - val_loss: 231.0393
Epoch 25/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.1169 - val_loss: 243.4127
Epoch 26/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.5862 - val_loss: 236.9689
Epoch 27/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.1415 - val_loss: 235.0406
Epoch 28/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.6970 - val_loss: 230.2448
Epoch 29/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.3379 - val_loss: 234.9188
Epoch 30/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.8077 - val_loss: 231.3681
Epoch 31/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.3927 - val_loss: 232.5173
Epoch 32/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.0913 - val_loss: 241.8336
Epoch 33/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.8409 - val_loss: 224.9196
Epoch 34/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.4884 - val_loss: 238.6687
Epoch 35/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.9538 - val_loss: 233.6639
Epoch 36/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.7739 - val_loss: 232.3344
Epoch 37/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.4243 - val_loss: 244.2183

 CHILD 3 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 6000

         EPOCHS = 37

         CHILD ACCURACY = 240.53260461517215

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/37
2018-07-17 14:13:01.218142: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 14:13:01.224259: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.0888 - val_loss: 295.5109
Epoch 2/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 290.2458 - val_loss: 281.1109
Epoch 3/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 282.7683 - val_loss: 278.8683
Epoch 4/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 279.9512 - val_loss: 283.6444
Epoch 5/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 277.6250 - val_loss: 276.7779
Epoch 6/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 275.4086 - val_loss: 272.1951
Epoch 7/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 272.0936 - val_loss: 265.8387
Epoch 8/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 267.0366 - val_loss: 265.6228
Epoch 9/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 262.9230 - val_loss: 255.1601
Epoch 10/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 259.8822 - val_loss: 254.1136
Epoch 11/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 257.6591 - val_loss: 250.7316
Epoch 12/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 255.8049 - val_loss: 251.0595
Epoch 13/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 254.0678 - val_loss: 249.6871
Epoch 14/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 252.5076 - val_loss: 246.4041
Epoch 15/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 250.8689 - val_loss: 243.3762
Epoch 16/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 249.5348 - val_loss: 241.6852
Epoch 17/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 248.1464 - val_loss: 242.7145
Epoch 18/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 247.1235 - val_loss: 239.4343
Epoch 19/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 246.0627 - val_loss: 239.5558
Epoch 20/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 245.1879 - val_loss: 238.1735
Epoch 21/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 244.2706 - val_loss: 236.0219
Epoch 22/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 243.4865 - val_loss: 237.7470
Epoch 23/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 242.5669 - val_loss: 234.3993
Epoch 24/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 242.0886 - val_loss: 234.9467
Epoch 25/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 241.5129 - val_loss: 239.3081
Epoch 26/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 240.9287 - val_loss: 232.1586
Epoch 27/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 240.2709 - val_loss: 235.4730
Epoch 28/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 239.8852 - val_loss: 235.4761
Epoch 29/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 239.2814 - val_loss: 233.0395
Epoch 30/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 238.7885 - val_loss: 231.6121
Epoch 31/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 238.5233 - val_loss: 228.3134
Epoch 32/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 237.9655 - val_loss: 233.1044
Epoch 33/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 237.7988 - val_loss: 228.3207
Epoch 34/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 237.1869 - val_loss: 236.8801
Epoch 35/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 237.0823 - val_loss: 230.7107
Epoch 36/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 236.5768 - val_loss: 229.4313
Epoch 37/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 236.1453 - val_loss: 230.5138

 CHILD 4 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 8000

         EPOCHS = 37

         CHILD ACCURACY = 227.02010882516464


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 2 <<<<<<<<<<<<<<<<<<<<<<<<<<<



 QUEUE SIZE BEFORE GET = 2


 NODE SELECTED <<<------ Epochs = 41 -------- BatchSize = 6000--------- Accuracy = 222.05674764264245 -------->>>

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/37
2018-07-17 14:27:36.068556: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 14:27:36.075171: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 25s 3us/step - loss: 304.5291 - val_loss: 288.9854
Epoch 2/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 280.6886 - val_loss: 276.4408
Epoch 3/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 276.8907 - val_loss: 273.3022
Epoch 4/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 274.6396 - val_loss: 278.4905
Epoch 5/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 273.1913 - val_loss: 271.3936
Epoch 6/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 271.3826 - val_loss: 268.1732
Epoch 7/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 268.4283 - val_loss: 264.5538
Epoch 8/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 263.6439 - val_loss: 262.3289
Epoch 9/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 259.7065 - val_loss: 253.3336
Epoch 10/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 256.7477 - val_loss: 252.6470
Epoch 11/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 254.3975 - val_loss: 247.2779
Epoch 12/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 252.5628 - val_loss: 251.5856
Epoch 13/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 250.6781 - val_loss: 247.5272
Epoch 14/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 249.1804 - val_loss: 245.4559
Epoch 15/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 247.6941 - val_loss: 242.1809
Epoch 16/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 246.4261 - val_loss: 240.7752
Epoch 17/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 245.1858 - val_loss: 239.0789
Epoch 18/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.7588 - val_loss: 235.0020
Epoch 19/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.7323 - val_loss: 236.4201
Epoch 20/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.7654 - val_loss: 238.3407
Epoch 21/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.6238 - val_loss: 236.2790
Epoch 22/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.9500 - val_loss: 242.1811
Epoch 23/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.9432 - val_loss: 233.4871
Epoch 24/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.0043 - val_loss: 228.5103
Epoch 25/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.3917 - val_loss: 232.4025
Epoch 26/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.7020 - val_loss: 226.9002
Epoch 27/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.8719 - val_loss: 228.4441
Epoch 28/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.1859 - val_loss: 227.3759
Epoch 29/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.5759 - val_loss: 225.7296
Epoch 30/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.2633 - val_loss: 229.7000
Epoch 31/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.5954 - val_loss: 223.0853
Epoch 32/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.0249 - val_loss: 230.4619
Epoch 33/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 232.5121 - val_loss: 233.2063
Epoch 34/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 232.0313 - val_loss: 232.9059
Epoch 35/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 231.6176 - val_loss: 222.3426
Epoch 36/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 231.1926 - val_loss: 232.4493
Epoch 37/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 230.8796 - val_loss: 222.2641

 CHILD 1 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7000

         EPOCHS = 37

         CHILD ACCURACY = 223.5506537522976

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/41
2018-07-17 14:42:56.665391: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 14:42:56.670524: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 28s 3us/step - loss: 299.1671 - val_loss: 279.3207
Epoch 2/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 278.6390 - val_loss: 280.2223
Epoch 3/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 275.4478 - val_loss: 273.1936
Epoch 4/41
9445953/9445953 [==============================] - 29s 3us/step - loss: 273.4387 - val_loss: 270.6020
Epoch 5/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 270.0147 - val_loss: 265.9128
Epoch 6/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 264.1605 - val_loss: 259.2853
Epoch 7/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 260.1191 - val_loss: 259.7826
Epoch 8/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 257.0610 - val_loss: 253.8682
Epoch 9/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 254.5774 - val_loss: 253.7473
Epoch 10/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 252.3235 - val_loss: 251.2636
Epoch 11/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 250.2747 - val_loss: 249.5776
Epoch 12/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 248.5848 - val_loss: 244.2261
Epoch 13/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 246.8936 - val_loss: 251.5307
Epoch 14/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 245.3493 - val_loss: 240.9997
Epoch 15/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 243.7212 - val_loss: 236.0072
Epoch 16/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 242.4382 - val_loss: 254.6399
Epoch 17/41
9445953/9445953 [==============================] - 29s 3us/step - loss: 241.3255 - val_loss: 237.6735
Epoch 18/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 240.2505 - val_loss: 231.4801
Epoch 19/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 239.2926 - val_loss: 253.6488
Epoch 20/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 238.2916 - val_loss: 232.1914
Epoch 21/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 237.4367 - val_loss: 239.7209
Epoch 22/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 236.8093 - val_loss: 249.4915
Epoch 23/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 235.8936 - val_loss: 237.7078
Epoch 24/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 235.2115 - val_loss: 237.9375
Epoch 25/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 234.7964 - val_loss: 233.0141
Epoch 26/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 234.0805 - val_loss: 262.7724
Epoch 27/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 233.8012 - val_loss: 245.8028
Epoch 28/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 233.1444 - val_loss: 226.7335
Epoch 29/41
9445953/9445953 [==============================] - 26s 3us/step - loss: 232.4775 - val_loss: 229.7786
Epoch 30/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 232.0925 - val_loss: 224.0363
Epoch 31/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 231.8034 - val_loss: 228.0453
Epoch 32/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 231.3399 - val_loss: 256.6899
Epoch 33/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 231.0149 - val_loss: 227.5216
Epoch 34/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 230.6048 - val_loss: 234.8583
Epoch 35/41
9445953/9445953 [==============================] - 27s 3us/step - loss: 230.2216 - val_loss: 228.8133
Epoch 36/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 229.6703 - val_loss: 235.3259
Epoch 37/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 229.6306 - val_loss: 224.7401
Epoch 38/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 229.0113 - val_loss: 236.7653
Epoch 39/41
9445953/9445953 [==============================] - 28s 3us/step - loss: 228.8857 - val_loss: 239.6118
Epoch 40/41
9445953/9445953 [==============================] - 30s 3us/step - loss: 228.4379 - val_loss: 228.2906
Epoch 41/41
9445953/9445953 [==============================] - 33s 3us/step - loss: 228.0947 - val_loss: 246.7262

 CHILD 2 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 41

         CHILD ACCURACY = 247.0895628514581

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/37
2018-07-17 15:01:58.481188: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 15:01:58.490493: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 29s 3us/step - loss: 361.7038 - val_loss: 339.8050
Epoch 2/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 333.7497 - val_loss: 321.8703
Epoch 3/37
9445953/9445953 [==============================] - 28s 3us/step - loss: 321.1527 - val_loss: 317.3212
Epoch 4/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3541 - val_loss: 317.0894
Epoch 5/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3030 - val_loss: 317.0899
Epoch 6/37
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0902
Epoch 7/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3030 - val_loss: 317.0921
Epoch 8/37
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0899
Epoch 9/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3032 - val_loss: 317.0918
Epoch 10/37
9445953/9445953 [==============================] - 29s 3us/step - loss: 319.3033 - val_loss: 317.0894
Epoch 11/37
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0916
Epoch 12/37
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0900
Epoch 13/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3032 - val_loss: 317.0902
Epoch 14/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3033 - val_loss: 317.0902
Epoch 15/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3032 - val_loss: 317.0901
Epoch 16/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3032 - val_loss: 317.0900
Epoch 17/37
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3031 - val_loss: 317.0900
Epoch 18/37
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3032 - val_loss: 317.0925
Epoch 19/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3031 - val_loss: 317.0922
Epoch 20/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3033 - val_loss: 317.0909
Epoch 21/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3031 - val_loss: 317.0894
Epoch 22/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3033 - val_loss: 317.0898
Epoch 23/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3032 - val_loss: 317.0901
Epoch 24/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3031 - val_loss: 317.0903
Epoch 25/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3030 - val_loss: 317.0907
Epoch 26/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3032 - val_loss: 317.0897
Epoch 27/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3031 - val_loss: 317.0905
Epoch 28/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3032 - val_loss: 317.0896
Epoch 29/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3031 - val_loss: 317.0898
Epoch 30/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3033 - val_loss: 317.0909
Epoch 31/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3033 - val_loss: 317.0900
Epoch 32/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3033 - val_loss: 317.0906
Epoch 33/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3033 - val_loss: 317.0907
Epoch 34/37
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3031 - val_loss: 317.0903
Epoch 35/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3032 - val_loss: 317.0900
Epoch 36/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 319.3034 - val_loss: 317.0898
Epoch 37/37
9445953/9445953 [==============================] - 28s 3us/step - loss: 319.3033 - val_loss: 317.0907

 CHILD 3 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 37

         CHILD ACCURACY = 314.8771851848221

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/37
2018-07-17 15:18:49.210803: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 15:18:49.217002: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 26s 3us/step - loss: 342.3011 - val_loss: 296.0184
Epoch 2/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 283.9648 - val_loss: 280.4968
Epoch 3/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 278.2626 - val_loss: 274.0466
Epoch 4/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 276.1800 - val_loss: 280.1983
Epoch 5/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 274.8463 - val_loss: 273.1758
Epoch 6/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 273.8961 - val_loss: 270.9646
Epoch 7/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 273.1471 - val_loss: 279.6673
Epoch 8/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 272.5057 - val_loss: 272.6124
Epoch 9/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 271.9942 - val_loss: 271.0058
Epoch 10/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 271.4694 - val_loss: 270.1298
Epoch 11/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 270.9475 - val_loss: 268.4542
Epoch 12/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 270.3435 - val_loss: 271.7926
Epoch 13/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 268.5670 - val_loss: 266.9852
Epoch 14/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 262.0208 - val_loss: 260.9069
Epoch 15/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 256.9547 - val_loss: 251.7437
Epoch 16/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 253.4187 - val_loss: 248.6282
Epoch 17/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 250.4746 - val_loss: 243.7204
Epoch 18/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 248.1888 - val_loss: 246.4710
Epoch 19/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 246.3825 - val_loss: 247.6993
Epoch 20/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 244.8287 - val_loss: 237.6481
Epoch 21/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 243.4351 - val_loss: 240.3491
Epoch 22/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 242.2523 - val_loss: 241.4097
Epoch 23/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 241.2255 - val_loss: 239.2236
Epoch 24/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 240.3533 - val_loss: 232.4385
Epoch 25/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 239.3666 - val_loss: 247.7512
Epoch 26/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 238.8423 - val_loss: 243.6074
Epoch 27/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 238.0639 - val_loss: 236.3023
Epoch 28/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 237.3648 - val_loss: 236.9603
Epoch 29/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 236.8495 - val_loss: 234.6669
Epoch 30/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 236.2888 - val_loss: 233.9389
Epoch 31/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.7418 - val_loss: 230.1161
Epoch 32/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.2320 - val_loss: 231.1226
Epoch 33/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.7812 - val_loss: 231.1069
Epoch 34/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.4387 - val_loss: 231.5325
Epoch 35/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.0013 - val_loss: 241.7033
Epoch 36/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.5109 - val_loss: 238.1467
Epoch 37/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.0504 - val_loss: 233.8005

 CHILD 4 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 6000

         EPOCHS = 37

         CHILD ACCURACY = 238.841176194474



 QUEUE SIZE BEFORE GET = 1


 NODE SELECTED <<<------ Epochs = 37 -------- BatchSize = 8000--------- Accuracy = 227.02010882516464 -------->>>

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/33
2018-07-17 15:34:47.208732: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 15:34:47.214852: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 25s 3us/step - loss: 306.0214 - val_loss: 282.3881
Epoch 2/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 282.6971 - val_loss: 276.4753
Epoch 3/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 277.7341 - val_loss: 276.2912
Epoch 4/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 275.4140 - val_loss: 279.2273
Epoch 5/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 273.8465 - val_loss: 270.9366
Epoch 6/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 272.2814 - val_loss: 267.9837
Epoch 7/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 268.8291 - val_loss: 264.0278
Epoch 8/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 263.4524 - val_loss: 255.8583
Epoch 9/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 258.9674 - val_loss: 256.4852
Epoch 10/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 255.8628 - val_loss: 254.1775
Epoch 11/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 253.3721 - val_loss: 248.0321
Epoch 12/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 251.3561 - val_loss: 244.9357
Epoch 13/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 249.4926 - val_loss: 245.9325
Epoch 14/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 247.7969 - val_loss: 241.4681
Epoch 15/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 246.2703 - val_loss: 238.0315
Epoch 16/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 244.8252 - val_loss: 240.5481
Epoch 17/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.5253 - val_loss: 240.7789
Epoch 18/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.4676 - val_loss: 249.9059
Epoch 19/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.3519 - val_loss: 235.1084
Epoch 20/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.1772 - val_loss: 233.5049
Epoch 21/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.3678 - val_loss: 231.8366
Epoch 22/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.4531 - val_loss: 232.1744
Epoch 23/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 237.5837 - val_loss: 227.7692
Epoch 24/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 236.8237 - val_loss: 232.6212
Epoch 25/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.0117 - val_loss: 227.2283
Epoch 26/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.2897 - val_loss: 225.5222
Epoch 27/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.7030 - val_loss: 229.0447
Epoch 28/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.1163 - val_loss: 224.1277
Epoch 29/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.3779 - val_loss: 227.6359
Epoch 30/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 232.7573 - val_loss: 237.6690
Epoch 31/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 232.3779 - val_loss: 227.9596
Epoch 32/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 231.6846 - val_loss: 220.6204
Epoch 33/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 231.2894 - val_loss: 225.1142

 CHILD 1 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7000

         EPOCHS = 33

         CHILD ACCURACY = 223.6543352732685


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 1 <<<<<<<<<<<<<<<<<<<<<<<<<<<

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/37
2018-07-17 15:48:22.981906: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 15:48:22.989605: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 25s 3us/step - loss: 311.3186 - val_loss: 284.3916
Epoch 2/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 280.6504 - val_loss: 275.0223
Epoch 3/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 276.1234 - val_loss: 273.8559
Epoch 4/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 271.6880 - val_loss: 270.4566
Epoch 5/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 267.8612 - val_loss: 263.6161
Epoch 6/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 264.6334 - val_loss: 259.0180
Epoch 7/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 261.7187 - val_loss: 259.0315
Epoch 8/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 258.9536 - val_loss: 254.1637
Epoch 9/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 256.1366 - val_loss: 249.3574
Epoch 10/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 253.8546 - val_loss: 259.1973
Epoch 11/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 251.7366 - val_loss: 249.8632
Epoch 12/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 249.6945 - val_loss: 245.1934
Epoch 13/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 247.7689 - val_loss: 242.6400
Epoch 14/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 246.1845 - val_loss: 239.9823
Epoch 15/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 244.8038 - val_loss: 236.7115
Epoch 16/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 243.6554 - val_loss: 237.9356
Epoch 17/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 242.4737 - val_loss: 235.9799
Epoch 18/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 241.5061 - val_loss: 243.9517
Epoch 19/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 240.6130 - val_loss: 239.6175
Epoch 20/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 239.8730 - val_loss: 236.3552
Epoch 21/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 239.0024 - val_loss: 235.0676
Epoch 22/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 238.3944 - val_loss: 232.6124
Epoch 23/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 237.5576 - val_loss: 239.3155
Epoch 24/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 237.0282 - val_loss: 227.6636
Epoch 25/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 236.4736 - val_loss: 233.4403
Epoch 26/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.9742 - val_loss: 234.8903
Epoch 27/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.4160 - val_loss: 231.1759
Epoch 28/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.9170 - val_loss: 243.3334
Epoch 29/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.7596 - val_loss: 234.6205
Epoch 30/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.1048 - val_loss: 228.6328
Epoch 31/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.7064 - val_loss: 223.8704
Epoch 32/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.5178 - val_loss: 229.8130
Epoch 33/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 233.1944 - val_loss: 226.3735
Epoch 34/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 232.9183 - val_loss: 224.5462
Epoch 35/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 232.5682 - val_loss: 230.5214
Epoch 36/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 232.1275 - val_loss: 232.0732
Epoch 37/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 231.9717 - val_loss: 224.2258

 CHILD 2 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7000

         EPOCHS = 37

         CHILD ACCURACY = 223.28686518535335


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 2 <<<<<<<<<<<<<<<<<<<<<<<<<<<

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/33
2018-07-17 16:03:32.647273: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 16:03:32.652158: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 23s 2us/step - loss: 309.3029 - val_loss: 299.6627
Epoch 2/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 287.3378 - val_loss: 281.0059
Epoch 3/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 281.6940 - val_loss: 276.6323
Epoch 4/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 278.8070 - val_loss: 278.9137
Epoch 5/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 276.9170 - val_loss: 273.5013
Epoch 6/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 275.7172 - val_loss: 273.5502
Epoch 7/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 274.6048 - val_loss: 271.2398
Epoch 8/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 273.3138 - val_loss: 270.2727
Epoch 9/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 272.2707 - val_loss: 269.1195
Epoch 10/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 271.4351 - val_loss: 267.9756
Epoch 11/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 267.2675 - val_loss: 261.1992
Epoch 12/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 261.2515 - val_loss: 255.0422
Epoch 13/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 257.1836 - val_loss: 252.0558
Epoch 14/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 253.8419 - val_loss: 247.8223
Epoch 15/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 251.0563 - val_loss: 244.4552
Epoch 16/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 249.0799 - val_loss: 242.1317
Epoch 17/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 247.1969 - val_loss: 241.4660
Epoch 18/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 245.5158 - val_loss: 240.7551
Epoch 19/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 244.2769 - val_loss: 240.5651
Epoch 20/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 242.8181 - val_loss: 235.8572
Epoch 21/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 241.9925 - val_loss: 234.6234
Epoch 22/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 240.9763 - val_loss: 238.0996
Epoch 23/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 240.1170 - val_loss: 235.2406
Epoch 24/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 239.1718 - val_loss: 228.7330
Epoch 25/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 238.5105 - val_loss: 229.2371
Epoch 26/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 237.9594 - val_loss: 232.4010
Epoch 27/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 237.3260 - val_loss: 229.9148
Epoch 28/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 236.7238 - val_loss: 226.7355
Epoch 29/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 236.2866 - val_loss: 230.5666
Epoch 30/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 235.8921 - val_loss: 237.0174
Epoch 31/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 235.3276 - val_loss: 228.9158
Epoch 32/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 234.9093 - val_loss: 230.7790
Epoch 33/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 234.3858 - val_loss: 227.2509

 CHILD 3 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 9000

         EPOCHS = 33

         CHILD ACCURACY = 226.8528220786937


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 3 <<<<<<<<<<<<<<<<<<<<<<<<<<<

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/33
2018-07-17 16:16:02.986856: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 16:16:02.993884: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 25s 3us/step - loss: 312.1896 - val_loss: 287.8415
Epoch 2/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 283.2894 - val_loss: 279.2828
Epoch 3/33
9445953/9445953 [==============================] - 24s 2us/step - loss: 278.9856 - val_loss: 274.4787
Epoch 4/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 277.5948 - val_loss: 276.3161
Epoch 5/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 276.4597 - val_loss: 273.5972
Epoch 6/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 275.7510 - val_loss: 272.9837
Epoch 7/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 274.8845 - val_loss: 271.5081
Epoch 8/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 273.6299 - val_loss: 274.5546
Epoch 9/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 271.7852 - val_loss: 267.3658
Epoch 10/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 269.6752 - val_loss: 269.5931
Epoch 11/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 267.5034 - val_loss: 264.2923
Epoch 12/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 265.8413 - val_loss: 263.0496
Epoch 13/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 264.4863 - val_loss: 261.4443
Epoch 14/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 263.2826 - val_loss: 258.2542
Epoch 15/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 262.0658 - val_loss: 259.5093
Epoch 16/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 260.9836 - val_loss: 262.8687
Epoch 17/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 259.9994 - val_loss: 258.5721
Epoch 18/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 259.2090 - val_loss: 255.5083
Epoch 19/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 258.5063 - val_loss: 256.3201
Epoch 20/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 257.8426 - val_loss: 253.1100
Epoch 21/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 257.3549 - val_loss: 254.9638
Epoch 22/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 256.6720 - val_loss: 252.8796
Epoch 23/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 256.3435 - val_loss: 254.1834
Epoch 24/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 255.9110 - val_loss: 250.7171
Epoch 25/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 255.4403 - val_loss: 252.2746
Epoch 26/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 255.1233 - val_loss: 251.8759
Epoch 27/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 254.8036 - val_loss: 250.7472
Epoch 28/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 254.4395 - val_loss: 256.3767
Epoch 29/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 254.1104 - val_loss: 251.5571
Epoch 30/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 253.8152 - val_loss: 249.6819
Epoch 31/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 253.5642 - val_loss: 249.4339
Epoch 32/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 253.3283 - val_loss: 249.0995
Epoch 33/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 253.0349 - val_loss: 249.5893

 CHILD 4 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 8000

         EPOCHS = 33

         CHILD ACCURACY = 245.46659125991613

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/37
2018-07-17 16:28:56.714043: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 16:28:56.719109: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 23s 2us/step - loss: 321.0991 - val_loss: 294.1105
Epoch 2/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 291.1878 - val_loss: 286.2383
Epoch 3/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 284.6302 - val_loss: 280.0975
Epoch 4/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 282.1764 - val_loss: 278.7500
Epoch 5/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 281.1186 - val_loss: 277.8469
Epoch 6/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 280.2797 - val_loss: 281.0072
Epoch 7/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 279.4763 - val_loss: 276.6800
Epoch 8/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 278.8433 - val_loss: 277.4936
Epoch 9/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 278.2571 - val_loss: 275.4224
Epoch 10/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 276.6524 - val_loss: 274.3611
Epoch 11/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 275.4939 - val_loss: 274.4446
Epoch 12/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 274.4959 - val_loss: 271.6519
Epoch 13/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 271.3535 - val_loss: 266.2609
Epoch 14/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 267.9795 - val_loss: 264.2547
Epoch 15/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 265.5638 - val_loss: 260.5955
Epoch 16/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 263.6957 - val_loss: 260.0996
Epoch 17/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 262.3644 - val_loss: 261.9483
Epoch 18/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 261.2994 - val_loss: 261.7997
Epoch 19/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 260.4594 - val_loss: 257.7931
Epoch 20/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 259.7030 - val_loss: 257.5261
Epoch 21/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 259.2485 - val_loss: 256.7994
Epoch 22/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 258.6643 - val_loss: 256.2262
Epoch 23/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 258.2554 - val_loss: 256.3385
Epoch 24/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 257.8150 - val_loss: 252.9143
Epoch 25/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 257.4999 - val_loss: 255.1985
Epoch 26/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 257.2123 - val_loss: 256.4777
Epoch 27/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 256.8138 - val_loss: 252.8428
Epoch 28/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 256.5414 - val_loss: 255.3822
Epoch 29/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 256.2778 - val_loss: 255.1954
Epoch 30/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 256.0737 - val_loss: 257.8126
Epoch 31/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 255.7927 - val_loss: 252.9938
Epoch 32/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 255.6053 - val_loss: 253.4780
Epoch 33/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 255.3518 - val_loss: 256.0193
Epoch 34/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 255.2132 - val_loss: 250.7953
Epoch 35/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 254.9778 - val_loss: 253.7688
Epoch 36/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 254.8420 - val_loss: 252.0112
Epoch 37/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 254.7250 - val_loss: 252.6514

 CHILD 5 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 9000

         EPOCHS = 37

         CHILD ACCURACY = 249.673912723919



 QUEUE SIZE BEFORE GET = 3


 NODE SELECTED <<<------ Epochs = 37 -------- BatchSize = 7000--------- Accuracy = 223.28686518535335 -------->>>

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/33
2018-07-17 16:42:51.370825: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 16:42:51.376990: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 25s 3us/step - loss: 309.5980 - val_loss: 283.0764
Epoch 2/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 283.1555 - val_loss: 281.7301
Epoch 3/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 279.0700 - val_loss: 274.9961
Epoch 4/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 276.6714 - val_loss: 273.9160
Epoch 5/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 275.1728 - val_loss: 271.8094
Epoch 6/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 274.1564 - val_loss: 271.6639
Epoch 7/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 273.4319 - val_loss: 270.8728
Epoch 8/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 272.8667 - val_loss: 271.2635
Epoch 9/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 272.4192 - val_loss: 269.8985
Epoch 10/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 271.9872 - val_loss: 269.9136
Epoch 11/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 271.6916 - val_loss: 269.8001
Epoch 12/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 271.3966 - val_loss: 268.8565
Epoch 13/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 271.1633 - val_loss: 269.9890
Epoch 14/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 271.0318 - val_loss: 268.5161
Epoch 15/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 270.8437 - val_loss: 269.2818
Epoch 16/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 270.7097 - val_loss: 270.6217
Epoch 17/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 270.5235 - val_loss: 269.9049
Epoch 18/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 270.4363 - val_loss: 269.0412
Epoch 19/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 270.2461 - val_loss: 268.7430
Epoch 20/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 270.1933 - val_loss: 268.4865
Epoch 21/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 270.1272 - val_loss: 268.3511
Epoch 22/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 269.9764 - val_loss: 268.3892
Epoch 23/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 269.8632 - val_loss: 267.7232
Epoch 24/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.7411 - val_loss: 267.1735
Epoch 25/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.6891 - val_loss: 268.7147
Epoch 26/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.6138 - val_loss: 268.6334
Epoch 27/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 269.5092 - val_loss: 267.7603
Epoch 28/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.4065 - val_loss: 267.8258
Epoch 29/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.4027 - val_loss: 267.4580
Epoch 30/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 269.2800 - val_loss: 268.0469
Epoch 31/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.2225 - val_loss: 267.5845
Epoch 32/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.1038 - val_loss: 267.8082
Epoch 33/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.0495 - val_loss: 267.6263

 CHILD 1 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7000

         EPOCHS = 33

         CHILD ACCURACY = 266.3690168642437

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/37
2018-07-17 16:56:20.934388: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 16:56:20.939909: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 26s 3us/step - loss: 303.8390 - val_loss: 285.1154
Epoch 2/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 282.8160 - val_loss: 278.5631
Epoch 3/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 275.4836 - val_loss: 272.6590
Epoch 4/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 270.0893 - val_loss: 267.3105
Epoch 5/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 265.3419 - val_loss: 258.2984
Epoch 6/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 261.4703 - val_loss: 258.7885
Epoch 7/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 258.2669 - val_loss: 258.3017
Epoch 8/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 255.6005 - val_loss: 256.5041
Epoch 9/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 253.2649 - val_loss: 248.7070
Epoch 10/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 251.2713 - val_loss: 246.1141
Epoch 11/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 249.4761 - val_loss: 242.7292
Epoch 12/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 247.7785 - val_loss: 244.1253
Epoch 13/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 246.1142 - val_loss: 243.2397
Epoch 14/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 244.8595 - val_loss: 237.7903
Epoch 15/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.6689 - val_loss: 247.0383
Epoch 16/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.5981 - val_loss: 235.3155
Epoch 17/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.3934 - val_loss: 238.2697
Epoch 18/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.6885 - val_loss: 242.4713
Epoch 19/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.8400 - val_loss: 236.7687
Epoch 20/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.9604 - val_loss: 236.2339
Epoch 21/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 238.4079 - val_loss: 233.6089
Epoch 22/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 237.6487 - val_loss: 236.5151
Epoch 23/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.9936 - val_loss: 232.7271
Epoch 24/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 236.3049 - val_loss: 230.9337
Epoch 25/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 235.7346 - val_loss: 228.5762
Epoch 26/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.1731 - val_loss: 246.5250
Epoch 27/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 234.7651 - val_loss: 244.6936
Epoch 28/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 234.2158 - val_loss: 225.8196
Epoch 29/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 233.6021 - val_loss: 227.9686
Epoch 30/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 233.1271 - val_loss: 227.0927
Epoch 31/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 232.7759 - val_loss: 224.0096
Epoch 32/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 232.1223 - val_loss: 229.3789
Epoch 33/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 232.0367 - val_loss: 233.1356
Epoch 34/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 231.3844 - val_loss: 224.7684
Epoch 35/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 231.0875 - val_loss: 225.6203
Epoch 36/37
9445953/9445953 [==============================] - 26s 3us/step - loss: 230.7158 - val_loss: 225.6018
Epoch 37/37
9445953/9445953 [==============================] - 25s 3us/step - loss: 230.3452 - val_loss: 222.8393

 CHILD 2 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 6000

         EPOCHS = 37

         CHILD ACCURACY = 218.5316955844953


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 3 <<<<<<<<<<<<<<<<<<<<<<<<<<<

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/33
2018-07-17 17:12:10.492544: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 17:12:10.499193: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 25s 3us/step - loss: 365.6103 - val_loss: 345.1515
Epoch 2/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 336.5641 - val_loss: 325.6334
Epoch 3/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 323.5584 - val_loss: 318.3607
Epoch 4/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.7383 - val_loss: 317.1177
Epoch 5/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3093 - val_loss: 317.0901
Epoch 6/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3031 - val_loss: 317.0899
Epoch 7/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3031 - val_loss: 317.0897
Epoch 8/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3033 - val_loss: 317.0897
Epoch 9/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3031 - val_loss: 317.0894
Epoch 10/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3028 - val_loss: 317.0899
Epoch 11/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3034 - val_loss: 317.0902
Epoch 12/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0902
Epoch 13/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0919
Epoch 14/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0915
Epoch 15/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0903
Epoch 16/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.8131 - val_loss: 317.0945
Epoch 17/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3034 - val_loss: 317.0908
Epoch 18/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3031 - val_loss: 317.0913
Epoch 19/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0894
Epoch 20/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3031 - val_loss: 317.0917
Epoch 21/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3031 - val_loss: 317.0914
Epoch 22/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3031 - val_loss: 317.0893
Epoch 23/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0901
Epoch 24/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3031 - val_loss: 317.0933
Epoch 25/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0894
Epoch 26/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3033 - val_loss: 317.0911
Epoch 27/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0895
Epoch 28/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3031 - val_loss: 317.0907
Epoch 29/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0907
Epoch 30/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0896
Epoch 31/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3033 - val_loss: 317.0894
Epoch 32/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3032 - val_loss: 317.0899
Epoch 33/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 319.3031 - val_loss: 317.0903

 CHILD 3 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 6000

         EPOCHS = 33

         CHILD ACCURACY = 314.8764583068975

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/37
2018-07-17 17:25:50.582590: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 17:25:50.587675: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 24s 3us/step - loss: 316.3582 - val_loss: 305.9192
Epoch 2/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 294.6565 - val_loss: 279.5108
Epoch 3/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 278.9444 - val_loss: 275.0241
Epoch 4/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 275.4593 - val_loss: 273.0493
Epoch 5/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 273.9373 - val_loss: 270.5813
Epoch 6/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 273.1023 - val_loss: 269.9191
Epoch 7/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 272.5599 - val_loss: 269.1718
Epoch 8/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 272.0317 - val_loss: 269.5115
Epoch 9/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 271.7516 - val_loss: 269.0979
Epoch 10/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 271.4014 - val_loss: 269.6371
Epoch 11/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 271.1922 - val_loss: 268.7520
Epoch 12/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 270.9279 - val_loss: 268.1729
Epoch 13/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 270.6955 - val_loss: 267.8065
Epoch 14/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 270.5597 - val_loss: 269.2470
Epoch 15/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 270.4045 - val_loss: 267.6802
Epoch 16/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 270.2819 - val_loss: 267.6482
Epoch 17/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 270.1431 - val_loss: 268.0488
Epoch 18/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 269.9421 - val_loss: 267.6241
Epoch 19/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 269.8036 - val_loss: 267.3491
Epoch 20/37
9445953/9445953 [==============================] - 24s 3us/step - loss: 269.7703 - val_loss: 267.3291
Epoch 21/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 269.5440 - val_loss: 267.3283
Epoch 22/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 269.4479 - val_loss: 266.9806
Epoch 23/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 269.3847 - val_loss: 267.2539
Epoch 24/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 269.3020 - val_loss: 268.0002
Epoch 25/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 269.1608 - val_loss: 267.4790
Epoch 26/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 269.1018 - val_loss: 266.6669
Epoch 27/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 269.0136 - val_loss: 265.9913
Epoch 28/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 268.9079 - val_loss: 266.0524
Epoch 29/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 268.7903 - val_loss: 266.1617
Epoch 30/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 268.7251 - val_loss: 266.0844
Epoch 31/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 268.6559 - val_loss: 265.9921
Epoch 32/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 268.5248 - val_loss: 266.9027
Epoch 33/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 268.4442 - val_loss: 265.8874
Epoch 34/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 268.3241 - val_loss: 266.4406
Epoch 35/37
9445953/9445953 [==============================] - 23s 2us/step - loss: 268.1896 - val_loss: 266.1414
Epoch 36/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 268.1379 - val_loss: 265.9131
Epoch 37/37
9445953/9445953 [==============================] - 24s 2us/step - loss: 268.0760 - val_loss: 266.8416

 CHILD 4 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 8000

         EPOCHS = 37

         CHILD ACCURACY = 264.4864466883939

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/33
2018-07-17 17:40:21.419100: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 17:40:21.425526: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 24s 3us/step - loss: 301.9411 - val_loss: 284.7637
Epoch 2/33
9445953/9445953 [==============================] - 24s 2us/step - loss: 281.3346 - val_loss: 276.5019
Epoch 3/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 277.7303 - val_loss: 276.5833
Epoch 4/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 275.4093 - val_loss: 271.4366
Epoch 5/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 273.3927 - val_loss: 270.6059
Epoch 6/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 270.5485 - val_loss: 263.9080
Epoch 7/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 266.0324 - val_loss: 258.7220
Epoch 8/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 262.6777 - val_loss: 258.9302
Epoch 9/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 259.9478 - val_loss: 254.3195
Epoch 10/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 257.9332 - val_loss: 251.9600
Epoch 11/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 255.8616 - val_loss: 250.3357
Epoch 12/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 254.1138 - val_loss: 245.9199
Epoch 13/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 252.4440 - val_loss: 247.6897
Epoch 14/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 251.0364 - val_loss: 253.0746
Epoch 15/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 249.6089 - val_loss: 242.4265
Epoch 16/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 248.4914 - val_loss: 242.1901
Epoch 17/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 247.5296 - val_loss: 242.4882
Epoch 18/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 246.5227 - val_loss: 246.3781
Epoch 19/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 245.7112 - val_loss: 238.2788
Epoch 20/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 244.9363 - val_loss: 238.9925
Epoch 21/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 244.1332 - val_loss: 241.0590
Epoch 22/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 243.6285 - val_loss: 235.1903
Epoch 23/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 242.8885 - val_loss: 235.6358
Epoch 24/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 242.1540 - val_loss: 238.4926
Epoch 25/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 241.5602 - val_loss: 235.2525
Epoch 26/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.1242 - val_loss: 235.8671
Epoch 27/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 240.5150 - val_loss: 236.1454
Epoch 28/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 240.1813 - val_loss: 232.9139
Epoch 29/33
9445953/9445953 [==============================] - 24s 2us/step - loss: 239.7375 - val_loss: 232.0611
Epoch 30/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 239.2461 - val_loss: 232.4016
Epoch 31/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 238.7861 - val_loss: 249.1593
Epoch 32/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 238.4175 - val_loss: 244.9482
Epoch 33/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 238.0176 - val_loss: 230.9050

 CHILD 5 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 8000

         EPOCHS = 33

         CHILD ACCURACY = 240.09021869638124



 QUEUE SIZE BEFORE GET = 3


 NODE SELECTED <<<------ Epochs = 37 -------- BatchSize = 6000--------- Accuracy = 218.5316955844953 -------->>>

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/33
2018-07-17 17:53:20.063780: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 17:53:20.068410: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 27s 3us/step - loss: 312.0793 - val_loss: 284.0435
Epoch 2/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 280.9391 - val_loss: 273.9045
Epoch 3/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 276.6025 - val_loss: 272.7888
Epoch 4/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 274.9828 - val_loss: 277.6422
Epoch 5/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 273.8765 - val_loss: 270.7708
Epoch 6/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 273.1602 - val_loss: 276.4663
Epoch 7/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 272.4667 - val_loss: 269.7509
Epoch 8/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 272.0238 - val_loss: 269.3905
Epoch 9/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 271.6490 - val_loss: 270.5158
Epoch 10/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 271.2095 - val_loss: 270.1358
Epoch 11/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 270.8597 - val_loss: 269.8971
Epoch 12/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 270.5356 - val_loss: 267.6180
Epoch 13/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 270.1642 - val_loss: 267.9751
Epoch 14/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 269.6503 - val_loss: 266.6965
Epoch 15/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 268.3834 - val_loss: 262.3508
Epoch 16/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 262.1896 - val_loss: 255.5393
Epoch 17/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 256.8713 - val_loss: 251.0539
Epoch 18/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 253.4686 - val_loss: 252.6435
Epoch 19/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 250.9177 - val_loss: 243.2077
Epoch 20/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 248.6343 - val_loss: 245.0477
Epoch 21/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 246.6040 - val_loss: 240.1233
Epoch 22/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 244.9108 - val_loss: 245.5264
Epoch 23/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 243.5843 - val_loss: 239.9643
Epoch 24/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.3948 - val_loss: 235.6968
Epoch 25/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.0448 - val_loss: 232.3521
Epoch 26/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 240.2496 - val_loss: 234.7567
Epoch 27/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 239.1923 - val_loss: 241.0798
Epoch 28/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.5082 - val_loss: 235.1829
Epoch 29/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 237.6716 - val_loss: 243.9849
Epoch 30/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 236.9967 - val_loss: 230.5269
Epoch 31/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.6178 - val_loss: 255.7541
Epoch 32/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.0153 - val_loss: 226.0367
Epoch 33/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.2812 - val_loss: 237.9065

 CHILD 1 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7000

         EPOCHS = 33

         CHILD ACCURACY = 238.88433687475117

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/33
2018-07-17 18:07:01.955673: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 18:07:01.959925: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 28s 3us/step - loss: 308.8746 - val_loss: 289.2689
Epoch 2/33
9445953/9445953 [==============================] - 28s 3us/step - loss: 281.7677 - val_loss: 278.6182
Epoch 3/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 278.1459 - val_loss: 274.6894
Epoch 4/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 275.6159 - val_loss: 273.6806
Epoch 5/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 271.2276 - val_loss: 269.9653
Epoch 6/33
9445953/9445953 [==============================] - 28s 3us/step - loss: 267.4856 - val_loss: 266.2385
Epoch 7/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 264.8004 - val_loss: 268.8816
Epoch 8/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 261.6536 - val_loss: 267.3935
Epoch 9/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 257.1009 - val_loss: 253.1248
Epoch 10/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 254.0016 - val_loss: 269.6152
Epoch 11/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 251.7624 - val_loss: 255.6110
Epoch 12/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 249.9260 - val_loss: 247.5844
Epoch 13/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 248.3053 - val_loss: 260.1641
Epoch 14/33
9445953/9445953 [==============================] - 28s 3us/step - loss: 247.1335 - val_loss: 241.4711
Epoch 15/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 245.8156 - val_loss: 240.9416
Epoch 16/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 244.9241 - val_loss: 254.8262
Epoch 17/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 244.0761 - val_loss: 262.9934
Epoch 18/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 243.1796 - val_loss: 245.3353
Epoch 19/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 242.5156 - val_loss: 236.4496
Epoch 20/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 241.7297 - val_loss: 237.7382
Epoch 21/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 241.1271 - val_loss: 240.1780
Epoch 22/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 240.6793 - val_loss: 253.1593
Epoch 23/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 240.1156 - val_loss: 231.1934
Epoch 24/33
9445953/9445953 [==============================] - 28s 3us/step - loss: 239.6069 - val_loss: 252.6544
Epoch 25/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 239.1821 - val_loss: 247.4243
Epoch 26/33
9445953/9445953 [==============================] - 28s 3us/step - loss: 238.7553 - val_loss: 232.1668
Epoch 27/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 238.2557 - val_loss: 233.4752
Epoch 28/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 237.9721 - val_loss: 246.9103
Epoch 29/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 237.5209 - val_loss: 234.1167
Epoch 30/33
9445953/9445953 [==============================] - 28s 3us/step - loss: 237.1191 - val_loss: 236.5918
Epoch 31/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 236.9387 - val_loss: 230.1852
Epoch 32/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 236.4040 - val_loss: 240.6396
Epoch 33/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 236.0971 - val_loss: 249.2106

 CHILD 2 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 33

         CHILD ACCURACY = 241.67389446638802

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/33
2018-07-17 18:22:05.781529: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 18:22:05.787416: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 26s 3us/step - loss: 299.7193 - val_loss: 279.6387
Epoch 2/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 278.6984 - val_loss: 274.5348
Epoch 3/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 273.1986 - val_loss: 271.7639
Epoch 4/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 268.2555 - val_loss: 266.6189
Epoch 5/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 263.9978 - val_loss: 259.1135
Epoch 6/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 260.6767 - val_loss: 253.7228
Epoch 7/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 257.7658 - val_loss: 252.8112
Epoch 8/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 255.4625 - val_loss: 248.3977
Epoch 9/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 253.2989 - val_loss: 251.2580
Epoch 10/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 251.3438 - val_loss: 254.7792
Epoch 11/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 249.8714 - val_loss: 245.5036
Epoch 12/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 248.3530 - val_loss: 248.2600
Epoch 13/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 247.1104 - val_loss: 247.5793
Epoch 14/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 245.9277 - val_loss: 265.1250
Epoch 15/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 244.7691 - val_loss: 237.8969
Epoch 16/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.9446 - val_loss: 244.8156
Epoch 17/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.0274 - val_loss: 238.8622
Epoch 18/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.0627 - val_loss: 254.9971
Epoch 19/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.3848 - val_loss: 244.9128
Epoch 20/33
9445953/9445953 [==============================] - 28s 3us/step - loss: 240.5475 - val_loss: 237.5219
Epoch 21/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.9152 - val_loss: 234.8737
Epoch 22/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.3529 - val_loss: 232.2867
Epoch 23/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.7152 - val_loss: 235.8842
Epoch 24/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.2427 - val_loss: 236.8964
Epoch 25/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.6173 - val_loss: 229.1404
Epoch 26/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.9990 - val_loss: 234.8378
Epoch 27/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.4988 - val_loss: 234.6075
Epoch 28/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.0017 - val_loss: 230.6783
Epoch 29/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.4798 - val_loss: 232.8027
Epoch 30/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.1599 - val_loss: 232.5596
Epoch 31/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.6543 - val_loss: 236.5123
Epoch 32/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 234.2623 - val_loss: 225.0222
Epoch 33/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 233.7641 - val_loss: 229.2502

 CHILD 3 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 6000

         EPOCHS = 33

         CHILD ACCURACY = 227.21202879109597

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/37
2018-07-17 18:36:05.279190: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 18:36:05.283796: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 27s 3us/step - loss: 297.3038 - val_loss: 280.0207
Epoch 2/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 280.0005 - val_loss: 274.9993
Epoch 3/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 273.3568 - val_loss: 278.9632
Epoch 4/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 267.1764 - val_loss: 280.0120
Epoch 5/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 262.5305 - val_loss: 256.3870
Epoch 6/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 258.7851 - val_loss: 277.8883
Epoch 7/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 256.0709 - val_loss: 249.7647
Epoch 8/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 253.8181 - val_loss: 252.5656
Epoch 9/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 251.7597 - val_loss: 247.0102
Epoch 10/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 249.7083 - val_loss: 268.0519
Epoch 11/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 247.8621 - val_loss: 246.1078
Epoch 12/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 246.3561 - val_loss: 237.1316
Epoch 13/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 244.9622 - val_loss: 241.8755
Epoch 14/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 243.5900 - val_loss: 242.7791
Epoch 15/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 242.5296 - val_loss: 254.0012
Epoch 16/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 241.3926 - val_loss: 246.1826
Epoch 17/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 240.3294 - val_loss: 239.2413
Epoch 18/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 239.3536 - val_loss: 240.5501
Epoch 19/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 238.7251 - val_loss: 235.3873
Epoch 20/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 237.8358 - val_loss: 239.6824
Epoch 21/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 237.3248 - val_loss: 233.4842
Epoch 22/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 236.5925 - val_loss: 239.5054
Epoch 23/37
9445953/9445953 [==============================] - 28s 3us/step - loss: 235.9660 - val_loss: 235.6426
Epoch 24/37
9445953/9445953 [==============================] - 28s 3us/step - loss: 235.3768 - val_loss: 256.8764
Epoch 25/37
9445953/9445953 [==============================] - 28s 3us/step - loss: 234.8068 - val_loss: 236.2178
Epoch 26/37
9445953/9445953 [==============================] - 28s 3us/step - loss: 234.2090 - val_loss: 242.6805
Epoch 27/37
9445953/9445953 [==============================] - 29s 3us/step - loss: 233.7169 - val_loss: 235.8674
Epoch 28/37
9445953/9445953 [==============================] - 28s 3us/step - loss: 233.3143 - val_loss: 263.3651
Epoch 29/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 232.8058 - val_loss: 232.3264
Epoch 30/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 232.5139 - val_loss: 227.6235
Epoch 31/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 232.0357 - val_loss: 234.9150
Epoch 32/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 231.8546 - val_loss: 232.2068
Epoch 33/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 231.3525 - val_loss: 235.0691
Epoch 34/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 230.9981 - val_loss: 239.0990
Epoch 35/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 230.5108 - val_loss: 245.1759
Epoch 36/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 230.1266 - val_loss: 224.9446
Epoch 37/37
9445953/9445953 [==============================] - 27s 3us/step - loss: 229.8826 - val_loss: 240.8688

 CHILD 4 out of 4 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 5000

         EPOCHS = 37

         CHILD ACCURACY = 244.66459754034742



 QUEUE SIZE BEFORE GET = 2


 NODE SELECTED <<<------ Epochs = 33 -------- BatchSize = 7000--------- Accuracy = 223.6543352732685 -------->>>

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/33
2018-07-17 18:52:50.777295: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 18:52:50.781782: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 26s 3us/step - loss: 302.9094 - val_loss: 278.8764
Epoch 2/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 278.2130 - val_loss: 274.0418
Epoch 3/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 275.4261 - val_loss: 275.3283
Epoch 4/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 273.5595 - val_loss: 270.2175
Epoch 5/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 270.9129 - val_loss: 264.4636
Epoch 6/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 265.2990 - val_loss: 262.5954
Epoch 7/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 260.0375 - val_loss: 255.9978
Epoch 8/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 256.3609 - val_loss: 253.3968
Epoch 9/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 253.3142 - val_loss: 246.9274
Epoch 10/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 250.6688 - val_loss: 246.5856
Epoch 11/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 248.6041 - val_loss: 248.0672
Epoch 12/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 246.7531 - val_loss: 239.8978
Epoch 13/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 245.3102 - val_loss: 236.3763
Epoch 14/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 243.8717 - val_loss: 249.6024
Epoch 15/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 242.6419 - val_loss: 236.3478
Epoch 16/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 241.5906 - val_loss: 239.7080
Epoch 17/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 240.6149 - val_loss: 233.5208
Epoch 18/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 239.9016 - val_loss: 232.5871
Epoch 19/33
9445953/9445953 [==============================] - 27s 3us/step - loss: 239.0522 - val_loss: 232.8327
Epoch 20/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 238.3071 - val_loss: 232.5330
Epoch 21/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 237.9351 - val_loss: 235.3263
Epoch 22/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 237.1483 - val_loss: 234.4399
Epoch 23/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 236.7084 - val_loss: 229.2709
Epoch 24/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 236.0145 - val_loss: 237.8506
Epoch 25/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 235.7195 - val_loss: 235.7853
Epoch 26/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 235.0567 - val_loss: 228.4613
Epoch 27/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 234.5971 - val_loss: 241.4080
Epoch 28/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 234.3300 - val_loss: 233.8847
Epoch 29/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 233.8212 - val_loss: 225.9806
Epoch 30/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 233.6037 - val_loss: 231.9642
Epoch 31/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 233.1082 - val_loss: 224.6611
Epoch 32/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 232.8242 - val_loss: 226.5911
Epoch 33/33
9445953/9445953 [==============================] - 26s 3us/step - loss: 232.6227 - val_loss: 237.0759

 CHILD 1 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 6000

         EPOCHS = 33

         CHILD ACCURACY = 227.10647062455783

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/29
2018-07-17 19:06:58.016802: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 19:06:58.029027: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 25s 3us/step - loss: 308.0613 - val_loss: 285.9729
Epoch 2/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 285.9179 - val_loss: 280.9996
Epoch 3/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 282.4368 - val_loss: 279.4763
Epoch 4/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 279.8043 - val_loss: 277.4692
Epoch 5/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 278.3354 - val_loss: 276.1539
Epoch 6/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 277.5124 - val_loss: 275.2142
Epoch 7/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 276.7980 - val_loss: 274.7477
Epoch 8/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 276.2123 - val_loss: 276.2081
Epoch 9/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 274.8777 - val_loss: 272.2360
Epoch 10/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 272.2472 - val_loss: 269.8209
Epoch 11/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 268.7575 - val_loss: 262.0129
Epoch 12/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 264.9352 - val_loss: 258.5554
Epoch 13/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 261.2948 - val_loss: 254.8743
Epoch 14/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 258.4412 - val_loss: 253.7474
Epoch 15/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 255.7648 - val_loss: 250.8992
Epoch 16/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 253.5739 - val_loss: 247.0408
Epoch 17/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 251.8094 - val_loss: 250.1234
Epoch 18/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 250.2652 - val_loss: 253.6834
Epoch 19/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 248.8943 - val_loss: 252.4899
Epoch 20/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 247.7349 - val_loss: 241.3813
Epoch 21/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 246.5347 - val_loss: 242.5294
Epoch 22/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 245.5880 - val_loss: 241.7927
Epoch 23/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 244.5945 - val_loss: 235.2733
Epoch 24/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 243.7269 - val_loss: 237.1218
Epoch 25/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 242.9027 - val_loss: 242.0867
Epoch 26/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 242.3228 - val_loss: 240.5103
Epoch 27/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 241.5881 - val_loss: 234.0185
Epoch 28/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 240.9235 - val_loss: 237.8057
Epoch 29/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 240.3367 - val_loss: 231.6271

 CHILD 2 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 8000

         EPOCHS = 29

         CHILD ACCURACY = 230.68798031562488

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/29
2018-07-17 19:18:29.987721: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 19:18:29.994904: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 25s 3us/step - loss: 300.6714 - val_loss: 285.0204
Epoch 2/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 284.6760 - val_loss: 277.0342
Epoch 3/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 276.7290 - val_loss: 272.1122
Epoch 4/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 273.7722 - val_loss: 270.0585
Epoch 5/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 270.3813 - val_loss: 265.3898
Epoch 6/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 266.9171 - val_loss: 265.5854
Epoch 7/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 263.3995 - val_loss: 257.3855
Epoch 8/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 259.4303 - val_loss: 259.8142
Epoch 9/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 255.1714 - val_loss: 250.2152
Epoch 10/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 252.0647 - val_loss: 245.5661
Epoch 11/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 249.5400 - val_loss: 242.9259
Epoch 12/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 247.4648 - val_loss: 240.3303
Epoch 13/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 245.8101 - val_loss: 241.0146
Epoch 14/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 244.0730 - val_loss: 236.4438
Epoch 15/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.8389 - val_loss: 253.7978
Epoch 16/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.4781 - val_loss: 239.4233
Epoch 17/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.5330 - val_loss: 233.9283
Epoch 18/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.5351 - val_loss: 231.4730
Epoch 19/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.6891 - val_loss: 239.5107
Epoch 20/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.1159 - val_loss: 233.9236
Epoch 21/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.4014 - val_loss: 229.2625
Epoch 22/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.6583 - val_loss: 230.8620
Epoch 23/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.2937 - val_loss: 231.1186
Epoch 24/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.6220 - val_loss: 227.8272
Epoch 25/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.1296 - val_loss: 224.9186
Epoch 26/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 234.6267 - val_loss: 240.6224
Epoch 27/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 234.2638 - val_loss: 243.5024
Epoch 28/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 233.5939 - val_loss: 224.0559
Epoch 29/29
9445953/9445953 [==============================] - 24s 3us/step - loss: 233.1838 - val_loss: 248.5642

 CHILD 3 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7000

         EPOCHS = 29

         CHILD ACCURACY = 244.4554646600259

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/33
2018-07-17 19:30:26.749198: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 19:30:26.753927: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 23s 2us/step - loss: 304.6566 - val_loss: 282.4573
Epoch 2/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 282.0293 - val_loss: 278.6515
Epoch 3/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 277.2422 - val_loss: 276.3766
Epoch 4/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 275.0242 - val_loss: 270.9297
Epoch 5/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 273.9525 - val_loss: 271.0742
Epoch 6/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 273.0750 - val_loss: 270.6190
Epoch 7/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 272.5304 - val_loss: 269.1030
Epoch 8/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 271.8835 - val_loss: 268.8398
Epoch 9/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 271.1343 - val_loss: 268.8222
Epoch 10/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 270.0961 - val_loss: 269.2068
Epoch 11/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 268.3586 - val_loss: 264.1473
Epoch 12/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 264.6199 - val_loss: 262.3157
Epoch 13/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 260.3774 - val_loss: 256.7698
Epoch 14/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 257.1879 - val_loss: 251.7402
Epoch 15/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 254.7345 - val_loss: 252.9578
Epoch 16/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 252.6010 - val_loss: 247.5186
Epoch 17/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 250.7015 - val_loss: 245.5624
Epoch 18/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 248.9721 - val_loss: 241.2473
Epoch 19/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 247.4151 - val_loss: 240.5288
Epoch 20/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 245.6321 - val_loss: 241.4730
Epoch 21/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 244.3239 - val_loss: 235.0451
Epoch 22/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 242.9236 - val_loss: 235.4119
Epoch 23/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 241.9489 - val_loss: 234.2128
Epoch 24/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 240.9450 - val_loss: 230.7540
Epoch 25/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 240.0470 - val_loss: 231.0715
Epoch 26/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 239.1620 - val_loss: 237.5879
Epoch 27/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 238.2276 - val_loss: 230.7383
Epoch 28/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 237.7214 - val_loss: 228.8854
Epoch 29/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 236.9715 - val_loss: 227.8073
Epoch 30/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 236.3907 - val_loss: 238.5086
Epoch 31/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 235.8288 - val_loss: 228.5550
Epoch 32/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 235.1793 - val_loss: 231.9914
Epoch 33/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 234.7318 - val_loss: 227.5419

 CHILD 4 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 8000

         EPOCHS = 33

         CHILD ACCURACY = 227.7658719689225

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/29
2018-07-17 19:43:08.503357: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 19:43:08.508118: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 26s 3us/step - loss: 304.8012 - val_loss: 287.7483
Epoch 2/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 280.0865 - val_loss: 281.2357
Epoch 3/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 275.6360 - val_loss: 277.1557
Epoch 4/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 271.8073 - val_loss: 267.7528
Epoch 5/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 267.2164 - val_loss: 261.5618
Epoch 6/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 263.4254 - val_loss: 269.4425
Epoch 7/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 260.2335 - val_loss: 257.3475
Epoch 8/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 257.1407 - val_loss: 258.2847
Epoch 9/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 254.4578 - val_loss: 252.9435
Epoch 10/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 251.8562 - val_loss: 244.2727
Epoch 11/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 249.7717 - val_loss: 242.4035
Epoch 12/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 247.9838 - val_loss: 239.3959
Epoch 13/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 246.4235 - val_loss: 238.9860
Epoch 14/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 245.0660 - val_loss: 237.2689
Epoch 15/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.8737 - val_loss: 235.7266
Epoch 16/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 243.0121 - val_loss: 237.4515
Epoch 17/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 242.0369 - val_loss: 243.4605
Epoch 18/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 241.1733 - val_loss: 244.3256
Epoch 19/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 240.4546 - val_loss: 235.0088
Epoch 20/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.8810 - val_loss: 233.8779
Epoch 21/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 239.2716 - val_loss: 246.1859
Epoch 22/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.5901 - val_loss: 246.9543
Epoch 23/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 238.0984 - val_loss: 240.8889
Epoch 24/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.4948 - val_loss: 242.5002
Epoch 25/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 237.1288 - val_loss: 231.3870
Epoch 26/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.5515 - val_loss: 232.8433
Epoch 27/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.2343 - val_loss: 252.5733
Epoch 28/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 236.0611 - val_loss: 230.7833
Epoch 29/29
9445953/9445953 [==============================] - 25s 3us/step - loss: 235.4591 - val_loss: 230.8345

 CHILD 5 out of 5 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 6000

         EPOCHS = 29

         CHILD ACCURACY = 237.44072597824388



 QUEUE SIZE BEFORE GET = 1


 NODE SELECTED <<<------ Epochs = 33 -------- BatchSize = 9000--------- Accuracy = 226.8528220786937 -------->>>

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/37
2018-07-17 19:55:17.354211: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 19:55:17.359933: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 22s 2us/step - loss: 306.4502 - val_loss: 283.1516
Epoch 2/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 281.3682 - val_loss: 275.7802
Epoch 3/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 277.0411 - val_loss: 272.7759
Epoch 4/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 275.1228 - val_loss: 271.3736
Epoch 5/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 273.4605 - val_loss: 270.7571
Epoch 6/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 271.7374 - val_loss: 270.7922
Epoch 7/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 269.0572 - val_loss: 262.8152
Epoch 8/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 263.7550 - val_loss: 259.3844
Epoch 9/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 259.6074 - val_loss: 254.3302
Epoch 10/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 256.6375 - val_loss: 249.9264
Epoch 11/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 254.2369 - val_loss: 254.1675
Epoch 12/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 252.3195 - val_loss: 245.6336
Epoch 13/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 250.3997 - val_loss: 243.4831
Epoch 14/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 248.5860 - val_loss: 243.8893
Epoch 15/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 247.1041 - val_loss: 239.5914
Epoch 16/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 245.6955 - val_loss: 239.6386
Epoch 17/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 244.1672 - val_loss: 240.1919
Epoch 18/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 242.9290 - val_loss: 237.9130
Epoch 19/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 241.8988 - val_loss: 232.9884
Epoch 20/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 240.6738 - val_loss: 238.8194
Epoch 21/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 239.7346 - val_loss: 232.4314
Epoch 22/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 238.8033 - val_loss: 249.5183
Epoch 23/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 238.0203 - val_loss: 233.3422
Epoch 24/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 237.1688 - val_loss: 232.9884
Epoch 25/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 236.6452 - val_loss: 243.3385
Epoch 26/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 235.9840 - val_loss: 233.5255
Epoch 27/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 235.3370 - val_loss: 232.2164
Epoch 28/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 234.8922 - val_loss: 231.9431
Epoch 29/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 234.1147 - val_loss: 228.6396
Epoch 30/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 233.8513 - val_loss: 230.9111
Epoch 31/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 233.3319 - val_loss: 230.2947
Epoch 32/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 232.8079 - val_loss: 225.6135
Epoch 33/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 232.3583 - val_loss: 230.5343
Epoch 34/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 231.8796 - val_loss: 229.5176
Epoch 35/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 231.4395 - val_loss: 228.2773
Epoch 36/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 231.1657 - val_loss: 226.2928
Epoch 37/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 230.6779 - val_loss: 225.9562

 CHILD 1 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 9000

         EPOCHS = 37

         CHILD ACCURACY = 223.73125044076835


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 1 <<<<<<<<<<<<<<<<<<<<<<<<<<<

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/37
2018-07-17 20:08:56.491486: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 20:08:56.500476: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 21s 2us/step - loss: 379.2379 - val_loss: 359.3445
Epoch 2/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 352.2708 - val_loss: 341.2363
Epoch 3/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 337.2297 - val_loss: 329.2293
Epoch 4/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 327.6793 - val_loss: 322.0887
Epoch 5/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 322.3924 - val_loss: 318.5695
Epoch 6/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 320.0783 - val_loss: 317.3321
Epoch 7/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.4057 - val_loss: 317.1006
Epoch 8/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3075 - val_loss: 317.0895
Epoch 9/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3030 - val_loss: 317.0900
Epoch 10/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3030 - val_loss: 317.0906
Epoch 11/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3031 - val_loss: 317.0904
Epoch 12/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3030 - val_loss: 317.0897
Epoch 13/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3031 - val_loss: 317.0893
Epoch 14/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3031 - val_loss: 317.0895
Epoch 15/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3031 - val_loss: 317.0899
Epoch 16/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3031 - val_loss: 317.0901
Epoch 17/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3031 - val_loss: 317.0902
Epoch 18/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3032 - val_loss: 317.0900
Epoch 19/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3031 - val_loss: 317.0895
Epoch 20/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3032 - val_loss: 317.0906
Epoch 21/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3031 - val_loss: 317.0913
Epoch 22/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3032 - val_loss: 317.0909
Epoch 23/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3032 - val_loss: 317.0897
Epoch 24/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3032 - val_loss: 317.0909
Epoch 25/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3031 - val_loss: 317.0895
Epoch 26/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3032 - val_loss: 317.0896
Epoch 27/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3031 - val_loss: 317.0893
Epoch 28/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3033 - val_loss: 317.0899
Epoch 29/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3031 - val_loss: 317.0893
Epoch 30/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3031 - val_loss: 317.0896
Epoch 31/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3030 - val_loss: 317.0897
Epoch 32/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3031 - val_loss: 317.0901
Epoch 33/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3032 - val_loss: 317.0904
Epoch 34/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3031 - val_loss: 317.0894
Epoch 35/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3032 - val_loss: 317.0893
Epoch 36/37
9445953/9445953 [==============================] - 21s 2us/step - loss: 319.3029 - val_loss: 317.0899
Epoch 37/37
9445953/9445953 [==============================] - 22s 2us/step - loss: 319.3031 - val_loss: 317.0897

 CHILD 2 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 10000

         EPOCHS = 37

         CHILD ACCURACY = 314.8760371900925

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/29
2018-07-17 20:21:57.576049: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 20:21:57.581694: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 23s 2us/step - loss: 371.0583 - val_loss: 355.1337
Epoch 2/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 347.7210 - val_loss: 336.6337
Epoch 3/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 332.9419 - val_loss: 325.4650
Epoch 4/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 324.5572 - val_loss: 319.7230
Epoch 5/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 320.7004 - val_loss: 317.5600
Epoch 6/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 319.4999 - val_loss: 317.1157
Epoch 7/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3119 - val_loss: 317.0894
Epoch 8/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 319.3031 - val_loss: 317.0901
Epoch 9/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 319.3031 - val_loss: 317.0902
Epoch 10/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 319.3032 - val_loss: 317.0900
Epoch 11/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 319.3031 - val_loss: 317.0895
Epoch 12/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 319.3032 - val_loss: 317.0893
Epoch 13/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 319.3032 - val_loss: 317.0898
Epoch 14/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 319.3031 - val_loss: 317.0898
Epoch 15/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 319.3031 - val_loss: 317.0907
Epoch 16/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 319.3032 - val_loss: 317.0894
Epoch 17/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 319.3030 - val_loss: 317.0922
Epoch 18/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 319.3032 - val_loss: 317.0896
Epoch 19/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 319.3031 - val_loss: 317.0904
Epoch 20/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 319.3032 - val_loss: 317.0904
Epoch 21/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 319.3032 - val_loss: 317.0897
Epoch 22/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 319.3031 - val_loss: 317.0896
Epoch 23/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 319.3031 - val_loss: 317.0911
Epoch 24/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 319.3031 - val_loss: 317.0893
Epoch 25/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 319.3032 - val_loss: 317.0898
Epoch 26/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 319.3031 - val_loss: 317.0907
Epoch 27/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 319.3030 - val_loss: 317.0893
Epoch 28/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 319.3030 - val_loss: 317.0893
Epoch 29/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 319.3032 - val_loss: 317.0899

 CHILD 3 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 9000

         EPOCHS = 29

         CHILD ACCURACY = 314.87653084102357

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/33
2018-07-17 20:32:36.286971: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 20:32:36.292045: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 22s 2us/step - loss: 307.6912 - val_loss: 286.6561
Epoch 2/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 287.5170 - val_loss: 293.2173
Epoch 3/33
9445953/9445953 [==============================] - 21s 2us/step - loss: 283.6976 - val_loss: 277.9094
Epoch 4/33
9445953/9445953 [==============================] - 21s 2us/step - loss: 280.3461 - val_loss: 277.1162
Epoch 5/33
9445953/9445953 [==============================] - 21s 2us/step - loss: 279.1053 - val_loss: 275.8579
Epoch 6/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 278.1343 - val_loss: 276.5373
Epoch 7/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 277.6030 - val_loss: 274.5388
Epoch 8/33
9445953/9445953 [==============================] - 21s 2us/step - loss: 277.0496 - val_loss: 274.2150
Epoch 9/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 276.7966 - val_loss: 275.2437
Epoch 10/33
9445953/9445953 [==============================] - 21s 2us/step - loss: 276.5214 - val_loss: 274.0272
Epoch 11/33
9445953/9445953 [==============================] - 21s 2us/step - loss: 276.3036 - val_loss: 274.6539
Epoch 12/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 276.0668 - val_loss: 273.6901
Epoch 13/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 275.9381 - val_loss: 274.4176
Epoch 14/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 275.7142 - val_loss: 274.4436
Epoch 15/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 275.5363 - val_loss: 273.4930
Epoch 16/33
9445953/9445953 [==============================] - 21s 2us/step - loss: 275.4086 - val_loss: 273.0343
Epoch 17/33
9445953/9445953 [==============================] - 21s 2us/step - loss: 275.2308 - val_loss: 274.8501
Epoch 18/33
9445953/9445953 [==============================] - 21s 2us/step - loss: 275.0909 - val_loss: 272.5384
Epoch 19/33
9445953/9445953 [==============================] - 21s 2us/step - loss: 274.9033 - val_loss: 272.6801
Epoch 20/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 274.7183 - val_loss: 272.1905
Epoch 21/33
9445953/9445953 [==============================] - 21s 2us/step - loss: 274.5865 - val_loss: 271.9796
Epoch 22/33
9445953/9445953 [==============================] - 21s 2us/step - loss: 274.3994 - val_loss: 272.6345
Epoch 23/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 274.2405 - val_loss: 271.8071
Epoch 24/33
9445953/9445953 [==============================] - 21s 2us/step - loss: 273.9931 - val_loss: 271.3905
Epoch 25/33
9445953/9445953 [==============================] - 21s 2us/step - loss: 273.7380 - val_loss: 271.6602
Epoch 26/33
9445953/9445953 [==============================] - 21s 2us/step - loss: 273.3599 - val_loss: 271.1404
Epoch 27/33
9445953/9445953 [==============================] - 21s 2us/step - loss: 272.7642 - val_loss: 271.4370
Epoch 28/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 271.5582 - val_loss: 266.2506
Epoch 29/33
9445953/9445953 [==============================] - 21s 2us/step - loss: 266.6891 - val_loss: 261.6688
Epoch 30/33
9445953/9445953 [==============================] - 21s 2us/step - loss: 263.6193 - val_loss: 262.8638
Epoch 31/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 261.6672 - val_loss: 257.5185
Epoch 32/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 260.1760 - val_loss: 255.8285
Epoch 33/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 259.2036 - val_loss: 256.6119

 CHILD 4 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 10000

         EPOCHS = 33

         CHILD ACCURACY = 255.2447917454021

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/29
2018-07-17 20:44:26.995356: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 20:44:26.999716: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 24s 3us/step - loss: 314.6108 - val_loss: 299.1938
Epoch 2/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 285.0739 - val_loss: 274.9297
Epoch 3/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 276.2759 - val_loss: 272.6775
Epoch 4/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 274.1462 - val_loss: 270.5359
Epoch 5/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 272.7703 - val_loss: 269.3822
Epoch 6/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 270.5344 - val_loss: 265.2434
Epoch 7/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 264.9946 - val_loss: 258.7963
Epoch 8/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 260.1974 - val_loss: 252.7827
Epoch 9/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 256.6977 - val_loss: 251.4911
Epoch 10/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 253.6583 - val_loss: 246.8520
Epoch 11/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 251.3180 - val_loss: 245.8012
Epoch 12/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 249.2736 - val_loss: 244.1917
Epoch 13/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 247.5489 - val_loss: 242.3968
Epoch 14/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 246.2171 - val_loss: 240.9007
Epoch 15/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 244.9202 - val_loss: 239.6553
Epoch 16/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 243.8039 - val_loss: 235.4297
Epoch 17/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 242.8908 - val_loss: 235.3386
Epoch 18/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 241.9336 - val_loss: 234.7792
Epoch 19/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 241.0324 - val_loss: 233.5313
Epoch 20/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 240.1915 - val_loss: 233.6569
Epoch 21/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 239.6185 - val_loss: 235.7857
Epoch 22/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 238.8549 - val_loss: 233.0788
Epoch 23/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 238.4685 - val_loss: 232.9996
Epoch 24/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 237.8583 - val_loss: 231.6227
Epoch 25/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 237.2143 - val_loss: 240.8083
Epoch 26/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 236.7515 - val_loss: 231.3944
Epoch 27/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 236.2180 - val_loss: 227.0450
Epoch 28/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 235.8401 - val_loss: 226.8041
Epoch 29/29
9445953/9445953 [==============================] - 23s 2us/step - loss: 235.4208 - val_loss: 228.9212

 CHILD 5 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 8000

         EPOCHS = 29

         CHILD ACCURACY = 221.02474954842737


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 2 <<<<<<<<<<<<<<<<<<<<<<<<<<<

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/29
2018-07-17 20:55:41.680594: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 20:55:41.685193: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 22s 2us/step - loss: 316.4628 - val_loss: 291.9053
Epoch 2/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 288.0623 - val_loss: 282.3852
Epoch 3/29
9445953/9445953 [==============================] - 21s 2us/step - loss: 283.3186 - val_loss: 279.4811
Epoch 4/29
9445953/9445953 [==============================] - 21s 2us/step - loss: 281.4769 - val_loss: 280.9782
Epoch 5/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 279.0218 - val_loss: 275.7479
Epoch 6/29
9445953/9445953 [==============================] - 21s 2us/step - loss: 274.4473 - val_loss: 269.7178
Epoch 7/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 269.3971 - val_loss: 267.7329
Epoch 8/29
9445953/9445953 [==============================] - 21s 2us/step - loss: 266.3031 - val_loss: 259.7545
Epoch 9/29
9445953/9445953 [==============================] - 21s 2us/step - loss: 263.1252 - val_loss: 258.7259
Epoch 10/29
9445953/9445953 [==============================] - 21s 2us/step - loss: 259.7909 - val_loss: 251.8622
Epoch 11/29
9445953/9445953 [==============================] - 21s 2us/step - loss: 256.2580 - val_loss: 247.5875
Epoch 12/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 253.2144 - val_loss: 245.0631
Epoch 13/29
9445953/9445953 [==============================] - 21s 2us/step - loss: 250.8624 - val_loss: 245.3025
Epoch 14/29
9445953/9445953 [==============================] - 21s 2us/step - loss: 248.8948 - val_loss: 242.0299
Epoch 15/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 247.3479 - val_loss: 240.0536
Epoch 16/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 245.9495 - val_loss: 237.8832
Epoch 17/29
9445953/9445953 [==============================] - 21s 2us/step - loss: 244.7171 - val_loss: 237.4524
Epoch 18/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 243.7330 - val_loss: 234.9097
Epoch 19/29
9445953/9445953 [==============================] - 21s 2us/step - loss: 242.6852 - val_loss: 238.6530
Epoch 20/29
9445953/9445953 [==============================] - 21s 2us/step - loss: 241.8147 - val_loss: 233.3820
Epoch 21/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 240.9258 - val_loss: 236.1411
Epoch 22/29
9445953/9445953 [==============================] - 21s 2us/step - loss: 240.2162 - val_loss: 234.5074
Epoch 23/29
9445953/9445953 [==============================] - 21s 2us/step - loss: 239.6832 - val_loss: 233.6407
Epoch 24/29
9445953/9445953 [==============================] - 21s 2us/step - loss: 238.9076 - val_loss: 236.1421
Epoch 25/29
9445953/9445953 [==============================] - 21s 2us/step - loss: 238.4580 - val_loss: 242.3865
Epoch 26/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 237.9397 - val_loss: 230.1873
Epoch 27/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 237.3177 - val_loss: 230.7824
Epoch 28/29
9445953/9445953 [==============================] - 21s 2us/step - loss: 236.9205 - val_loss: 229.7052
Epoch 29/29
9445953/9445953 [==============================] - 22s 2us/step - loss: 236.5629 - val_loss: 231.4588

 CHILD 6 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 10000

         EPOCHS = 29

         CHILD ACCURACY = 223.88167088622055


                 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> APPENDED CHILD TO THE QUEUE | QUEUE SIZE = 3 <<<<<<<<<<<<<<<<<<<<<<<<<<<



 QUEUE SIZE BEFORE GET = 3


 NODE SELECTED <<<------ Epochs = 29 -------- BatchSize = 8000--------- Accuracy = 221.02474954842737 -------->>>

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/33
2018-07-17 21:06:05.687475: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 21:06:05.692617: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 25s 3us/step - loss: 310.9365 - val_loss: 285.6411
Epoch 2/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 285.8235 - val_loss: 280.1031
Epoch 3/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 282.5143 - val_loss: 277.7470
Epoch 4/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 278.7988 - val_loss: 275.6056
Epoch 5/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 274.6884 - val_loss: 274.3083
Epoch 6/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 271.6144 - val_loss: 267.2682
Epoch 7/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 269.3678 - val_loss: 264.3454
Epoch 8/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 267.5709 - val_loss: 268.0666
Epoch 9/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 266.0211 - val_loss: 264.8499
Epoch 10/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 264.7293 - val_loss: 264.7939
Epoch 11/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 263.5763 - val_loss: 258.5889
Epoch 12/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 262.5212 - val_loss: 259.1740
Epoch 13/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 261.6146 - val_loss: 257.1891
Epoch 14/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 260.6356 - val_loss: 258.3926
Epoch 15/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 259.9352 - val_loss: 257.3307
Epoch 16/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 259.0624 - val_loss: 260.5091
Epoch 17/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 258.3907 - val_loss: 259.2906
Epoch 18/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 257.7263 - val_loss: 264.8094
Epoch 19/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 257.1678 - val_loss: 251.5277
Epoch 20/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 256.6355 - val_loss: 257.2215
Epoch 21/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 256.1306 - val_loss: 254.3497
Epoch 22/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 255.7956 - val_loss: 251.1155
Epoch 23/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 255.3411 - val_loss: 259.0595
Epoch 24/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 254.9695 - val_loss: 250.0454
Epoch 25/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 254.6718 - val_loss: 252.3832
Epoch 26/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 254.3057 - val_loss: 256.6115
Epoch 27/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 254.1108 - val_loss: 251.4824
Epoch 28/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 253.8839 - val_loss: 251.2394
Epoch 29/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 253.6902 - val_loss: 251.3277
Epoch 30/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 253.3263 - val_loss: 250.8397
Epoch 31/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 253.1979 - val_loss: 249.0916
Epoch 32/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 253.0243 - val_loss: 248.0973
Epoch 33/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 252.7658 - val_loss: 247.4753

 CHILD 1 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7000

         EPOCHS = 33

         CHILD ACCURACY = 244.67335403613748

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/25
2018-07-17 21:19:30.645970: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 21:19:30.651030: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 24s 3us/step - loss: 367.7570 - val_loss: 349.1160
Epoch 2/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 340.7986 - val_loss: 329.5825
Epoch 3/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 326.6188 - val_loss: 320.3208
Epoch 4/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 320.8001 - val_loss: 317.4434
Epoch 5/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.4161 - val_loss: 317.0922
Epoch 6/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3042 - val_loss: 317.0895
Epoch 7/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3030 - val_loss: 317.0895
Epoch 8/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0912
Epoch 9/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3031 - val_loss: 317.0905
Epoch 10/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0902
Epoch 11/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3031 - val_loss: 317.0903
Epoch 12/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0901
Epoch 13/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3031 - val_loss: 317.0893
Epoch 14/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3033 - val_loss: 317.0900
Epoch 15/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0902
Epoch 16/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3033 - val_loss: 317.0894
Epoch 17/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0894
Epoch 18/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0902
Epoch 19/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0896
Epoch 20/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0906
Epoch 21/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3033 - val_loss: 317.0898
Epoch 22/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0901
Epoch 23/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0906
Epoch 24/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0895
Epoch 25/25
9445953/9445953 [==============================] - 24s 3us/step - loss: 319.3032 - val_loss: 317.0906

 CHILD 2 out of 6 ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

         BATCH SIZE = 7000

         EPOCHS = 25

         CHILD ACCURACY = 314.8771532592476

Train on 9445953 samples, validate on 1049551 samples
Epoch 1/33
2018-07-17 21:29:27.712950: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1312] Adding visible gpu devices: 0
2018-07-17 21:29:27.716918: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 40 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
9445953/9445953 [==============================] - 23s 2us/step - loss: 311.1060 - val_loss: 286.3693
Epoch 2/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 284.3986 - val_loss: 285.3879
Epoch 3/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 277.5568 - val_loss: 272.2969
Epoch 4/33
9445953/9445953 [==============================] - 22s 2us/step - loss: 274.4999 - val_loss: 269.6113
Epoch 5/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 270.2345 - val_loss: 269.2385
Epoch 6/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 266.2028 - val_loss: 260.8405
Epoch 7/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 262.7851 - val_loss: 255.4097
Epoch 8/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 260.0517 - val_loss: 255.7581
Epoch 9/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 257.5588 - val_loss: 254.4747
Epoch 10/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 255.4285 - val_loss: 250.1493
Epoch 11/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 253.6818 - val_loss: 248.9837
Epoch 12/33
9445953/9445953 [==============================] - 24s 2us/step - loss: 251.9371 - val_loss: 247.0360
Epoch 13/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 250.4589 - val_loss: 245.1158
Epoch 14/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 249.0002 - val_loss: 250.1491
Epoch 15/33
9445953/9445953 [==============================] - 24s 2us/step - loss: 247.6048 - val_loss: 242.5957
Epoch 16/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 246.4176 - val_loss: 244.0140
Epoch 17/33
9445953/9445953 [==============================] - 25s 3us/step - loss: 245.4310 - val_loss: 242.2703
Epoch 18/33
9445953/9445953 [==============================] - 23s 2us/step - loss: 244.3094 - val_loss: 246.0897
Epoch 19/33
9445953/9445953 [==============================] - 24s 3us/step - loss: 243.3642 - val_loss: 240.8119
Epoch 20/33
2169000/9445953 [=====>........................] - ETA: 17s - loss: 244.1940

The first part of the assignment is completed by "RunDataTransformer.py" 

	It takes as inputs the folder "crawled+pages" generated by RunCrawler.py from assignment 1 to be input by the user. 
	The other argument is the number of files to be processed for tokenization. 

	The output is a temporary file called "tokenizer_results.txt" 

	It contains all the token extracted from all the documents. 

	These libraries used were: 

	import re 

	from sys import argv
	import os 

The second part: 

	

	Some changes to the actual instructions. 
	This script does not take any inputs from the user. 
	It depends solely on the file returned by RunDataTransformer.py 
	As RunDataTransformer.py has some system variables defined it was having some trouble to import into 
	other python code like "CreateIndex.py" etc. 

	The files are mostly list of tuples except for the inverted index file. 
	The inverted Index file is a json dump of a python dictionary. 

	TermIDFile - Contains the term Id, the term itself followed by the number of files that term occurs in. 

	DocumentIDFile - Contains the DocumentID, document name, followed by the total number of term in that document. 
	
	InvertedIndex - Contains the TermId as the key of the dictionary, the value for each key is a list of tuples. 
			The first value in a tuple is the id of the document. The second value is the frequency of term occurence. 
			So, an entry like: 
				"11427": [[2, 134], [8, 7], [10, 2], [13, 1], [39, 2]] 
			means that term id 11427, is present in doc 2 with a frequency 134, in doc 8 with freq 7 , and so on. 	
			(term 11427 is 'Harvard' btw). 

	Libraries used: 
	import re 
	from sys import argv, getsizeof
	import os
	from collections import defaultdict
	import json 

Stats: 

	Stats are written programmatically into the "stats.txt" file. However there is an error with the calculation of the index ratio. 
	I thought the index file needs to compared with the total of other index files and I coded for that. 
	So although all the numbers are coded, the ratio of the index size to the total file size needs to be done manually. 
	
	The CreateIndex.py code appends results to the stats file after it is created from the RunDataTransformer.py code. 
	The codes must be executed one after the other for the stats. 
	
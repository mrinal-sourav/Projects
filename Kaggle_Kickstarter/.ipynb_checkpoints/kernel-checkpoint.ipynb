{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "176894540fe45a9bc307f4f05ebe7418f016b326"
   },
   "source": [
    "<h3> Imports </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "31ed5dc1f51a916f66aa0b799600719e235c367c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from math import log\n",
    "import json \n",
    "import time\n",
    "from random import randint\n",
    "\n",
    "# keras imports for neural network\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7fad460b972efe5039a44fca586fc4c480d65ce2"
   },
   "source": [
    "<h2> Data Preparation for training and testing </h2>\n",
    "\n",
    "I see two dasets available in the task: <br>\n",
    "One seems to be from 2016, without currency conversion to USD. <br> \n",
    "Another is from 2018 with some newly added records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "79ae72159580760a66e41d9cc71f0931d6f5d40c"
   },
   "outputs": [],
   "source": [
    "kick_start_2016 = pd.read_csv('../input/ks-projects-201612.csv', encoding = 'ISO-8859-1')\n",
    "kick_start_2016.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58e983ea03fb4490358f9ff69d3de463315cb8ae"
   },
   "outputs": [],
   "source": [
    "kick_start_2018 = pd.read_csv('../input/ks-projects-201801.csv')\n",
    "kick_start_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03bab8b40d6aa776a835a568efc0ae0caa30d042"
   },
   "outputs": [],
   "source": [
    "print(len(kick_start_2018) - len(kick_start_2016))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "79d6c977a91b4291174264e85c8ee9edb7c84779"
   },
   "source": [
    "<h3> So, there are 54911 more records in 2018 data than 2016 data </h3> \n",
    "\n",
    "These records may be ideal for testing. <br> \n",
    "I will now extract only those records from 2018 data that also exist in 2016 using the ID field.<br>\n",
    "But first, the 2016 data needs renaming the columns labels (removing trailing spaces etc.) to bring it to the same format as 2018 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e4b29c5a1f079f38d60d4aedc9bf0d229ae044ca"
   },
   "outputs": [],
   "source": [
    "kick_start_2016.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cef231f95e8515894bee03b90da807a6347236c6"
   },
   "outputs": [],
   "source": [
    "kick_start_2018.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1512508cf7595b849703dac8abf1cf503fa22062"
   },
   "outputs": [],
   "source": [
    "# renaming the 2016 data columns\n",
    "kick_start_2016.columns = ['ID', 'name', 'category', 'main_category', 'currency', 'deadline',\n",
    "       'goal', 'launched', 'pledged', 'state', 'backers', 'country',\n",
    "       'usd_pledged', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15',\n",
    "       'Unnamed: 16']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "50a89c3212e788c8bf296e5ab4871dc589ac0d6d"
   },
   "source": [
    "<h3> Extracting what is common to both datasets, in 2018 data. <br>\n",
    "This will be used to train the decision tree and the neural network. <br>\n",
    "I have mentioned how to conbine both these models for both training and testing in the overall strategy further below.<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2c7b97ce1ea9bccd02b20b161824d55546093ef3"
   },
   "outputs": [],
   "source": [
    "kick_start_common = kick_start_2018.loc[kick_start_2018.ID.isin(kick_start_2016.ID)].reset_index(drop=True)\n",
    "len(kick_start_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "69caaae43c12112efe11ba13eb2e1255c4efd172"
   },
   "outputs": [],
   "source": [
    "kick_start_common.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b7efaddcf5ae5f34d308cc2e0777022550951aee"
   },
   "source": [
    "<h3> Extracting records unique to 2018 data </h3>\n",
    "<h3> I will use these as my test dataset later towards the end to get the final accuracy of the combined model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "91b38a62a44c275f7128f97a07a888afee7c3c1e"
   },
   "outputs": [],
   "source": [
    "kick_start_unique = kick_start_2018.loc[-kick_start_2018.ID.isin(kick_start_2016.ID)].reset_index(drop=True)\n",
    "len(kick_start_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d27e9f2bc1b52fa2fe258e4423b2c8c7359d0727"
   },
   "outputs": [],
   "source": [
    "kick_start_unique.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d10313862936def12011f36141601c19a488f978"
   },
   "source": [
    "<h2> Lets focus on the training dataaset for now and visualize some of its aspects. </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aeaf61e7944efbbd05f01cdb06976d331dc5855b"
   },
   "outputs": [],
   "source": [
    "kick_start = kick_start_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "600cc7690ea337f54f493f2fad7bfec3c2cbfed0"
   },
   "outputs": [],
   "source": [
    "kick_start[\"state\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "85918e7a398c94a5d844a0acb3640add09bcc043"
   },
   "source": [
    "<b> Checking the distribution of the target field </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1770436e5b1e66fcca533291ea06e5d50a5cf877"
   },
   "outputs": [],
   "source": [
    "pd.value_counts(kick_start['state']).plot.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8436434fa693819120e510898381c39ed3d4ab8f"
   },
   "source": [
    "<h3> Analyses, assumptions and visualizations </h3> \n",
    "\n",
    "<b>My first assumption is that the \"state\" will correlate well with the number of days between \"launch\" and \"deadline\".</b> <br>\n",
    "So, I convert those dates and bring them to \"No. of days\" format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f4929347e7ee5365758d7bfef39b3963f7a97fb0"
   },
   "outputs": [],
   "source": [
    "x = pd.to_datetime(kick_start[\"deadline\"])\n",
    "y = pd.to_datetime(kick_start[\"launched\"])\n",
    "z = x - y  \n",
    "\n",
    "print (z.min())\n",
    "print (z.mean())\n",
    "print (z.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4258937669ce7659b53220f24dda3bc4d1f604bd"
   },
   "outputs": [],
   "source": [
    "num_days = z.apply(lambda x: str(x.days))\n",
    "pd.value_counts(num_days).plot.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "686005cdf0908476fa0869461d4aba76c6b91d11"
   },
   "source": [
    "<b> Most projects seem to have a deadline of 29 days (~1 month), followed by 59 days (~2 months) etc. </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "83642b7e78cbba1996dac95204deb8c09bb79dfd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c575309592cd094148bc0c3ad44519d2fcadaa90"
   },
   "source": [
    "<h3> Overall strategy for training</h3>\n",
    "\n",
    "I will select certain fields (mostly categorical) to feed to a Decision Tree model to reduce entropy in the data. This will  also include the \"No. of days to deadline\" computed above. \n",
    "\n",
    "If the decision tree returns some good results and is able to reduce entropy by looking at just the categorical data (<b>without the $amounts, backers etc. </b>), I will output the probability distribution of states as the \"partial\" predictions from this tree. \n",
    "\n",
    ", I will concatenate these partial predictions with the rest of the columns ($amounts, backers etc.) to create a \"feature vector\". <br>\n",
    "This feature vector would then go as inputs to a neural network for further training. <br>\n",
    "\n",
    "So, even while testing, predictions will be broken down to two parts, first to recieve partial predictions from the decision tree and then to get the final predictions from the neural network.\n",
    "\n",
    "<b> The intuition is to use the Decision Tree to handle entropy in the categorical data and reduce the non-linearity / dimensions for the neural network to achieve better learning. </b>\n",
    "\n",
    "Since I need the probability distributions from the decision tree, I am implementing a decision tree based on ID3 algorithm for this purpose. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e6e12e9f1a935471d44a26633cccdc96c2244a23"
   },
   "source": [
    "<h3> Fields selected for decision tree : </h3> \n",
    "\n",
    "<ul> \n",
    "    <li> category </li>\n",
    "    <li> main_category </li>\n",
    "    <li> currency </li>\n",
    "    <li> country </li> \n",
    "    <li> Number of days to deadline </li> \n",
    "</ul> \n",
    "\n",
    "<b> The \"id\" and \"name\" fields will be omitted as I don't think there is much correlation between these fields and the \"state\" </b> \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7fad4c0b9d3e6c24715578d90bdf4d97ff8f1514"
   },
   "outputs": [],
   "source": [
    "dt_kstart = kick_start[['category', 'main_category', 'currency', 'country', 'state']]\n",
    "dt_kstart['num_days'] = num_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "76cab024b50f17448729edc205d1a1b445320a37"
   },
   "outputs": [],
   "source": [
    "dt_kstart.state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8972facb665088172c70b41a198bb3eb480fe02a"
   },
   "outputs": [],
   "source": [
    "# this function calculates the probability distribution of the unique items for a specified column in a dataframe\n",
    "def get_probabilities(df, column):\n",
    "    freqs = df[column].value_counts()\n",
    "    summation = sum(freqs)\n",
    "    probabilities = freqs / summation\n",
    "    return (probabilities) \n",
    "\n",
    "# function to return log base 2\n",
    "def ln(x):\n",
    "    return log(x)/log(2)\n",
    "\n",
    "# to return the entropy given the probability distribution    \n",
    "def get_entropy(probabilities):\n",
    "    return sum( probabilities * probabilities.apply(ln)) * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1bbcaab1f7ca9cda0997762985003c884989e920"
   },
   "outputs": [],
   "source": [
    "# Initial entropy of the 'state' column in the training data\n",
    "get_entropy(get_probabilities(dt_kstart, 'state'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6cd5c980e24a73a818aaac64bbb25ba84f668e5b"
   },
   "outputs": [],
   "source": [
    "dt_kstart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "59ae46a0bf534c030b1534db1a2586073aaf3c14"
   },
   "outputs": [],
   "source": [
    "# splitting a data-frame, on an index/column and value \n",
    "# returns the new dataframe after the split\n",
    "def split_data(df, column, value):\n",
    "    return df[df[column] == value]\n",
    "\n",
    "# to get the best feature based on information gain \n",
    "def get_best_feature(df, target):\n",
    "    initial_entropy = get_entropy(get_probabilities(df, target))\n",
    "    best_gain = 0.0\n",
    "    best_feature = None\n",
    "    feature_list = list(df.columns)\n",
    "    feature_list.remove(target)\n",
    "    for feature in feature_list:\n",
    "        uniques = df[feature].unique()\n",
    "        new_entropy = 0 \n",
    "        for value in uniques:\n",
    "            subset =  split_data (df, feature, value) \n",
    "            probability = len(subset) / len(df)\n",
    "            new_entropy += probability * get_entropy(get_probabilities(subset, target))\n",
    "        info_gain = initial_entropy - new_entropy\n",
    "        # print (info_gain, feature)\n",
    "        if info_gain > best_gain:\n",
    "            best_gain = info_gain\n",
    "            best_feature = feature\n",
    "            \n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "418efea6b32a0085724c20aa99cbbeeb1537f392"
   },
   "outputs": [],
   "source": [
    "get_best_feature(dt_kstart, 'state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1078f79c403a68430f4b1080d2aa3cae9c9334ea"
   },
   "source": [
    "<h2>  Looks like, my assumption that num_days would highly correlate with state, is wrong! </h2> \n",
    "\n",
    "Nonetheless, there is some correlation and some information gain. <br>\n",
    "We now proceed to build the Decision Tree <br>\n",
    "Though the output of this decision tree is a probability distribution, I still label it as 'state' so that it is easier to retreive predictions from this tree later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e6ba6f8d33bb5ec199e5b437049f1b1bb0ae9c08"
   },
   "outputs": [],
   "source": [
    "# returns true if there is only one label in the target field \n",
    "def is_pure(df, target):\n",
    "    return len(df[target].unique()) == 1\n",
    "        \n",
    "def create_tree(df, target):\n",
    "    # condition for pure data (when there is only one possible 'state')\n",
    "    if is_pure(df, target):\n",
    "        return {'state' : dict(get_probabilities(df, target))}\n",
    "    \n",
    "    #condition for leaf nodes\n",
    "    if len(df.columns) <= 2:\n",
    "        features = list(df.columns)\n",
    "        features.remove(target)\n",
    "        feature = features[0]\n",
    "        leaf_node = {feature:{}}\n",
    "        uniques = df[feature].unique()\n",
    "        for value in uniques:\n",
    "            subset = split_data(df, feature, value)\n",
    "            leaf_node[feature][value] = {'state' : dict(get_probabilities(subset, target))}\n",
    "        return leaf_node\n",
    "    \n",
    "    # recursive call to create the nested tree/dictionary\n",
    "    best_feature = get_best_feature(df, target)\n",
    "    if best_feature:\n",
    "        my_tree = {best_feature:{}}\n",
    "        uniques = df[best_feature].unique()\n",
    "        for value in uniques:\n",
    "            subset = split_data(df, best_feature, value)\n",
    "            subset = subset.drop(best_feature, axis=1)\n",
    "            my_tree[best_feature][value] = create_tree(subset, target)\n",
    "    else: \n",
    "        my_tree = {'state' : dict(get_probabilities(df, target))}\n",
    "        \n",
    "    return my_tree\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5bde2866f973dae046149d723023ca10f8401775"
   },
   "outputs": [],
   "source": [
    "# start time\n",
    "start = time.perf_counter()\n",
    "\n",
    "# creating the tree\n",
    "d_tree = create_tree(dt_kstart, 'state')\n",
    "\n",
    "# saving the dictionary\n",
    "filename = '/kaggle/working/decision_tree.txt'\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(d_tree, f)\n",
    "    \n",
    "# end time\n",
    "stop = time.perf_counter()\n",
    "\n",
    "print('Creating the Decision Tree took close to ' + str((stop-start)/60.0) + ' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1738fcbed8203fdd0cfd62a2cd853ff6f29c57d4"
   },
   "outputs": [],
   "source": [
    "# loading the tree\n",
    "def load_tree(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "d_tree = load_tree('/kaggle/working/decision_tree.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d0d8643f3cbadf590879deb976d438c409e4c55a"
   },
   "outputs": [],
   "source": [
    "# to predict a single instance of a feature using the decision tree\n",
    "# inputs: the tree; feature of type pandas.Series.series\n",
    "# returns: the probability distribution of the states as a dictionary\n",
    "def partial_predict(tree, features):\n",
    "    probabs = {}\n",
    "    first_dict = next(iter(tree))\n",
    "    second_dict = tree[first_dict]\n",
    "    feat_value = features[first_dict]\n",
    "    if first_dict != 'state':\n",
    "        for key in second_dict.keys():\n",
    "            if feat_value == key:\n",
    "                probabs = partial_predict(second_dict[key], features)\n",
    "    else: \n",
    "        probabs = second_dict\n",
    "    return probabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2cb12a9b6370f0aec06c1070259bad4ed4b67a07"
   },
   "source": [
    "<h3> Unit testing the tree on a single instance/row </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cfce9365cf6f6d21c7592803c084720ba1f32e3b"
   },
   "outputs": [],
   "source": [
    "labels = dict(dt_kstart.loc[89])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9e5158a95704a302bab7726b4429da4da7a5d581"
   },
   "outputs": [],
   "source": [
    "partial_predict(d_tree, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "805b30c8da0d30901dadf6bc77a40d8e5989c6cd"
   },
   "outputs": [],
   "source": [
    "# retrieving data from the tree\n",
    "d_tree['category']['Restaurants']['num_days']['59']['country']['US']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4cb5c05950bccfbb72889f5e4bbeb3f76075aec3"
   },
   "source": [
    "<h3> Translate probability distributions from a dictionary to a numpy array </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dad70f46802a56e04d7282d12605b8274ab6bc7c"
   },
   "outputs": [],
   "source": [
    "# to translate a predicted distribution (a dictionary) to its corresponding numpy version\n",
    "def translate(distribution):\n",
    "    array = np.empty([6])\n",
    "    # to hardcode positions in the numpy array \n",
    "    positions = {'failed':0, \n",
    "                 'successful':1, \n",
    "                 'canceled':2, \n",
    "                 'undefined':3, \n",
    "                 'live':4, \n",
    "                 'suspended':5} \n",
    "    for key in positions:\n",
    "        if key in distribution.keys():\n",
    "            array[positions[key]] = distribution[key]\n",
    "        else:\n",
    "            array[positions[key]] = 0 \n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "90cf53e86bfd5ed25466e603a5645ca6bfb702f1"
   },
   "outputs": [],
   "source": [
    "x = partial_predict(d_tree, labels) #same example as above\n",
    "print(x)\n",
    "y = translate(x)\n",
    "print (y) # this is now translated to a numpy version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d9992dfdd6a422134bdfde31797b79d3f0eb1f5b"
   },
   "outputs": [],
   "source": [
    "# since this is a probability distribution, all entries must sum to 1 \n",
    "y.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f9933799b692de7edd4079a52dcd075b7f1aaab6"
   },
   "source": [
    "<h3> Generating probability distributions from categorical data for the entire training dataset using the tree </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "958f14efb565bdc011a8a66ad7c39c4d33b91aa5"
   },
   "outputs": [],
   "source": [
    "to_predict = dt_kstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bb27213c1d08d55c98e3aa290cbba64b6ca7e54b"
   },
   "outputs": [],
   "source": [
    "# to get predictions for an entire dataframe\n",
    "def get_partial_predictions(tree, inputs):\n",
    "    partial_predictions = []\n",
    "    for index,row in inputs.iterrows():\n",
    "        features = dict(row)\n",
    "        probabs = partial_predict(tree, features)\n",
    "        arr = translate(probabs)\n",
    "        partial_predictions.append(arr)\n",
    "    return np.array(partial_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8109d9b7a354378688e4363e1c3de621bfa967a3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b4d7679eebf65e5d912082ff289c7d0f0afae317"
   },
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "part_predict = get_partial_predictions(d_tree, to_predict)\n",
    "stop = time.perf_counter()\n",
    "\n",
    "print(part_predict.shape)\n",
    "print('This process took ' + str(stop-start) + ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "51f1ff922312464a7be51df36b16a4410c4d3f22"
   },
   "source": [
    " <h2> 'part_predict' now contains the partial predictions from the decision tree for the entire dataset </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d69c96758c1e7be0caa534fcb8f9e16b1f4fa056"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4b6cd7033e26f36b1873baf37ab8c5079e907fb5"
   },
   "source": [
    "<h2> We now prepare the training dataset for the neural network </h2> \n",
    "\n",
    "As was mentioned earlier, the neural network needs the probability distributions from the tree and the remaining numerical columns. \n",
    "\n",
    "So the inputs to the tree would be: \n",
    "\n",
    "<ul>\n",
    "    <li> Probability Distributions from the decision tree (length = 6) </li>\n",
    "    <li> backers </li>\n",
    "    <li> usd_pledged_real </li>\n",
    "    <li> usd_goal_real </li> \n",
    "</ul> \n",
    "\n",
    "I am omitting the other columns for \"pledged\" and \"goal\" as they may contain different 'currencies' which has already been handled by the tree.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ff8321554b235b116281c705121b59556b7f35cd"
   },
   "source": [
    "<h2> We first concatenate the partial prediction to the remaining (numeric) fields in the dataset </h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8793c449a6d2e3b15aa5822a885657ce81bacff0"
   },
   "outputs": [],
   "source": [
    "nn_train_part1 = part_predict\n",
    "nn_train_part2 = np.array(kick_start[['backers', 'usd_pledged_real', 'usd_goal_real']])\n",
    "\n",
    "print (nn_train_part1.shape)\n",
    "print (nn_train_part2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ba07705ff1cb721b690a2638e4f090305df10f1"
   },
   "outputs": [],
   "source": [
    "nn_inputs = np.concatenate((nn_train_part1, nn_train_part2), axis=1)\n",
    "print(nn_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a6cd8f5e5dd912614c7ddb85d07c9b4420a2703b"
   },
   "outputs": [],
   "source": [
    "#save the training_inputs for the neural network\n",
    "np.save('/kaggle/working/nn_inputs', nn_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f44b6c74fbcce069eb2803114c1f3746ab6c2b5c"
   },
   "outputs": [],
   "source": [
    "# for the targets of the neural network\n",
    "states = np.array(kick_start['state'])\n",
    "states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0c8e7bf1467b89b8caa5c581ce71b12fea497a06"
   },
   "outputs": [],
   "source": [
    "# to translate the state into integers for one-hot encoding\n",
    "def translate_states(states):\n",
    "    array = np.empty([len(states)], dtype = 'int8')\n",
    "    positions = {'failed':0, \n",
    "                 'successful':1, \n",
    "                 'canceled':2, \n",
    "                 'undefined':3, \n",
    "                 'live':4, \n",
    "                 'suspended':5} \n",
    "    for i, state in enumerate(list(states)):\n",
    "        array[i] = int(positions[state])\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c7201a3f638a98de1ad161cf9ac8a22719bccc98"
   },
   "outputs": [],
   "source": [
    "translated = translate_states(states)\n",
    "translated[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "760b183d647b23fdc81cc75eba1cf42687334ad0"
   },
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "nb_classes = 6\n",
    "one_hot_targets = np.eye(nb_classes)[translated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8ab28b53584382b9aff529741f9431b3f9dbdced"
   },
   "outputs": [],
   "source": [
    "one_hot_targets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3e1096fde97943e6e76e1672c16774658f690356"
   },
   "outputs": [],
   "source": [
    "# saving the targets for the neural network\n",
    "np.save('/kaggle/working/one_hot_targets', one_hot_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "86783055f50833ea97e20371ec249b26e74d1250"
   },
   "source": [
    "<h2> We now have our inputs in \"nn_inputs\" and our targets in \"one_hot_targets\". </h2>\n",
    "\n",
    "<b> Training the Neural Network </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f6207ca7d986ba298a6a49f145fce6981e479968"
   },
   "outputs": [],
   "source": [
    "inputs = np.load('/kaggle/working/nn_inputs.npy')\n",
    "targets = np.load('/kaggle/working/one_hot_targets.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6cc9132a3250fbd3c1846870214a7ccdcd926a50"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(9, input_dim=9, activation='sigmoid'))\n",
    "model.add(Dense(20, activation='sigmoid'))\n",
    "model.add(Dense(20, activation='sigmoid'))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(6, activation = 'softmax')) \n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(nn_inputs, one_hot_targets, validation_split = 0.1, epochs = 6, batch_size=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b54c3f68a23f67b52cb5194cdba26822a25b4d2a"
   },
   "outputs": [],
   "source": [
    "model.save('/kaggle/working/nn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1d0084038fb3270c6f96678fd091f7ca6ccd06d7"
   },
   "outputs": [],
   "source": [
    "# helper function to convert dates to num_days\n",
    "def convert_dates(features):\n",
    "    x = pd.to_datetime(features[\"deadline\"])\n",
    "    y = pd.to_datetime(features[\"launched\"])\n",
    "    z = x - y \n",
    "    num_days = str(z.days)\n",
    "    return num_days\n",
    "    \n",
    "# for final predictions using both the decision tree and the neural network \n",
    "# inputs: a pandas.Series.series object called features, and,\n",
    "#         the trained decision tree and neural network\n",
    "# outputs: the predicted 'state' for the provided features as a numpy array \n",
    "def predict(features, d_tree, model):\n",
    "    expected_out = one_hot = None\n",
    "    reverse_hot = {0:'failed', \n",
    "                   1:'successful', \n",
    "                   2:'canceled', \n",
    "                   3:'undefined', \n",
    "                   4:'live', \n",
    "                   5:'suspended'}\n",
    "    num_days = convert_dates(features)\n",
    "    features = dict(features)\n",
    "    features['num_days'] = num_days\n",
    "    part_preds = partial_predict(d_tree, features)\n",
    "    part1 = translate(part_preds)\n",
    "    part2 = np.array([features['backers'], \n",
    "                      features['usd_pledged_real'], \n",
    "                      features['usd_goal_real']])\n",
    "    to_predict = np.concatenate((part1, part2))\n",
    "    to_predict = np.array([to_predict])\n",
    "    predicted_numpy = model.predict(to_predict)\n",
    "    prediction = np.array(reverse_hot[predicted_numpy.argmax()])\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "63b2b757af93742e7c0c36e4b96834e87250cf18"
   },
   "source": [
    "<h3> Testing on some instances </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "527651a3005c533c88b3bcc1b4476c490d97b20a"
   },
   "outputs": [],
   "source": [
    "# test an i'th row in the dataset\n",
    "def get_prediction(i):\n",
    "    return predict(kick_start.loc[i], d_tree, model)\n",
    "\n",
    "print (get_prediction(randint(0,1000)))\n",
    "print (get_prediction(randint(0,5000)))\n",
    "print (get_prediction(randint(0,1000)))\n",
    "print (get_prediction(randint(0,5000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bad074f810d68c900334a98ec0a04e0af3b5150b"
   },
   "source": [
    "<h2> Testing with the entire training dataset </h2> \n",
    "\n",
    "Loading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d06216c1311e9d8cd6d1b78a1d68c194c9a43131"
   },
   "outputs": [],
   "source": [
    "model = load_model('/kaggle/working/nn_model.h5')\n",
    "d_tree = load_tree('/kaggle/working/decision_tree.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "207042cd66d5bfd795841f730516e98474d10b25"
   },
   "source": [
    "<h3> We will drop the 'state' labels from the training data and fill it with 'None' </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "11b3779402eae623328f23b9dbb3a5e250c39444"
   },
   "outputs": [],
   "source": [
    "kick_start_test = kick_start.drop(['state'], axis=1)\n",
    "kick_start_test['state'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ebffe0e5d27b646742e4b8de2667b19e2855d1db"
   },
   "outputs": [],
   "source": [
    "kick_start_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "db348d83c6009cec81cf9446c86488e25e59b608"
   },
   "outputs": [],
   "source": [
    "expected_outputs = kick_start['state']\n",
    "expected_outputs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "59d7cd878a07003a75a9caf079f7350e2a547888"
   },
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "results = {'predicted':[], 'expected': list(expected_outputs)}\n",
    "for index,row in kick_start_test.iterrows():\n",
    "    results['predicted'].append(predict(row, d_tree, model))  \n",
    "\n",
    "end = time.perf_counter()\n",
    "print ('Getting predictions on the training dataset took ' + \n",
    "       str((end - start) / 60.0) + ' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "226d22459dfe9369408ad0aefb2e5f1fcb9efc69"
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('/kaggle/working/results_training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "846f28e2ac50230874f01a0288ce97cff9837766"
   },
   "outputs": [],
   "source": [
    "def display_results_data(result_df):\n",
    "    matches = result_df.loc[(result_df['predicted'] == result_df['expected'])]\n",
    "    match_percentage = len(matches)/len(result_df) * 100\n",
    "    errors =  result_df.loc[(result_df['predicted'] != result_df['expected'])]\n",
    "    error_percentage = len(errors)/len(result_df) * 100\n",
    "    \n",
    "    print ('\\nTrue Positives = ' + str(len(matches)) + \n",
    "           '\\t\\t' + 'True Pos. Percentage = ' + \n",
    "           str(match_percentage))\n",
    "    print ('\\nErrors = ' + str(len(errors)) +\n",
    "           '\\t\\t\\t' + 'Error Percentage = ' + \n",
    "           str(error_percentage))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bf52faff3c3efd112aae6838a67b9ef193b4f84c"
   },
   "outputs": [],
   "source": [
    "display_results_data(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a4a2c4d901337dc2bba55d6f980fc11cbf866967"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1f1aa7387f4a01380bb97e9555b06351f8c56acc"
   },
   "source": [
    "<h1> TESTING ON UNSEEN DATA </h1> \n",
    "<h3> I will now use the 'kick_start_unique' dataframe set aside for testing which has data neither model was trained on </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "113011e71d8f55c2e5db9414f140118a91633acc"
   },
   "outputs": [],
   "source": [
    "model = load_model('/kaggle/working/nn_model.h5')\n",
    "d_tree = load_tree('/kaggle/working/decision_tree.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ad77aa013c72344e38dee1b514fdd998e680f6ac"
   },
   "source": [
    "<h3> Recalling the unique data from 2018 not present in 2016 for this test. <br>\n",
    "These records are new to both the models as only 2016 records were considered for the training </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c3b6e36b821b995aab4b88fa284d9f8772b55c59"
   },
   "outputs": [],
   "source": [
    "kick_start_unique.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "99390e8363d3b34f27e536e5f363a66f80c0900e"
   },
   "source": [
    " Initializing the \"expected\" outputs and dropping the 'state' column from test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "22247906fbba42cd4638b92a18cbb69148a706d9"
   },
   "outputs": [],
   "source": [
    "expected_outputs = kick_start_unique['state']\n",
    "expected_outputs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5c6b3029ac2e4771a38ecc9101027ddb3ce2f7bc"
   },
   "outputs": [],
   "source": [
    "test_data = kick_start_unique.drop(['state'], axis=1)\n",
    "test_data['state'] = None\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "52c60db1fc2fee62336d05db6f792e518600e8eb"
   },
   "source": [
    "<h2> Final Model Predictions <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d30cac5ad0f79c558e47b25f31a47af006b69148"
   },
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "results = {'predicted':[], 'expected': list(expected_outputs)}\n",
    "for index,row in test_data.iterrows():\n",
    "    results['predicted'].append(predict(row, d_tree, model))  \n",
    "\n",
    "end = time.perf_counter()\n",
    "print ('Getting predictions on the Test dataset took ' + \n",
    "       str((end - start) / 60.0) + ' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e289ebdbdf9cb93fc12211a38b6302fb8ee72bd2"
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('/kaggle/working/unseen_test_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d0b95f3070f1d3c6e7770e6bfdb4726b8e10273a"
   },
   "outputs": [],
   "source": [
    "display_results_data(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "034f3883ebba5e85587c4bd53bd63cb9e34c12dd"
   },
   "source": [
    "<h1> So, the accuracy of the combined, symbiotic models, is still better than 80% even on unseen data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6d956d5f87ea41fdb880f353869c2e5607de6a57"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
